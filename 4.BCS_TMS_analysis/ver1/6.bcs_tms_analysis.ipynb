{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e5118c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import ctypes\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.api.types import is_datetime64tz_dtype\n",
    "import platform\n",
    "import logging\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import zipfile\n",
    "import duckdb \n",
    "import warnings\n",
    "import fastparquet\n",
    "from tqdm import tqdm \n",
    "from typing import List, Optional, Union\n",
    "import psutil\n",
    "import time # For timing the execution\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# Optional: adjust pandas display for debugging; you can comment these out\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ee48ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# jupyter nbconvert --to python 6.bcs_tms_analysis.ipynb \\\n",
    "#     --TemplateExporter.exclude_markdown=True \\\n",
    "#     --TemplateExporter.exclude_output_prompt=True \\\n",
    "#     --TemplateExporter.exclude_input_prompt=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed3575c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded mapping table with 27 entries.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>reg_num</th>\n",
       "      <th>customer</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>AP39WF8593</td>\n",
       "      <td>FB Guntur</td>\n",
       "      <td>12.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>AP39WG0252</td>\n",
       "      <td>FB Guntur</td>\n",
       "      <td>12.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>AP39WF8589</td>\n",
       "      <td>FB Guntur</td>\n",
       "      <td>12.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>AP39WF8584</td>\n",
       "      <td>FB Guntur</td>\n",
       "      <td>12.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>AP39WG0271</td>\n",
       "      <td>FB Guntur</td>\n",
       "      <td>12.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     reg_num   customer  model\n",
       "0  11  AP39WF8593  FB Guntur   12.5\n",
       "1   9  AP39WG0252  FB Guntur   12.5\n",
       "2   7  AP39WF8589  FB Guntur   12.5\n",
       "3  13  AP39WF8584  FB Guntur   12.5\n",
       "4  14  AP39WG0271  FB Guntur   12.5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_file = \"../../../data_points/Naarni VehicleID_RegNo_links - Vehicle_mapping.csv\"\n",
    "try:\n",
    "    df_mapping = pd.read_csv(mapping_file)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Mapping file '{mapping_file}' not found. Cannot enrich data.\")\n",
    "    # Create an empty mapping table to allow the rest of the script to run without crashing\n",
    "    df_mapping = pd.DataFrame(columns=[\"id\", \"reg_num\", \"customer\", \"model\"])\n",
    "else:\n",
    "    df_mapping = df_mapping.rename(columns={\n",
    "        \"Device No.\": \"id\",\n",
    "        \"Registration No\": \"reg_num\",\n",
    "        \"Customer\": \"customer\",\n",
    "        \"Model\": \"model\"\n",
    "    })\n",
    "    # Ensure the merge key ('id') is a string to match the chunks\n",
    "    if \"id\" in df_mapping.columns:\n",
    "        df_mapping[\"id\"] = df_mapping[\"id\"].astype(str)\n",
    "        df_mapping = df_mapping[[\"id\", \"reg_num\", \"customer\", \"model\"]]\n",
    "    else:\n",
    "        print(\"Warning: 'Device No.' column not found in mapping file.\")\n",
    "        df_mapping = pd.DataFrame(columns=[\"id\", \"reg_num\", \"customer\", \"model\"])\n",
    "\n",
    "print(f\"Loaded mapping table with {len(df_mapping)} entries.\")\n",
    "# df_mapping is now ready to be passed into the processing function\n",
    "\n",
    "df_mapping.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0cf6c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "CORE_COLS = [\n",
    "    \"id\", \"timestamp\", \"dt\",\n",
    "    \"vehiclereadycondition\", \"gun_connection_status\", \"ignitionstatus\",\"odometerreading\",\n",
    "    \"vehicle_speed_vcu\", \"gear_position\",\n",
    "    \"bat_soc\", \"soh\", \"total_battery_current\",\n",
    "    \"pack1_cellmax_temperature\", \"pack1_cell_min_temperature\",\n",
    "    \"pack1_maxtemperature_cell_number\", \"pack1_celltemperature_cellnumber\",\n",
    "    \"bat_voltage\", \"cellmax_voltagecellnumber\", \"cellminvoltagecellnumber\", \n",
    "    \"cell_min_voltage\",\"cell_max_voltage\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7067d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def free_mem():\n",
    "    \"\"\"Try to return freed memory back to the OS (no-op on some platforms).\"\"\"\n",
    "    try:\n",
    "        libc = ctypes.CDLL(None)\n",
    "        if hasattr(libc, \"malloc_trim\"):\n",
    "            libc.malloc_trim(0)\n",
    "    except Exception:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d35fd70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_battery_temp_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Uses df.rename(inplace=False), creating one copy, which is fine for chunks\n",
    "    rename_map = {\n",
    "        \"pack1_cellmax_temperature\": \"batt_maxtemp\",\n",
    "        \"pack1_cell_min_temperature\": \"batt_mintemp\",\n",
    "        \"pack1_maxtemperature_cell_number\":\"batt_maxtemp_tc\", \n",
    "        \"pack1_celltemperature_cellnumber\":\"batt_mintemp_tc\",\n",
    "        \"cell_max_voltage\":\"batt_maxvolt\",\n",
    "        \"cellmax_voltagecellnumber\":\"batt_maxvolt_cell\",\n",
    "        \"cell_min_voltage\":\"batt_minvolt\",\n",
    "        \"cellminvoltagecellnumber\":\"batt_minvolt_cell\", \n",
    "    }\n",
    "    existing = {k: v for k, v in rename_map.items() if k in df.columns}\n",
    "    if not existing:\n",
    "        return df\n",
    "    return df.rename(columns=existing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e93dfe43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================================\n",
    "# CONFIG\n",
    "# =====================================================================\n",
    "\n",
    "MAX_SPEED_KMPH = 120.0      # physical upper bound (bus never >120 km/h)\n",
    "MAX_ODO_DIST_KM = 0.2       # max plausible odo jump per sample (~200 m)\n",
    "MAX_DT_SEC = 3.0            # dt_sec cap (you already use this)\n",
    "BIG_ODO_CAP = 1.0           # sanity cap for odo (km)\n",
    "DT_DISCONTINUITY_SEC = 180  # >3 min gap can be treated as discontinuity in Stage-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7eddf573",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalize_odometer(df):\n",
    "    df = df.sort_values([\"id\", \"timestamp\"]).copy()\n",
    "\n",
    "    for vid, grp in df.groupby(\"id\"):\n",
    "        idx = grp.index\n",
    "        odo = grp[\"odometer_final\"].to_numpy()\n",
    "\n",
    "        for i in range(1, len(odo)):\n",
    "            if odo[i] < odo[i-1]:\n",
    "                odo[i] = odo[i-1]\n",
    "\n",
    "        df.loc[idx, \"odometer_final\"] = odo\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ccfc668f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_odometer(df, odo_col=\"odometerreading\"):\n",
    "    \"\"\"\n",
    "    TRUE, CORRECT, NULL-ONLY, SESSION-AWARE, 3-PASS ODOMETER IMPUTER.\n",
    "\n",
    "    Rules implemented exactly:\n",
    "\n",
    "      â€¢ PASS 1: Fix top/bottom NULL islands.\n",
    "      â€¢ PASS 2: SINGLE NULL: bracket logic + speed/dt estimate + clamping.\n",
    "      â€¢ PASS 3: MULTI NULL: iterative bounded fill, updating L â†’ new L.\n",
    "      â€¢ Session protection: If R < L â†’ treat as session break â†’ propagate L.\n",
    "      â€¢ STRICT: Never modify original *non-null* odometer readings.\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.sort_values([\"id\", \"timestamp\"]).copy()\n",
    "    df[\"odometer_final\"] = df[odo_col].astype(float)\n",
    "\n",
    "    for vid, grp in df.groupby(\"id\"):\n",
    "        idx = grp.index\n",
    "        odo_raw = grp[odo_col].astype(float).to_numpy()\n",
    "        speed = grp[\"vehicle_speed_vcu\"].astype(float).to_numpy()\n",
    "        dt = grp[\"dt_sec\"].astype(float).to_numpy()\n",
    "\n",
    "        # Final output buffer:\n",
    "        fill = odo_raw.copy()\n",
    "\n",
    "        n = len(odo_raw)\n",
    "        i = 0\n",
    "\n",
    "        while i < n:\n",
    "            if not np.isnan(odo_raw[i]):\n",
    "                i += 1\n",
    "                continue\n",
    "\n",
    "            # Start of a null island\n",
    "            start = i\n",
    "            while i < n and np.isnan(odo_raw[i]):\n",
    "                i += 1\n",
    "            end = i - 1  # inclusive\n",
    "\n",
    "            prev_idx = start - 1\n",
    "            next_idx = end + 1\n",
    "\n",
    "            L = odo_raw[prev_idx] if prev_idx >= 0 else None\n",
    "            R = odo_raw[next_idx] if next_idx < n else None\n",
    "\n",
    "            # -------------------------------\n",
    "            # PASS 1: TOP & BOTTOM NULL ISLANDS\n",
    "            # -------------------------------\n",
    "            if L is None and R is not None:\n",
    "                # Top NULL block â†’ propagate next known value backward\n",
    "                for pos in range(start, end + 1):\n",
    "                    fill[pos] = R\n",
    "                continue\n",
    "\n",
    "            if R is None and L is not None:\n",
    "                # Bottom NULL block â†’ propagate previous known value forward\n",
    "                for pos in range(start, end + 1):\n",
    "                    fill[pos] = L\n",
    "                continue\n",
    "\n",
    "            # If both missing â†’ extremely rare but fallback to zero change\n",
    "            if L is None and R is None:\n",
    "                continue\n",
    "\n",
    "            # -------------------------------\n",
    "            # SESSION BREAK PROTECTION\n",
    "            # -------------------------------\n",
    "            if R < L:\n",
    "                # Monotonic break â†’ treat as end-of-session\n",
    "                for pos in range(start, end + 1):\n",
    "                    fill[pos] = L\n",
    "                continue\n",
    "\n",
    "            # -------------------------------\n",
    "            # PASS 2 & PASS 3 (Unified Engine)\n",
    "            # -------------------------------\n",
    "            gap = end - start + 1\n",
    "\n",
    "            # The active bounds shrink as we impute\n",
    "            curr_L = L\n",
    "            curr_R = R\n",
    "\n",
    "            for k in range(gap):\n",
    "                pos = start + k\n",
    "\n",
    "                if speed[pos] == 0:\n",
    "                    est = curr_L  # idle â†’ no movement\n",
    "                else:\n",
    "                    # compute movement in km\n",
    "                    est = curr_L + (speed[pos] * dt[pos] / 3600.0)\n",
    "\n",
    "                # Clamp within [curr_L, curr_R]\n",
    "                est_clamped = max(curr_L, min(est, curr_R))\n",
    "\n",
    "                # STRICT: only fill if original was NULL\n",
    "                if np.isnan(odo_raw[pos]):\n",
    "                    fill[pos] = est_clamped\n",
    "\n",
    "                # Shrink left boundary â†’ progressive update\n",
    "                curr_L = fill[pos]\n",
    "\n",
    "        df.loc[idx, \"odometer_final\"] = np.round(fill, 3)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12c43ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing_values(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Clean & impute all sensors EXCEPT odometer.\n",
    "\n",
    "    Includes:\n",
    "      - dt_sec sanitisation\n",
    "      - SOC fixing (SOC=0 â†’ NaN â†’ interpolated)\n",
    "      - temperature, voltage, TC/cell sanity\n",
    "      - refined battery current clamping\n",
    "      - ignition/ready/gun consistency\n",
    "      - charging-mode overrides\n",
    "      - parked-mode overrides\n",
    "      - speed imputation for all stable states\n",
    "      - gear correction\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.sort_values([\"id\", \"timestamp\"]).copy()\n",
    "\n",
    "    # Round column 'odometerreading' to 3 decimal places, preserving NaNs\n",
    "    mask_odo = df['odometerreading'].notna() # Create a boolean mask for non-null values\n",
    "    df.loc[mask_odo, 'odometerreading'] = df.loc[mask_odo, 'odometerreading'].round(3)\n",
    "\n",
    "    # ----------------------------------------------------\n",
    "    # 0. dt_sec calculation\n",
    "    # ----------------------------------------------------\n",
    "    df[\"dt_sec\"] = (\n",
    "        df.groupby(\"id\")[\"timestamp\"]\n",
    "          .diff()\n",
    "          .dt.total_seconds()\n",
    "          .fillna(0)\n",
    "    )\n",
    "    df.loc[df[\"dt_sec\"] > 3, \"dt_sec\"] = 0\n",
    "\n",
    "    # ----------------------------------------------------\n",
    "    # 1. SANITISATION\n",
    "    # ----------------------------------------------------\n",
    "    # 1a temperature sanitisation\n",
    "    for col in [\"batt_maxtemp\", \"batt_mintemp\"]:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "        df.loc[df[col] < -10, col] = pd.NA\n",
    "\n",
    "    # 1b voltage\n",
    "    for col in [\"batt_maxvolt\", \"batt_minvolt\", \"bat_voltage\"]:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "        df.loc[df[col] <= 0, col] = pd.NA\n",
    "\n",
    "    # 1c thermocouple + cell\n",
    "    for col in [\"batt_maxtemp_tc\", \"batt_mintemp_tc\"]:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "        df.loc[(df[col] < 1) | (df[col] > 108), col] = pd.NA\n",
    "\n",
    "    for col in [\"batt_maxvolt_cell\", \"batt_minvolt_cell\"]:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "        df.loc[(df[col] < 1) | (df[col] > 576), col] = pd.NA\n",
    "\n",
    "    # ----------------------------------------------------\n",
    "    # 1d SOC FIX â€” VERY IMPORTANT\n",
    "    # ----------------------------------------------------\n",
    "    df[\"bat_soc\"] = pd.to_numeric(df[\"bat_soc\"], errors=\"coerce\")\n",
    "\n",
    "    # SOC=0 is almost always a sensor glitch â†’ treat as missing\n",
    "    df.loc[df[\"bat_soc\"] == 0, \"bat_soc\"] = np.nan\n",
    "\n",
    "    # Interpolate SOC per vehicle\n",
    "    df[\"bat_soc\"] = (\n",
    "        df.groupby(\"id\")[\"bat_soc\"]\n",
    "        .transform(lambda s: s.interpolate(limit_direction=\"both\"))\n",
    "    )\n",
    "\n",
    "\n",
    "    df[\"bat_soc\"] = df[\"bat_soc\"].clip(lower=0, upper=100)\n",
    "\n",
    "    # ----------------------------------------------------\n",
    "    # 1e refined battery current clamp\n",
    "    # ----------------------------------------------------\n",
    "    curr = pd.to_numeric(df[\"total_battery_current\"], errors=\"coerce\")\n",
    "    valid_mask = curr.abs().between(0, 2500)\n",
    "    valid_values = curr.where(valid_mask)\n",
    "\n",
    "    curr_ff = valid_values.ffill().fillna(0.0)\n",
    "    curr = curr.where(valid_mask, curr_ff)\n",
    "    df[\"total_battery_current\"] = curr\n",
    "\n",
    "    # ----------------------------------------------------\n",
    "    # 2. GROUPWISE IMPUTATION (per vehicle)\n",
    "    # ----------------------------------------------------\n",
    "    impute_cols = [\n",
    "        (\"batt_maxtemp\", 80),\n",
    "        (\"batt_mintemp\", 80),\n",
    "        (\"batt_maxtemp_tc\", 80),\n",
    "        (\"batt_mintemp_tc\", 80),\n",
    "        (\"batt_maxvolt\", 30),\n",
    "        (\"batt_minvolt\", 30),\n",
    "        (\"batt_maxvolt_cell\", 30),\n",
    "        (\"batt_minvolt_cell\", 30),\n",
    "        (\"bat_voltage\", 20),\n",
    "        (\"bat_soc\", 300),   # now cleaned\n",
    "        (\"soh\", 300),\n",
    "    ]\n",
    "\n",
    "    for vid, grp in df.groupby(\"id\"):\n",
    "        idx = grp.index\n",
    "\n",
    "        # -----------------------------------------\n",
    "        # 2a forward/backfill for regular sensors\n",
    "        # -----------------------------------------\n",
    "        for col, limit in impute_cols:\n",
    "            df.loc[idx, col] = grp[col].ffill().bfill()\n",
    "\n",
    "        # -----------------------------------------\n",
    "        # 2b current interpolation for small gaps\n",
    "        # -----------------------------------------\n",
    "        df.loc[idx, \"total_battery_current\"] = grp[\"total_battery_current\"].interpolate(\n",
    "            limit=10, limit_direction=\"both\"\n",
    "        )\n",
    "\n",
    "        # -----------------------------------------\n",
    "        # 2c BASIC READY + GUN fill\n",
    "        # -----------------------------------------\n",
    "        for col in [\"vehiclereadycondition\", \"gun_connection_status\"]:df.loc[idx, col] = grp[col].ffill().bfill()\n",
    "\n",
    "        # -----------------------------------------\n",
    "        # 2d IGNITIONSTATUS CLEANUP\n",
    "        # -----------------------------------------\n",
    "        ign = pd.to_numeric(grp[\"ignitionstatus\"], errors=\"coerce\")\n",
    "        ign = ign.ffill().bfill()\n",
    "\n",
    "        # Ready=1 & ignition null â†’ ignition=1\n",
    "        ready_mask = df.loc[idx, \"vehiclereadycondition\"].fillna(0).astype(int).eq(1)\n",
    "        ign.loc[ready_mask & ign.isna()] = 1\n",
    "        df.loc[idx, \"ignitionstatus\"] = ign\n",
    "\n",
    "        # -----------------------------------------\n",
    "        # 2e SPEED IMPUTATION\n",
    "        # -----------------------------------------\n",
    "        if \"vehicle_speed_vcu\" in grp.columns:\n",
    "            v = pd.to_numeric(grp[\"vehicle_speed_vcu\"], errors=\"coerce\")\n",
    "            v = v.where(v.between(0, 120), np.nan)\n",
    "\n",
    "            v = v.ffill().bfill()\n",
    "            df.loc[idx, \"vehicle_speed_vcu\"] = v.round(2)\n",
    "\n",
    "        # -----------------------------------------\n",
    "        # 2f GEAR POSITION\n",
    "        # -----------------------------------------\n",
    "        if \"gear_position\" in grp.columns:\n",
    "            g = pd.to_numeric(grp[\"gear_position\"], errors=\"coerce\")\n",
    "            g = g.where(g.isin([0, 1, 2]), np.nan)\n",
    "\n",
    "            ready0 = df.loc[idx, \"vehiclereadycondition\"].fillna(0).astype(int).eq(0)\n",
    "            ign0 = df.loc[idx, \"ignitionstatus\"].fillna(0).astype(int).eq(0)\n",
    "\n",
    "            force_neutral = ready0 | ign0\n",
    "            g[force_neutral] = 0\n",
    "\n",
    "            df.loc[idx, \"gear_position\"] = g.ffill().bfill().astype(\"Int64\")\n",
    "\n",
    "        # ----------------------------------------------------\n",
    "        # 2g CHARGING STATE CONSISTENCY\n",
    "        # ----------------------------------------------------\n",
    "        charging = df.loc[idx, \"gun_connection_status\"].fillna(0).astype(int).eq(1)\n",
    "\n",
    "        # ignition ON during charging\n",
    "        df.loc[idx[charging], \"ignitionstatus\"] = 1\n",
    "        df.loc[idx[charging], \"vehiclereadycondition\"] = 0\n",
    "        df.loc[idx[charging], \"gear_position\"] = 0\n",
    "\n",
    "        # speed=0 when charging & missing\n",
    "        df.loc[idx[charging & df.loc[idx, \"vehicle_speed_vcu\"].isna()],\"vehicle_speed_vcu\"] = 0.0\n",
    "\n",
    "        # ----------------------------------------------------\n",
    "        # 2h OFF/PARKED SPEED FIX\n",
    "        # gun=0 & ready=0 & ignition=0 & speed NA â†’ 0\n",
    "        # ----------------------------------------------------\n",
    "        off_mask = (\n",
    "            (df.loc[idx, \"gun_connection_status\"].fillna(0).astype(int) == 0) &\n",
    "            (df.loc[idx, \"vehiclereadycondition\"].fillna(0).astype(int) == 0) &\n",
    "            (df.loc[idx, \"ignitionstatus\"].fillna(0).astype(int) == 0)\n",
    "        )\n",
    "\n",
    "        df.loc[idx[off_mask & df.loc[idx, \"vehicle_speed_vcu\"].isna()],\"vehicle_speed_vcu\"] = 0.0\n",
    "\n",
    "        # ----------------------------------------------------\n",
    "        # 2i READY BUT IGNITION=0 (contradictory â†’ treat as stationary)\n",
    "        # ----------------------------------------------------\n",
    "        ready_ign_off = (\n",
    "            (df.loc[idx, \"gun_connection_status\"].fillna(0).astype(int) == 0) &\n",
    "            (df.loc[idx, \"vehiclereadycondition\"].fillna(0).astype(int) == 1) &\n",
    "            (df.loc[idx, \"ignitionstatus\"].fillna(0).astype(int) == 0)\n",
    "        )\n",
    "\n",
    "        df.loc[idx[ready_ign_off & df.loc[idx, \"vehicle_speed_vcu\"].isna()],\"vehicle_speed_vcu\"] = 0.0\n",
    "        \n",
    "        df.vehicle_speed_vcu = df.vehicle_speed_vcu.round(2)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40517f63",
   "metadata": {},
   "source": [
    "Aï¸âƒ£ First: we derive a boolean signal: `gun_connected = (out[\"gun_connection_status\"] == 1)`\n",
    "\n",
    "ðŸ”‹ CHARGING_ACTIVE: `chg_active = (gun_connected) & (current > +5A)`\n",
    "- Battery is in CC/CV mode, current > 0, charger locked â†’ SOC must increase or stay flat.\n",
    "- If it drops â†’ timestamp glitch, SOC jitter, or packet misordering â†’ G L I T C H\n",
    "\n",
    "ðŸ”‹ CHARGING_MAINTAIN: `chg_maint = (gun_connected) & current.abs().between(0, 5)`\n",
    "- BMS balancing may cause Â±0.1â€“0.3 % SOC wobble.\n",
    "- Bigger drops = glitch.\n",
    "\n",
    "ðŸ”‹ CHARGING_IDLE: chg_idle = `(gun_connected) & (current > 5)`\n",
    "- Charger connected but no current. SOC may drift slightly due to temperature compensation. Â±0.5% jitter is normal.\n",
    "\n",
    "\n",
    "Bï¸âƒ£ Then DISCHARGING_* states\n",
    "- âœ” DISCHARGING_ACTIVE\n",
    "- dis_active = (\n",
    "    (~gun_connected) &\n",
    "    (vehicle_speed_vcu > 0.5) &\n",
    "    (gear_position in [1,2])\n",
    ")\n",
    "\n",
    "* DISCHARGING_IDLE\n",
    "- Everything else not covered by the above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92a1c397",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_df_with_state(df: pd.DataFrame, df_mapping: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Make a copy (chunk-safe)\n",
    "    out = df.copy()\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 1. Merge mapping\n",
    "    # ------------------------------------------------------------------\n",
    "    out[\"id\"] = out[\"id\"].astype(str)\n",
    "    out = out.merge(df_mapping, on=\"id\", how=\"left\", validate=\"m:1\")\n",
    "\n",
    "    # fill mapping fallbacks\n",
    "    out[\"reg_num\"] = out[\"reg_num\"].fillna(\"REGNUM_\" + out[\"id\"])\n",
    "    out[\"customer\"] = out[\"customer\"].fillna(\"CUST_\" + out[\"id\"])\n",
    "    out[\"model\"] = out[\"model\"].fillna(\"MDL_\" + out[\"id\"])\n",
    "\n",
    "    out[\"reg_num\"] = out[\"reg_num\"].astype(str)\n",
    "    out[\"customer\"] = out[\"customer\"].astype(str)\n",
    "    out[\"model\"] = out[\"model\"].astype(str)\n",
    "\n",
    "    # -----------------------------------------------------------\n",
    "    # 2. Timestamp handling â€” THE SAFE VERSION\n",
    "    # -----------------------------------------------------------\n",
    "\n",
    "    # --- TIMESTAMP FIX (UTC â†’ IST) ---\n",
    "\n",
    "    # 1. Parse raw timestamp exactly as received\n",
    "    out[\"ts_utc\"] = pd.to_datetime(out[\"timestamp\"], errors=\"coerce\", utc=True)\n",
    "\n",
    "    # 2. Drop invalid rows\n",
    "    out = out.dropna(subset=[\"ts_utc\"])\n",
    "\n",
    "    # 3. Convert to Asia/Kolkata (IST)\n",
    "    out[\"timestamp\"] = out[\"ts_utc\"].dt.tz_convert(\"Asia/Kolkata\")\n",
    "\n",
    "    # 4. Remove timezone info from final timestamp if needed\n",
    "    #    (matplotlib, parquet, feather become safer with tz-naive)\n",
    "    out[\"timestamp\"] = out[\"timestamp\"].dt.tz_localize(None)\n",
    "\n",
    "    # 5. Sort by vehicle + IST timestamp\n",
    "    out = out.sort_values([\"id\", \"timestamp\"]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 3. Mode + alt_mode logic (unchanged)\n",
    "    # ------------------------------------------------------------------\n",
    "\n",
    "    # Gun connection normalization\n",
    "    gcs_raw = out[\"gun_connection_status\"]\n",
    "    gcs_num = pd.to_numeric(gcs_raw, errors=\"coerce\")\n",
    "    gcs_str = gcs_raw.astype(str).str.lower().str.strip()\n",
    "\n",
    "    gun_connected = (gcs_num == 1) | gcs_str.isin({\"1\",\"true\",\"yes\",\"y\",\"connected\",\"on\"})\n",
    "    gun_connected = gun_connected.fillna(False)\n",
    "\n",
    "    # Vehicle readiness normalization\n",
    "    if \"vehiclereadycondition\" in out.columns:\n",
    "        vrc_raw = out[\"vehiclereadycondition\"]\n",
    "        vrc_num = pd.to_numeric(vrc_raw, errors=\"coerce\")\n",
    "        vrc_str = vrc_raw.astype(str).str.strip().str.lower()\n",
    "        vehicle_ready = (vrc_num == 1) | vrc_str.isin({\"1\",\"true\",\"yes\",\"y\",\"ready\",\"on\"})\n",
    "        vehicle_ready = vehicle_ready.fillna(False)\n",
    "    else:\n",
    "        vehicle_ready = pd.Series(False, index=out.index)\n",
    "\n",
    "    # Legacy mode column\n",
    "    out[\"mode\"] = np.where(gun_connected, \"CHARGING\", \"DISCHARGING\")\n",
    "\n",
    "    # Rolling current for alt_mode\n",
    "    current_rm = (\n",
    "        out[\"total_battery_current\"]\n",
    "        .rolling(15, min_periods=1)\n",
    "        .mean()\n",
    "        .fillna(0)\n",
    "    )\n",
    "\n",
    "    # thresholds\n",
    "    ACTIVE_CHG_THRESH = -15\n",
    "    MAINTAIN_LOW = -15\n",
    "    MAINTAIN_HIGH = +2\n",
    "\n",
    "    # CHARGING states\n",
    "    chg_active = (gun_connected &(out[\"total_battery_current\"] < -5)).to_numpy(dtype=bool)\n",
    "    chg_maint = (gun_connected &(out[\"total_battery_current\"].abs().between(0, 5))).to_numpy(dtype=bool)\n",
    "    chg_idle = (gun_connected &(out[\"total_battery_current\"] > 5)).to_numpy(dtype=bool)\n",
    "\n",
    "    # # DISCHARGING states\n",
    "    dis_active = ((~gun_connected) &(out[\"vehicle_speed_vcu\"].gt(0.5).fillna(False)) &(out[\"gear_position\"].isin([1, 2]).fillna(False))).to_numpy(dtype=bool)\n",
    "    # dis_idle   = ((~gun_connected) & (~dis_active)).to_numpy(dtype=bool)\n",
    "\n",
    "    out[\"alt_mode\"] = np.select(\n",
    "        [chg_active, chg_maint, chg_idle, dis_active],\n",
    "        [\"CHARGING_ACTIVE\", \"CHARGING_MAINTAIN\", \"CHARGING_IDLE\", \"DISCHARGING_ACTIVE\"],\n",
    "        default=\"DISCHARGING_IDLE\"\n",
    "    )\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 4. Delta + buckets (unchanged)\n",
    "    # ------------------------------------------------------------------\n",
    "    for col in [\"batt_maxtemp\", \"batt_mintemp\", \"batt_maxvolt\", \"batt_minvolt\"]:\n",
    "        if col in out.columns:\n",
    "            out[col] = pd.to_numeric(out[col], errors=\"coerce\")\n",
    "\n",
    "    out[\"batt_temp_delta\"] = out[\"batt_maxtemp\"] - out[\"batt_mintemp\"]\n",
    "    out[\"volt_delta_mv\"] = abs((out[\"batt_maxvolt\"] - out[\"batt_minvolt\"]) * 1000)  # absolute value since max < min can happen\n",
    "\n",
    "    out[\"date_val\"] = out[\"timestamp\"].dt.floor(\"D\")\n",
    "\n",
    "    # Bucketing\n",
    "    out[\"maxtemp_bucket\"] = pd.cut(\n",
    "        out[\"batt_maxtemp\"],\n",
    "        [-np.inf, 28, 32, 35, 40, np.inf],\n",
    "        labels=[\"<28\", \"28â€“32\", \"32â€“35\", \"35â€“40\", \">40\"]\n",
    "    )\n",
    "\n",
    "    out[\"temp_delta_bucket\"] = pd.cut(\n",
    "        out[\"batt_temp_delta\"],\n",
    "        [-np.inf, 2, 5, 8, np.inf],\n",
    "        labels=[\"<2\", \"2â€“5\", \"5â€“8\", \">8\"]\n",
    "    )\n",
    "\n",
    "    out[\"volt_delta_bucket\"] = pd.cut(\n",
    "        out[\"volt_delta_mv\"],\n",
    "        [0, 10, 20, 30, np.inf],\n",
    "        labels=[\"0â€“10\", \"10â€“20\", \"20â€“30\", \">30\"],\n",
    "        include_lowest=True\n",
    "    )\n",
    "\n",
    "    soc_bins = [0,10,20,30,40,50,60,70,80,90,np.inf]\n",
    "    soc_labels = [\"0â€“10\",\"10â€“20\",\"20â€“30\",\"30-40\",\"40-50\",\"50-60\",\"60-70\",\"70-80\",\"80-90\",\"90-100\"]\n",
    "\n",
    "    out[\"soc_band_bucket\"] = pd.cut(out[\"bat_soc\"], bins=soc_bins, labels=soc_labels)\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 5. Select final columns\n",
    "    # ------------------------------------------------------------------\n",
    "    cols_keep = [\n",
    "        \"id\",\"reg_num\",\"customer\",\"model\",\n",
    "        \"timestamp\",\"date_val\",\"dt_sec\",\n",
    "        \"mode\",\"alt_mode\",\n",
    "        \"ignitionstatus\",\"vehiclereadycondition\",\"gun_connection_status\",\n",
    "        \"vehicle_speed_vcu\",\"gear_position\",\n",
    "        \"odometerreading\",\"odometer_final\",\n",
    "        \"batt_maxtemp\",\"batt_mintemp\",\"batt_temp_delta\",\n",
    "        \"maxtemp_bucket\",\"temp_delta_bucket\",\n",
    "        \"batt_maxvolt\",\"batt_minvolt\",\"volt_delta_mv\",\"volt_delta_bucket\",\n",
    "        \"batt_maxtemp_tc\",\"batt_mintemp_tc\",\n",
    "        \"pack_id_max\",\"pack_id_min\",\n",
    "        \"batt_maxvolt_cell\",\"batt_minvolt_cell\",\n",
    "        \"bat_voltage\",\"total_battery_current\",\n",
    "        \"bat_soc\",\"soc_band_bucket\",\"soh\"\n",
    "    ]\n",
    "\n",
    "    cols_keep = [c for c in cols_keep if c in out.columns]\n",
    "    out = out[cols_keep]\n",
    "\n",
    "    return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e2e67c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- DUCKDB CHUNK GENERATOR (Fixed) ---\n",
    "\n",
    "def duckdb_chunk_generator(conn, sql_query, chunk_size):\n",
    "    \"\"\"Generates Pandas DataFrames in chunks directly from DuckDB cursor.\"\"\"\n",
    "    cursor = conn.cursor() \n",
    "    cursor.execute(sql_query)\n",
    "    \n",
    "    while True:\n",
    "        # Uses the corrected method name: fetch_df_chunk\n",
    "        chunk = cursor.fetch_df_chunk(chunk_size) \n",
    "        if chunk is None or chunk.empty:\n",
    "            break\n",
    "        yield chunk\n",
    "\n",
    "# --- ROBUST FILE EXTRACTION (Fixed from OSErrors) ---\n",
    "\n",
    "def extract_files_to_disk(zip_path, output_dir):\n",
    "    \"\"\"Cleans directory and extracts all Parquet files from ZIP.\"\"\"\n",
    "    if output_dir.exists():\n",
    "        logging.info(f\"ðŸ§¹ Clearing existing directory: {output_dir.resolve()}\")\n",
    "        # Robust cleanup to avoid OS/lock issues\n",
    "        try:\n",
    "            shutil.rmtree(output_dir)\n",
    "        except OSError:\n",
    "             for item in output_dir.iterdir():\n",
    "                if item.is_dir():\n",
    "                    shutil.rmtree(item)\n",
    "                else:\n",
    "                    os.remove(item) \n",
    "             os.rmdir(output_dir)\n",
    "\n",
    "    output_dir.mkdir(parents=True)\n",
    "        \n",
    "    logging.info(\"ðŸ”„ Extracting ALL Parquet files from ZIP to disk...\")\n",
    "    try:\n",
    "        with zipfile.ZipFile(zip_path, \"r\") as z:\n",
    "            all_files_to_extract = [f for f in z.namelist() if f.endswith(\".parquet\")]\n",
    "            logging.info(f\"ðŸ”Ž Found {len(all_files_to_extract)} total Parquet files in archive.\")\n",
    "            for filename in all_files_to_extract:\n",
    "                z.extract(filename, path=output_dir)\n",
    "            return len(all_files_to_extract)\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"âŒ ZIP file not found at: {zip_path}\") from None\n",
    "\n",
    "def setup_duckdb_query(output_dir, utc_start, utc_end, core_cols):\n",
    "    \"\"\"Sets up DuckDB connection and SQL query.\"\"\"\n",
    "    parquet_glob_path = str(output_dir.joinpath(\"**/*.parquet\"))\n",
    "    # Only select the columns you need for Stage 1 processing\n",
    "    column_list = \", \".join([f'\"{c}\"' for c in core_cols])\n",
    "    \n",
    "    # CRITICAL: Predicate Pushdown filter on the internal 'timestamp' column\n",
    "    sql_query = f\"\"\"\n",
    "        SELECT {column_list}\n",
    "        FROM read_parquet('{parquet_glob_path}')\n",
    "        WHERE \n",
    "            \"timestamp\" >= '{utc_start.isoformat()}' AND \n",
    "            \"timestamp\" < '{utc_end.isoformat()}'\n",
    "    \"\"\"\n",
    "    return duckdb.connect(), sql_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3dc1a962",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_stage1_data_setup(analysis_start_date_str: str, \n",
    "                          analysis_end_date_str: str, \n",
    "                          zip_path: Path, \n",
    "                          extraction_dir: Path,\n",
    "                          force_extraction: bool = False) -> tuple[datetime, datetime, int]:\n",
    "    \"\"\"\n",
    "    Handles date range setup, IST-to-UTC conversion, file extraction, \n",
    "    and checks if data is available for processing.\n",
    "    \n",
    "    Args:\n",
    "        analysis_start_date_str: Start date in YYYY-MM-DD format.\n",
    "        analysis_end_date_str: End date in YYYY-MM-DD format.\n",
    "        zip_path: Path to the source ZIP file.\n",
    "        extraction_dir: Target directory for extracted Parquet files.\n",
    "        force_extraction: If True, always clean and re-extract files. \n",
    "                          If False, skips extraction if the directory exists.\n",
    "    \n",
    "    Returns: (utc_start, utc_end, file_count)\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Date Parsing and UTC Conversion (Assuming +5:30 IST offset)\n",
    "    target_date = datetime.strptime(analysis_start_date_str, \"%Y-%m-%d\").date()\n",
    "    ist_start = datetime.combine(target_date, datetime.min.time())\n",
    "    \n",
    "    end_date_obj = datetime.strptime(analysis_end_date_str, \"%Y-%m-%d\").date()\n",
    "    ist_end = datetime.combine(end_date_obj, datetime.min.time()) + timedelta(days=1)\n",
    "    \n",
    "    utc_start = ist_start - timedelta(hours=5, minutes=30)\n",
    "    utc_end = ist_end - timedelta(hours=5, minutes=30)\n",
    "    \n",
    "    logging.info(f\"ðŸ” Analysis window (UTC): {utc_start} â†’ {utc_end}\")\n",
    "\n",
    "    # 2. FILE EXTRACTION CONTROL\n",
    "    file_count = 0\n",
    "    \n",
    "    if extraction_dir.exists() and not force_extraction:\n",
    "        logging.info(\"â™»ï¸ Skipping file extraction: Directory exists and force_extraction=False.\")\n",
    "        # Recursively count all .parquet files in the existing directory\n",
    "        file_count = len(list(extraction_dir.rglob('*.parquet')))\n",
    "        if file_count > 0:\n",
    "             logging.info(f\"âœ… Found {file_count} existing files. Proceeding to DuckDB loading.\")\n",
    "        \n",
    "    else:\n",
    "        # If directory doesn't exist, or force_extraction is True, run the full extraction.\n",
    "        logging.info(\"ðŸ”„ Running full extraction (Cleanup + Extract)...\")\n",
    "        # This relies on the robust `extract_files_to_disk` function\n",
    "        file_count = extract_files_to_disk(zip_path, extraction_dir)\n",
    "        \n",
    "    # 3. Validation Check\n",
    "    if file_count == 0:\n",
    "        logging.warning(\"ðŸ›‘ Skipping analysis: No files were found.\")\n",
    "        sys.exit() # Exit the script cleanly if no files were found\n",
    "\n",
    "    return utc_start, utc_end, file_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2aee4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-01 23:07:16 - INFO - ðŸ” Analysis window (UTC): 2025-08-31 18:30:00 â†’ 2025-11-15 18:30:00\n",
      "2025-12-01 23:07:16 - INFO - â™»ï¸ Skipping file extraction: Directory exists and force_extraction=False.\n",
      "2025-12-01 23:07:16 - INFO - âœ… Found 474 existing files. Proceeding to DuckDB loading.\n"
     ]
    }
   ],
   "source": [
    "# --- CONFIGURATION (Ensure these are defined at the top of your script) ---\n",
    "ZIP_FILE_PATH = \"../../../data_points/naarni75_cpoall.zip\" \n",
    "EXTRACTION_DIR = Path(\"../../../data_points/extracted_parts/cpo_all\") \n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "# --- Set 75-Day Date Range (Using your target dates) ---\n",
    "analysis_start_date_str = \"2025-09-01\" \n",
    "# NOTE: Using 2025-11-14 since 75 days starts on 2025-09-01 and ends on 2025-11-14.\n",
    "# Using 2025-11-15 will include the start of the 76th day (if data exists).\n",
    "analysis_end_date_str = \"2025-11-15\"   \n",
    "# --------------------------------------------------------\n",
    "\n",
    "# NEW STAGE 1 EXECUTION:\n",
    "utc_start, utc_end, file_count = run_stage1_data_setup(\n",
    "    analysis_start_date_str=analysis_start_date_str,\n",
    "    analysis_end_date_str=analysis_end_date_str,\n",
    "    zip_path=ZIP_FILE_PATH,\n",
    "    extraction_dir=EXTRACTION_DIR,\n",
    "    force_extraction = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b4e8cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-01 23:07:16 - INFO - âœ… Found 29 unique vehicle IDs in the dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '22', '24', '25', '26', '27', '28', '29', '3', '30', '31', '32', '33', '41', '42', '46', '6', '7', '9']\n"
     ]
    }
   ],
   "source": [
    "# 2. SETUP DUCKDB QUERY\n",
    "conn, sql_query = setup_duckdb_query(EXTRACTION_DIR, utc_start, utc_end, CORE_COLS)\n",
    "\n",
    "# A quick DuckDB query to get the distinct IDs from the 75-day filtered dataset\n",
    "get_ids_query = f\"\"\"\n",
    "    SELECT DISTINCT id \n",
    "    FROM ({sql_query})\n",
    "\"\"\"\n",
    "# Fetch the list of IDs (this is a very small amount of data)\n",
    "vehicle_ids = conn.execute(get_ids_query).fetchdf()[\"id\"].astype(str).tolist()\n",
    "# vehicle_ids = ['3','16','18','19','32','42','6','7','9','11','12','13','14','15','20','25','27','28','29','30','31','33','35','41','46']\n",
    "\n",
    "logging.info(f\"âœ… Found {len(vehicle_ids)} unique vehicle IDs in the dataset.\")\n",
    "print(sorted(vehicle_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa8a5298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: The functions 'duckdb_chunk_generator', 'rename_battery_temp_columns', \n",
    "# 'impute_missing_values', 'prepare_df_with_state', 'finalize_odometer', and 'free_mem' \n",
    "# MUST be defined in your Jupyter Notebook environment before calling this.\n",
    "\n",
    "def process_and_save_data(\n",
    "    conn: duckdb.DuckDBPyConnection, \n",
    "    sql_query: str, \n",
    "    chunk_size: int, \n",
    "    parquet_feather_path: str,\n",
    "    vehicle_ids: List[str],\n",
    "    df_mapping: pd.DataFrame,\n",
    "    extract_data: bool = False,\n",
    "    chunk_log_path: Optional[Union[str, Path]] = None,\n",
    ") -> int:\n",
    "    \"\"\"\n",
    "    Executes the memory-safe chunked processing loop for Stage 1.\n",
    "\n",
    "    MODIFIED (corrected odometer handling):\n",
    "      - Cross-chunk odometer continuity is tracked via last_known_odo.\n",
    "      - last_known_odo is now updated *after* finalize_odometer(), using\n",
    "        the finalized odometer_final values in df_chunk_state.\n",
    "      - This guarantees no backward odometer jumps across chunks.\n",
    "    \"\"\"\n",
    "\n",
    "    output_path = Path(parquet_feather_path)\n",
    "    # Cross-chunk odometer cache: {vehicle_id: last_valid_odometer_final}\n",
    "    last_known_odo: Dict[str, float] = {}\n",
    "\n",
    "    # -------------------------------------------------------\n",
    "    # SKIP IF FILE EXISTS\n",
    "    # -------------------------------------------------------\n",
    "    if not extract_data and output_path.exists():\n",
    "        conn_count = duckdb.connect()\n",
    "        try:\n",
    "            total_rows = conn_count.execute(\n",
    "                f\"SELECT count(*) FROM '{parquet_feather_path}'\"\n",
    "            ).fetchone()[0]\n",
    "            logging.info(f\"âœ… Skipping: File already exists with {total_rows:,} rows.\")\n",
    "            return total_rows\n",
    "        finally:\n",
    "            conn_count.close()\n",
    "\n",
    "    # -------------------------------------------------------\n",
    "    # INIT & PRE-CALCULATION\n",
    "    # -------------------------------------------------------\n",
    "    logging.info(f\"ðŸ§  Preparing data stream...\")\n",
    "\n",
    "    try:\n",
    "        total_input_rows = conn.execute(\n",
    "            f\"SELECT COUNT(*) FROM ({sql_query})\"\n",
    "        ).fetchone()[0]\n",
    "        logging.info(f\"ðŸ“Š Total rows to process: {total_input_rows:,}\")\n",
    "    except Exception as e:\n",
    "        logging.warning(\n",
    "            f\"Could not determine total row count: {e}. Progress bar will be indefinite.\"\n",
    "        )\n",
    "        total_input_rows = None\n",
    "\n",
    "    logging.info(f\"ðŸ’¾ Output path: {parquet_feather_path}\")\n",
    "\n",
    "    first_chunk = True\n",
    "    total_processed_rows = 0\n",
    "    chunk_index = 0\n",
    "\n",
    "    process = psutil.Process(os.getpid())\n",
    "    psutil.cpu_percent(interval=None)  # prime CPU sampling\n",
    "\n",
    "    # Chunk timing log setup\n",
    "    log_file = None\n",
    "    if chunk_log_path is not None:\n",
    "        log_file = Path(chunk_log_path)\n",
    "        if not log_file.exists():\n",
    "            with log_file.open(\"w\") as f:\n",
    "                f.write(\n",
    "                    \"timestamp,chunk_idx,chunk_rows,total_rows,\"\n",
    "                    \"duration_sec,rows_per_sec,cpu_pct,ram_mb\\n\"\n",
    "                )\n",
    "\n",
    "    # -------------------------------------------------------\n",
    "    # LOGGING SUPPRESSION\n",
    "    # -------------------------------------------------------\n",
    "    current_log_level = logging.getLogger().level\n",
    "    logging.getLogger().setLevel(logging.WARNING)\n",
    "\n",
    "    try:\n",
    "        # -------------------------------------------------------\n",
    "        # PROGRESS BAR\n",
    "        # -------------------------------------------------------\n",
    "        progress = tqdm(\n",
    "            total=total_input_rows,\n",
    "            desc=\"Processing Data\",\n",
    "            unit=\"row\",\n",
    "            mininterval=0.2,\n",
    "            dynamic_ncols=True,\n",
    "            colour=\"cyan\",\n",
    "        )\n",
    "\n",
    "        # -------------------------------------------------------\n",
    "        # MAIN LOOP: STREAM CHUNKS\n",
    "        # -------------------------------------------------------\n",
    "        for chunk in duckdb_chunk_generator(conn, sql_query, chunk_size):\n",
    "            t0 = time.perf_counter()\n",
    "            chunk_index += 1\n",
    "\n",
    "            raw_chunk_len = len(chunk)\n",
    "            df_chunk = chunk\n",
    "\n",
    "            # --- PREP 1: Rename ---\n",
    "            df_chunk = rename_battery_temp_columns(df_chunk)\n",
    "\n",
    "            df_chunk['vehicle_speed_vcu'] = df_chunk['vehicle_speed_vcu'].round(2)\n",
    "\n",
    "            # --- PREP 2: Filter & Cast ---\n",
    "            if \"id\" in df_chunk.columns:\n",
    "                df_chunk[\"id\"] = df_chunk[\"id\"].astype(str)\n",
    "                if vehicle_ids:\n",
    "                    df_chunk = df_chunk[df_chunk[\"id\"].isin(vehicle_ids)]\n",
    "                df_chunk = df_chunk.convert_dtypes()\n",
    "\n",
    "            # --- PREP 2b: Cross-chunk odometer continuity (odometerreading) ---\n",
    "            if \"odometerreading\" in df_chunk.columns:\n",
    "                for vid in df_chunk[\"id\"].unique():\n",
    "                    if vid in last_known_odo:\n",
    "                        first_idx = df_chunk[df_chunk[\"id\"] == vid].index.min()\n",
    "                        if pd.isna(df_chunk.loc[first_idx, \"odometerreading\"]):\n",
    "                            df_chunk.loc[first_idx, \"odometerreading\"] = last_known_odo[vid]\n",
    "\n",
    "            # --- PREP 3: Time & Impute ---\n",
    "            df_chunk[\"timestamp\"] = pd.to_datetime(df_chunk[\"timestamp\"], errors=\"coerce\")\n",
    "            df_chunk = df_chunk.sort_values([\"id\", \"timestamp\"]).copy()\n",
    "            df_chunk = impute_missing_values(df_chunk)\n",
    "            df_chunk = impute_odometer(df_chunk)\n",
    "\n",
    "            # # --- PREP 4: State Prep ---\n",
    "            df_chunk_state = prepare_df_with_state(df_chunk, df_mapping)\n",
    "\n",
    "            # --- PREP 4b: FINALIZE ODOMETER on state DataFrame ---\n",
    "            # This should enforce rounding + monotonicity.\n",
    "            df_chunk_state = finalize_odometer(df_chunk_state)\n",
    "\n",
    "            # --- PREP 4c: Update cross-chunk continuity AFTER finalization ---\n",
    "            if \"odometer_final\" in df_chunk_state.columns:\n",
    "                for vid, sub in df_chunk_state.groupby(\"id\"):\n",
    "                    sub_final = sub[\"odometer_final\"].dropna()\n",
    "                    if len(sub_final):\n",
    "                        # Use *finalized* odometer for continuity\n",
    "                        last_known_odo[vid] = float(sub_final.iloc[-1])\n",
    "\n",
    "            if df_chunk_state.empty:\n",
    "                progress.update(raw_chunk_len)\n",
    "                progress.set_postfix_str(\"Skipped empty chunk\")\n",
    "                del df_chunk, df_chunk_state\n",
    "                gc.collect()\n",
    "                free_mem()\n",
    "                continue\n",
    "\n",
    "            rows_saved_this_chunk = len(df_chunk_state)\n",
    "            total_processed_rows += rows_saved_this_chunk\n",
    "\n",
    "            # --- SAVE CHUNK ---\n",
    "            if first_chunk:\n",
    "                df_chunk_state.to_parquet(\n",
    "                    parquet_feather_path, compression=\"zstd\", index=False\n",
    "                )\n",
    "                first_chunk = False\n",
    "            else:\n",
    "                fastparquet.write(\n",
    "                    parquet_feather_path,\n",
    "                    df_chunk_state,\n",
    "                    compression=\"zstd\",\n",
    "                    write_index=False,\n",
    "                    append=True,\n",
    "                )\n",
    "\n",
    "            # --- METRICS ---\n",
    "            t1 = time.perf_counter()\n",
    "            duration = t1 - t0\n",
    "            rows_per_sec = rows_saved_this_chunk / duration if duration > 0 else 0\n",
    "            cpu_pct = psutil.cpu_percent(interval=None)\n",
    "            ram_mb = process.memory_info().rss / (1024 * 1024)\n",
    "\n",
    "            # --- UPDATE PROGRESS ---\n",
    "            progress.update(raw_chunk_len)\n",
    "            progress.set_postfix(\n",
    "                saved=f\"{total_processed_rows:,}\",\n",
    "                cpu=f\"{cpu_pct:4.1f}%\",\n",
    "                ram=f\"{ram_mb:6.1f}MB\",\n",
    "                speed=f\"{rows_per_sec:8.1f} r/s\",\n",
    "            )\n",
    "\n",
    "            # --- FILE LOGGING ---\n",
    "            if log_file is not None:\n",
    "                with log_file.open(\"a\") as f:\n",
    "                    f.write(\n",
    "                        f\"{datetime.now().isoformat()},{chunk_index},\"\n",
    "                        f\"{rows_saved_this_chunk},{total_processed_rows},\"\n",
    "                        f\"{duration:.3f},{rows_per_sec:.1f},\"\n",
    "                        f\"{cpu_pct:.1f},{ram_mb:.1f}\\n\"\n",
    "                    )\n",
    "\n",
    "            # --- CLEANUP ---\n",
    "            del df_chunk, df_chunk_state\n",
    "            gc.collect()\n",
    "            free_mem()\n",
    "\n",
    "    finally:\n",
    "        if \"progress\" in locals():\n",
    "            progress.close()\n",
    "\n",
    "        logging.getLogger().setLevel(current_log_level)\n",
    "        conn.close()\n",
    "\n",
    "    logging.info(f\"âœ… Finished processing. Total rows saved: {total_processed_rows:,}\")\n",
    "    return total_processed_rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "122a454a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-01 23:07:16 - INFO - âœ… Skipping: File already exists with 52,888,998 rows.\n",
      "2025-12-01 23:07:16 - INFO - ðŸŽ‰ Final DataFrame saved. Total rows processed: 52,888,998\n",
      "2025-12-01 23:07:16 - INFO - âœ… Data Processing (Stage 1) complete. Feather file ready for analysis.\n"
     ]
    }
   ],
   "source": [
    "# --- ASSUMING run_stage1_data_setup WAS CALLED AND RETURNED utc_start, utc_end ---\n",
    "# Example configuration that needs to be available:\n",
    "# EXTRACTION_DIR = Path(\"../extracted_parts\") \n",
    "# CORE_COLS = [...]\n",
    "# CRITICAL FIX: Drastically reduced chunk size to prevent memory spike\n",
    "CHUNK_SIZE = 500 # Process 50,000 rows max at any time\n",
    "\n",
    "\n",
    "# 1. Setup DuckDB Query (as shown previously)\n",
    "conn, sql_query = setup_duckdb_query(EXTRACTION_DIR, utc_start, utc_end, CORE_COLS)\n",
    "\n",
    "# 2. Define Inputs\n",
    "# output_feather_file = \"df_with_state_30days.feather\"\n",
    "output_parquet_file = \"../df_with_state.parquet\"\n",
    "\n",
    "# 3. Run the memory-safe processing loop\n",
    "total_rows = process_and_save_data(\n",
    "    conn=conn,\n",
    "    sql_query=sql_query,\n",
    "    chunk_size=CHUNK_SIZE,\n",
    "    parquet_feather_path=output_parquet_file,\n",
    "    vehicle_ids=vehicle_ids,\n",
    "    df_mapping=df_mapping,\n",
    "    extract_data=False\n",
    ")\n",
    "\n",
    "logging.info(f\"ðŸŽ‰ Final DataFrame saved. Total rows processed: {total_rows:,}\")\n",
    "logging.info(\"âœ… Data Processing (Stage 1) complete. Feather file ready for analysis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d803154e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_parquet_subset(parquet_path: str, start_dt: datetime, end_dt: datetime) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reads a subset of the processed Feather file using a date filter\n",
    "    applied directly by DuckDB (predicate pushdown).\n",
    "    \n",
    "    Args:\n",
    "        feather_path: Path to the processed Feather file.\n",
    "        start_dt: Start datetime for the filter (inclusive).\n",
    "        end_dt: End datetime for the filter (exclusive).\n",
    "        \n",
    "    Returns:\n",
    "        A new DataFrame containing only the filtered data.\n",
    "    \"\"\"\n",
    "    logging.info(f\"Loading data subset from {start_dt} to {end_dt}...\")\n",
    "    \n",
    "    # Use DuckDB to query the Feather file directly on disk\n",
    "    con = duckdb.connect()\n",
    "    \n",
    "    # The SQL query filters rows on the disk file based on the 'timestamp' column.\n",
    "    sql_query = f\"\"\"\n",
    "        SELECT *\n",
    "        FROM read_parquet('{parquet_path}')\n",
    "        WHERE \n",
    "            \"timestamp\" >= '{start_dt.isoformat()}' AND \n",
    "            \"timestamp\" < '{end_dt.isoformat()}'        \n",
    "    \"\"\"\n",
    "    # AND \"id\" IN ('16')\n",
    "\n",
    "    # Fetch the filtered, smaller DataFrame\n",
    "    df_subset = con.execute(sql_query).fetchdf()\n",
    "    con.close()\n",
    "    \n",
    "    logging.info(f\"âœ… Loaded {len(df_subset):,} rows for the requested subset.\")\n",
    "    return df_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a52164d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-01 23:07:16 - INFO - Loading data subset from 2025-09-01 00:00:00 to 2025-09-02 00:00:00...\n",
      "2025-12-01 23:07:17 - INFO - âœ… Loaded 155,729 rows for the requested subset.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>reg_num</th>\n",
       "      <th>customer</th>\n",
       "      <th>model</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>date_val</th>\n",
       "      <th>dt_sec</th>\n",
       "      <th>mode</th>\n",
       "      <th>alt_mode</th>\n",
       "      <th>ignitionstatus</th>\n",
       "      <th>vehiclereadycondition</th>\n",
       "      <th>gun_connection_status</th>\n",
       "      <th>vehicle_speed_vcu</th>\n",
       "      <th>gear_position</th>\n",
       "      <th>odometerreading</th>\n",
       "      <th>odometer_final</th>\n",
       "      <th>batt_maxtemp</th>\n",
       "      <th>batt_mintemp</th>\n",
       "      <th>batt_temp_delta</th>\n",
       "      <th>maxtemp_bucket</th>\n",
       "      <th>temp_delta_bucket</th>\n",
       "      <th>batt_maxvolt</th>\n",
       "      <th>batt_minvolt</th>\n",
       "      <th>volt_delta_mv</th>\n",
       "      <th>volt_delta_bucket</th>\n",
       "      <th>batt_maxtemp_tc</th>\n",
       "      <th>batt_mintemp_tc</th>\n",
       "      <th>batt_maxvolt_cell</th>\n",
       "      <th>batt_minvolt_cell</th>\n",
       "      <th>bat_voltage</th>\n",
       "      <th>total_battery_current</th>\n",
       "      <th>bat_soc</th>\n",
       "      <th>soc_band_bucket</th>\n",
       "      <th>soh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>HR55AY9237</td>\n",
       "      <td>ZB Gurgaon</td>\n",
       "      <td>12.5</td>\n",
       "      <td>2025-09-01 05:30:00.937</td>\n",
       "      <td>2025-09-01</td>\n",
       "      <td>0.000</td>\n",
       "      <td>DISCHARGING</td>\n",
       "      <td>DISCHARGING_IDLE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8679.0</td>\n",
       "      <td>8679.0</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;28</td>\n",
       "      <td>&lt;2</td>\n",
       "      <td>3.288</td>\n",
       "      <td>3.278</td>\n",
       "      <td>9.99999</td>\n",
       "      <td>0â€“10</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>374</td>\n",
       "      <td>480</td>\n",
       "      <td>525.0</td>\n",
       "      <td>72.800003</td>\n",
       "      <td>33.200001</td>\n",
       "      <td>30-40</td>\n",
       "      <td>99.599998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>HR55AY9237</td>\n",
       "      <td>ZB Gurgaon</td>\n",
       "      <td>12.5</td>\n",
       "      <td>2025-09-01 05:30:02.016</td>\n",
       "      <td>2025-09-01</td>\n",
       "      <td>1.079</td>\n",
       "      <td>DISCHARGING</td>\n",
       "      <td>DISCHARGING_IDLE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8679.0</td>\n",
       "      <td>8679.0</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;28</td>\n",
       "      <td>&lt;2</td>\n",
       "      <td>3.288</td>\n",
       "      <td>3.278</td>\n",
       "      <td>9.99999</td>\n",
       "      <td>0â€“10</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>374</td>\n",
       "      <td>480</td>\n",
       "      <td>525.0</td>\n",
       "      <td>72.800003</td>\n",
       "      <td>33.200001</td>\n",
       "      <td>30-40</td>\n",
       "      <td>99.599998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>HR55AY9237</td>\n",
       "      <td>ZB Gurgaon</td>\n",
       "      <td>12.5</td>\n",
       "      <td>2025-09-01 05:30:03.116</td>\n",
       "      <td>2025-09-01</td>\n",
       "      <td>1.100</td>\n",
       "      <td>DISCHARGING</td>\n",
       "      <td>DISCHARGING_IDLE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8679.0</td>\n",
       "      <td>8679.0</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;28</td>\n",
       "      <td>&lt;2</td>\n",
       "      <td>3.288</td>\n",
       "      <td>3.278</td>\n",
       "      <td>9.99999</td>\n",
       "      <td>0â€“10</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>374</td>\n",
       "      <td>480</td>\n",
       "      <td>525.0</td>\n",
       "      <td>72.800003</td>\n",
       "      <td>33.200001</td>\n",
       "      <td>30-40</td>\n",
       "      <td>99.599998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>HR55AY9237</td>\n",
       "      <td>ZB Gurgaon</td>\n",
       "      <td>12.5</td>\n",
       "      <td>2025-09-01 05:30:04.196</td>\n",
       "      <td>2025-09-01</td>\n",
       "      <td>1.080</td>\n",
       "      <td>DISCHARGING</td>\n",
       "      <td>DISCHARGING_IDLE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8679.0</td>\n",
       "      <td>8679.0</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;28</td>\n",
       "      <td>&lt;2</td>\n",
       "      <td>3.288</td>\n",
       "      <td>3.278</td>\n",
       "      <td>9.99999</td>\n",
       "      <td>0â€“10</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>374</td>\n",
       "      <td>480</td>\n",
       "      <td>525.0</td>\n",
       "      <td>72.800003</td>\n",
       "      <td>33.200001</td>\n",
       "      <td>30-40</td>\n",
       "      <td>99.599998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>HR55AY9237</td>\n",
       "      <td>ZB Gurgaon</td>\n",
       "      <td>12.5</td>\n",
       "      <td>2025-09-01 05:30:05.256</td>\n",
       "      <td>2025-09-01</td>\n",
       "      <td>1.060</td>\n",
       "      <td>DISCHARGING</td>\n",
       "      <td>DISCHARGING_IDLE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8679.0</td>\n",
       "      <td>8679.0</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;28</td>\n",
       "      <td>&lt;2</td>\n",
       "      <td>3.288</td>\n",
       "      <td>3.278</td>\n",
       "      <td>9.99999</td>\n",
       "      <td>0â€“10</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>374</td>\n",
       "      <td>480</td>\n",
       "      <td>525.0</td>\n",
       "      <td>72.800003</td>\n",
       "      <td>33.200001</td>\n",
       "      <td>30-40</td>\n",
       "      <td>99.599998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     reg_num    customer model               timestamp   date_val  \\\n",
       "0  16  HR55AY9237  ZB Gurgaon  12.5 2025-09-01 05:30:00.937 2025-09-01   \n",
       "1  16  HR55AY9237  ZB Gurgaon  12.5 2025-09-01 05:30:02.016 2025-09-01   \n",
       "2  16  HR55AY9237  ZB Gurgaon  12.5 2025-09-01 05:30:03.116 2025-09-01   \n",
       "3  16  HR55AY9237  ZB Gurgaon  12.5 2025-09-01 05:30:04.196 2025-09-01   \n",
       "4  16  HR55AY9237  ZB Gurgaon  12.5 2025-09-01 05:30:05.256 2025-09-01   \n",
       "\n",
       "   dt_sec         mode          alt_mode  ignitionstatus  \\\n",
       "0   0.000  DISCHARGING  DISCHARGING_IDLE               0   \n",
       "1   1.079  DISCHARGING  DISCHARGING_IDLE               0   \n",
       "2   1.100  DISCHARGING  DISCHARGING_IDLE               0   \n",
       "3   1.080  DISCHARGING  DISCHARGING_IDLE               0   \n",
       "4   1.060  DISCHARGING  DISCHARGING_IDLE               0   \n",
       "\n",
       "   vehiclereadycondition  gun_connection_status  vehicle_speed_vcu  \\\n",
       "0                      0                      0                0.0   \n",
       "1                      0                      0                0.0   \n",
       "2                      0                      0                0.0   \n",
       "3                      0                      0                0.0   \n",
       "4                      0                      0                0.0   \n",
       "\n",
       "   gear_position  odometerreading  odometer_final  batt_maxtemp  batt_mintemp  \\\n",
       "0              0           8679.0          8679.0            28            27   \n",
       "1              0           8679.0          8679.0            28            27   \n",
       "2              0           8679.0          8679.0            28            27   \n",
       "3              0           8679.0          8679.0            28            27   \n",
       "4              0           8679.0          8679.0            28            27   \n",
       "\n",
       "   batt_temp_delta maxtemp_bucket temp_delta_bucket  batt_maxvolt  \\\n",
       "0                1            <28                <2         3.288   \n",
       "1                1            <28                <2         3.288   \n",
       "2                1            <28                <2         3.288   \n",
       "3                1            <28                <2         3.288   \n",
       "4                1            <28                <2         3.288   \n",
       "\n",
       "   batt_minvolt  volt_delta_mv volt_delta_bucket  batt_maxtemp_tc  \\\n",
       "0         3.278        9.99999              0â€“10                3   \n",
       "1         3.278        9.99999              0â€“10                3   \n",
       "2         3.278        9.99999              0â€“10                3   \n",
       "3         3.278        9.99999              0â€“10                3   \n",
       "4         3.278        9.99999              0â€“10                3   \n",
       "\n",
       "   batt_mintemp_tc  batt_maxvolt_cell  batt_minvolt_cell  bat_voltage  \\\n",
       "0                9                374                480        525.0   \n",
       "1                9                374                480        525.0   \n",
       "2                9                374                480        525.0   \n",
       "3                9                374                480        525.0   \n",
       "4                9                374                480        525.0   \n",
       "\n",
       "   total_battery_current    bat_soc soc_band_bucket        soh  \n",
       "0              72.800003  33.200001           30-40  99.599998  \n",
       "1              72.800003  33.200001           30-40  99.599998  \n",
       "2              72.800003  33.200001           30-40  99.599998  \n",
       "3              72.800003  33.200001           30-40  99.599998  \n",
       "4              72.800003  33.200001           30-40  99.599998  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(Timestamp('2025-09-01 05:30:00.937000'),\n",
       " Timestamp('2025-09-01 23:59:59.826000'))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the 30-day filter window\n",
    "filter_start_date = datetime(2025, 9, 1)\n",
    "filter_end_date = datetime(2025, 9, 2) # Exclusive end date\n",
    "\n",
    "# 1. Load the filtered subset safely\n",
    "df_subset = read_parquet_subset(\n",
    "    parquet_path=\"../df_with_state.parquet\",\n",
    "    start_dt=filter_start_date,\n",
    "    end_dt=filter_end_date\n",
    ")\n",
    "\n",
    "# # 2. Sort the data by vehicle ID and timestamp\n",
    "# # This is CRUCIAL for the cumulative maximum to work correctly for each vehicle.\n",
    "df_subset = df_subset.sort_values(by=['id', 'timestamp']).reset_index(drop=True)\n",
    "\n",
    "# # 3. Apply the cumulative maximum, GROUPED BY 'id'\n",
    "# # This enforces monotonicity (non-decreasing readings) for the odometer.\n",
    "df_subset['odometer_final'] = df_subset.groupby('id')['odometer_final'].cummax()\n",
    "\n",
    "display(df_subset.head())\n",
    "\n",
    "# 3. Aggressive memory cleanup after use (CRITICAL)\n",
    "# del df_subset\n",
    "# gc.collect()\n",
    "# free_mem()\n",
    "\n",
    "\n",
    "df_subset.timestamp.min(),df_subset.timestamp.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24e9f13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_subset.bat_soc.describe(percentiles=[0.005,0.01,0.05,0.1,0.25,0.5,0.75,0.9,0.95,0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6fbd9813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                           0\n",
       "reg_num                      0\n",
       "customer                     0\n",
       "model                        0\n",
       "timestamp                    0\n",
       "date_val                     0\n",
       "dt_sec                       0\n",
       "mode                         0\n",
       "alt_mode                     0\n",
       "ignitionstatus               0\n",
       "vehiclereadycondition        0\n",
       "gun_connection_status        0\n",
       "vehicle_speed_vcu            0\n",
       "gear_position                0\n",
       "odometerreading          31288\n",
       "odometer_final               0\n",
       "batt_maxtemp                 0\n",
       "batt_mintemp                 0\n",
       "batt_temp_delta              0\n",
       "maxtemp_bucket               0\n",
       "temp_delta_bucket            0\n",
       "batt_maxvolt                 0\n",
       "batt_minvolt                 0\n",
       "volt_delta_mv                0\n",
       "volt_delta_bucket            0\n",
       "batt_maxtemp_tc              0\n",
       "batt_mintemp_tc              0\n",
       "batt_maxvolt_cell            0\n",
       "batt_minvolt_cell            0\n",
       "bat_voltage                  0\n",
       "total_battery_current        0\n",
       "bat_soc                      0\n",
       "soc_band_bucket              0\n",
       "soh                          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_subset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "114457db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     53959.000000\n",
       "mean          0.008430\n",
       "std           0.035243\n",
       "min           0.000000\n",
       "0.1%          0.000000\n",
       "1%            0.000000\n",
       "25%           0.000000\n",
       "50%           0.000000\n",
       "75%           0.000000\n",
       "90%           0.010000\n",
       "95%           0.103000\n",
       "99%           0.125000\n",
       "99.95%        0.354000\n",
       "max           3.500000\n",
       "Name: odometer_final, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_subset[df_subset.id == '16'].odometer_final.diff().describe(percentiles=[0.001,0.01,0.25,0.5,0.75,0.9,0.95,0.99,0.9995])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f0cccff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>odometerreading</th>\n",
       "      <th>odometer_final</th>\n",
       "      <th>vehicle_speed_vcu</th>\n",
       "      <th>dt_sec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [timestamp, odometerreading, odometer_final, vehicle_speed_vcu, dt_sec]\n",
       "Index: []"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df16 = df_subset[df_subset.id == '16'].copy()\n",
    "df16 = df16.reset_index(drop=True)  # CRITICAL FIX\n",
    "\n",
    "# find raw negative diffs\n",
    "neg_idx = df16.index[df16[\"odometer_final\"].diff() >110]\n",
    "\n",
    "# Build Â±2 context window\n",
    "context_idx = (\n",
    "    set(neg_idx - 3)\n",
    "    | set(neg_idx - 2)\n",
    "    | set(neg_idx - 1)\n",
    "    | set(neg_idx)\n",
    "    | set(neg_idx + 1)\n",
    "    | set(neg_idx + 2)\n",
    ")\n",
    "\n",
    "# Keep only valid iloc rows\n",
    "context_idx = [i for i in context_idx if 0 <= i < len(df16)]\n",
    "\n",
    "# Show the window\n",
    "df16.iloc[context_idx][[\n",
    "    \"timestamp\",\n",
    "    \"odometerreading\",\n",
    "    \"odometer_final\",\n",
    "    \"vehicle_speed_vcu\",\n",
    "    \"dt_sec\"\n",
    "]].sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e3de2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df16.iloc[context_idx][[\n",
    "    \"timestamp\",\n",
    "    \"odometerreading\",\n",
    "    \"odometer_final\",\n",
    "    \"vehicle_speed_vcu\",\n",
    "    \"dt_sec\"\n",
    "]].sort_index().to_csv(\"df16_negative_odo_context.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1ccd6171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "alt_mode\n",
       "DISCHARGING_ACTIVE    73159\n",
       "DISCHARGING_IDLE      58875\n",
       "CHARGING_ACTIVE       22152\n",
       "CHARGING_MAINTAIN       952\n",
       "CHARGING_IDLE           591\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_subset.alt_mode.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8c9738e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_subset['timestamp'] = pd.to_datetime(df_subset['timestamp'], utc=True)\n",
    "# df_subset = df_subset.sort_values(by=['id', 'timestamp']).reset_index(drop=True)\n",
    "# df_subset['odometer_final'] = df_subset.groupby('id')['odometer_final'].cummax()\n",
    "# df_subset.volt_delta_mv.describe(percentiles=[0.9,0.95,0.9992])\n",
    "# df_subset[df_subset.batt_mintemp>-40].batt_mintemp.describe()\n",
    "# len(df_subset[(df_subset.odometer_final.isnull())&(df_subset.vehicle_speed_vcu>1)])\n",
    "# len(df_subset[df_subset.dt_sec==0])\n",
    "# df_subset[(df_subset.odometer_final.isnull())]#.vehicle_speed_vcu.describe()\n",
    "# df_subset[['timestamp','vehicle_speed_vcu','gear_position','odometerreading','odometer_final']].isnull().sum()*100.0/len(df_subset)\n",
    "# missing = df_subset[df_subset.odometer_final.isna()]\n",
    "# print(\"Total missing:\", len(missing))\n",
    "# print(missing[['timestamp','vehicle_speed_vcu','dt_sec','odometerreading']].head(20))\n",
    "# print(\"Speed null %:\", missing.vehicle_speed_vcu.isna().mean()*100)\n",
    "# print(\"dt null %:\", missing.dt_sec.isna().mean()*100)\n",
    "# df_subset[(df_subset.vehiclereadycondition == 0)&(df_subset.gun_connection_status == 1)]\n",
    "# df_subset[(df_subset.alt_mode=='CHARGING')&(df_subset.total_battery_current<-5)].total_battery_current.describe(percentiles=[0.7,0.8,0.9,0.95,0.98,0.99,0.999])\n",
    "# df_subset.groupby(['id','date_val','alt_mode'])['alt_mode'].count()\n",
    "# display(df_subset[(df_subset.mode=='CHARGING')&(df_subset.vehiclereadycondition=='1')&(df_subset.gun_connection_status=='1')].head(100))\n",
    "# df_subset.volt_delta_mv.max()\n",
    "# df_subset.total_battery_current[df_subset.total_battery_current>-3200].min()\n",
    "# pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "# pd.reset_option('display.float_format')\n",
    "# df_subset.head(1000).to_csv('data_ref.csv')\n",
    "# df_subset[df_subset.dt_sec>1].dt_sec.describe(percentiles=[0.9,0.95,0.99,0.995,0.997]).round(2)\n",
    "# df_subset.groupby(['id','date_val'])['dt_sec'].sum()/60.0\n",
    "\n",
    "# # chk = ((df_subset.groupby(['date_val','mode','batt_maxtemp_tc','pack_id_max'])['dt_sec'].sum()*100.0/60.0)/(df_subset.groupby(['date_val'])['dt_sec'].sum()/60.0)).sort_values()\n",
    "# chk = (\n",
    "#         (df_subset[df_subset['mode'] == 'CHARGING'].groupby(['date_val','mode','batt_maxtemp_tc','pack_id_max'])['dt_sec'].sum()*100.0/60.0) / \n",
    "#         (df_subset[df_subset['mode'] == 'CHARGING'].groupby(['date_val'])['dt_sec'].sum()/60.0)\n",
    "#       ).sort_index(level='batt_maxtemp_tc')\n",
    "# display(chk)\n",
    "\n",
    "\n",
    "# # chk = ((df_subset.groupby(['date_val','mode','batt_maxtemp_tc','pack_id_max'])['dt_sec'].sum()*100.0/60.0)/(df_subset.groupby(['date_val'])['dt_sec'].sum()/60.0)).sort_values()\n",
    "# chk2 = (\n",
    "#         (df_subset[df_subset['mode'] == 'CHARGING'].groupby(['date_val','mode','batt_maxtemp_tc','pack_id_max'])['dt_sec'].sum()/60.0)).sort_index(level='batt_maxtemp_tc')\n",
    "# display(chk2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e16711d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How close two charging blocks can be and still count as one session\n",
    "CHARGING_GAP_MERGE_MIN = 15.0   # minutes\n",
    "SPEED_MOTION_THRESHOLD = 0.5   # km/h, for motion_pct\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def _get_charging_mask(df_vid: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Returns a boolean Series marking rows that belong to a *charging envelope*.\n",
    "\n",
    "    Priority:\n",
    "      1) If 'alt_mode' exists:\n",
    "           any alt_mode starting with 'CHARGING'\n",
    "           (CHARGING_ACTIVE / CHARGING_MAINTAIN / CHARGING_IDLE)\n",
    "           is treated as charging.\n",
    "      2) Else if 'mode' exists:\n",
    "           mode == 'CHARGING'.\n",
    "      3) Else: fall back to gun_connection_status / current-based heuristic.\n",
    "    \"\"\"\n",
    "    df_vid = df_vid.copy()\n",
    "\n",
    "    # --- Preferred: multi-state alt_mode ---\n",
    "    if \"alt_mode\" in df_vid.columns:\n",
    "        return df_vid[\"alt_mode\"].astype(str).str.startswith(\"CHARGING\")\n",
    "\n",
    "    # --- Fallback: simple mode ---\n",
    "    if \"mode\" in df_vid.columns:\n",
    "        return df_vid[\"mode\"].astype(str).str.upper() == \"CHARGING\"\n",
    "\n",
    "    # --- Last resort: gun + current heuristic ---\n",
    "    gun = pd.Series(False, index=df_vid.index)\n",
    "    if \"gun_connection_status\" in df_vid.columns:\n",
    "        g = df_vid[\"gun_connection_status\"]\n",
    "        g_num = pd.to_numeric(g, errors=\"coerce\")\n",
    "        g_str = g.astype(str).str.strip().str.lower()\n",
    "        gun = (g_num == 1) | g_str.isin({\"1\", \"true\", \"yes\", \"y\", \"connected\", \"on\"})\n",
    "        gun = gun.fillna(False)\n",
    "\n",
    "    if \"total_battery_current\" in df_vid.columns:\n",
    "        cur = pd.to_numeric(df_vid[\"total_battery_current\"], errors=\"coerce\")\n",
    "        cur_cond = (cur < -5).fillna(False)\n",
    "    else:\n",
    "        cur_cond = pd.Series(False, index=df_vid.index)\n",
    "\n",
    "    return gun | cur_cond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0b3a43d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _build_charging_sessions_for_vehicle(df_vid: pd.DataFrame) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Builds stitched CHARGING envelopes for a single vehicle.\n",
    "\n",
    "    A charging envelope is any contiguous region where _get_charging_mask() is True,\n",
    "    with gaps â‰¤ CHARGING_GAP_MERGE_MIN minutes merged into a single session.\n",
    "\n",
    "    Returns a list of dicts:\n",
    "        { 'start_idx', 'end_idx', 'start_time', 'end_time' }\n",
    "    \"\"\"\n",
    "    df_vid = df_vid.sort_values(\"timestamp\").reset_index(drop=True)\n",
    "    is_chg = _get_charging_mask(df_vid)\n",
    "\n",
    "    if not is_chg.any():\n",
    "        return []\n",
    "\n",
    "    tmp = df_vid.copy()\n",
    "    tmp[\"is_chg\"] = is_chg\n",
    "    tmp[\"chg_block\"] = tmp[\"is_chg\"].ne(tmp[\"is_chg\"].shift()).cumsum()\n",
    "\n",
    "    raw_blocks: list[dict] = []\n",
    "    for block_id, g in tmp.groupby(\"chg_block\", sort=True):\n",
    "        # skip non-charging blocks\n",
    "        if not g[\"is_chg\"].iloc[0]:\n",
    "            continue\n",
    "\n",
    "        start_idx = int(g.index[0])\n",
    "        end_idx   = int(g.index[-1])\n",
    "\n",
    "        raw_blocks.append(\n",
    "            {\n",
    "                \"start_idx\": start_idx,\n",
    "                \"end_idx\": end_idx,\n",
    "                \"start_time\": df_vid.loc[start_idx, \"timestamp\"],\n",
    "                \"end_time\":   df_vid.loc[end_idx,   \"timestamp\"],\n",
    "            }\n",
    "        )\n",
    "\n",
    "    if not raw_blocks:\n",
    "        return []\n",
    "\n",
    "    raw_blocks.sort(key=lambda b: b[\"start_idx\"])\n",
    "\n",
    "    stitched: list[dict] = []\n",
    "    current = raw_blocks[0].copy()\n",
    "\n",
    "    for nxt in raw_blocks[1:]:\n",
    "        gap_min = (nxt[\"start_time\"] - current[\"end_time\"]).total_seconds() / 60.0\n",
    "        if gap_min <= CHARGING_GAP_MERGE_MIN:\n",
    "            # merge into current envelope\n",
    "            current[\"end_idx\"] = nxt[\"end_idx\"]\n",
    "            current[\"end_time\"] = nxt[\"end_time\"]\n",
    "        else:\n",
    "            stitched.append(current)\n",
    "            current = nxt.copy()\n",
    "\n",
    "    stitched.append(current)\n",
    "    return stitched\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "db31800b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_session_metrics(seg: pd.DataFrame) -> dict:\n",
    "    \"\"\"\n",
    "    Given a contiguous segment (one session) for a single vehicle,\n",
    "    compute all requested metrics.\n",
    "    \"\"\"\n",
    "    seg = seg.copy()\n",
    "    seg = seg.sort_values(\"timestamp\")\n",
    "\n",
    "    if len(seg) < 2:\n",
    "        return None\n",
    "\n",
    "    # --- time deltas ---\n",
    "    seg[\"dt\"] = seg[\"timestamp\"].diff().dt.total_seconds().fillna(0)\n",
    "    # For safety: zero-out first dt so we don't pull in time before the session\n",
    "    seg.iloc[0, seg.columns.get_loc(\"dt\")] = 0.0\n",
    "\n",
    "    total_time = seg[\"dt\"].sum()\n",
    "    if total_time <= 0:\n",
    "        total_time = (seg[\"timestamp\"].iloc[-1] - seg[\"timestamp\"].iloc[0]).total_seconds()\n",
    "\n",
    "    # --- base metadata ---\n",
    "    id_val = seg[\"id\"].iloc[0]\n",
    "    reg_num = seg[\"reg_num\"].dropna().iloc[0] if \"reg_num\" in seg.columns and seg[\"reg_num\"].notna().any() else None\n",
    "    customer = seg[\"customer\"].dropna().iloc[0] if \"customer\" in seg.columns and seg[\"customer\"].notna().any() else None\n",
    "    model = seg[\"model\"].dropna().iloc[0] if \"model\" in seg.columns and seg[\"model\"].notna().any() else None\n",
    "\n",
    "    start_time = seg[\"timestamp\"].iloc[0]\n",
    "    end_time = seg[\"timestamp\"].iloc[-1]\n",
    "    duration_mins = round((end_time - start_time).total_seconds() / 60.0, 2)\n",
    "\n",
    "    # --- energy integration ---\n",
    "    # Ensure numeric\n",
    "    seg[\"bat_voltage\"] = pd.to_numeric(seg.get(\"bat_voltage\"), errors=\"coerce\")\n",
    "    seg[\"total_battery_current\"] = pd.to_numeric(seg.get(\"total_battery_current\"), errors=\"coerce\")\n",
    "\n",
    "    # kW\n",
    "    seg[\"power_kw\"] = (seg[\"bat_voltage\"] * seg[\"total_battery_current\"]) / 1000.0\n",
    "\n",
    "    # kWh components (sign-aware)\n",
    "    # charging (I < 0) â†’ energy INTO pack\n",
    "    mask_chg = seg[\"total_battery_current\"] < 0\n",
    "    mask_dis = seg[\"total_battery_current\"] > 0\n",
    "\n",
    "    seg[\"energy_kwh_chg\"] = 0.0\n",
    "    seg.loc[mask_chg, \"energy_kwh_chg\"] = -seg.loc[mask_chg, \"power_kw\"] * seg.loc[mask_chg, \"dt\"] / 3600.0\n",
    "\n",
    "    seg[\"energy_kwh_dis\"] = 0.0\n",
    "    seg.loc[mask_dis, \"energy_kwh_dis\"] = seg.loc[mask_dis, \"power_kw\"] * seg.loc[mask_dis, \"dt\"] / 3600.0\n",
    "\n",
    "    kwh_charging = round(seg[\"energy_kwh_chg\"].sum(), 2)\n",
    "    kwh_discharging = round(seg[\"energy_kwh_dis\"].sum(), 2)\n",
    "\n",
    "    # --- SOC metrics ---\n",
    "    soc_col = \"bat_soc\" if \"bat_soc\" in seg.columns else None\n",
    "    soc_start = soc_end = soc_gain = soc_drop = None\n",
    "    if soc_col:\n",
    "        soc_valid = seg[soc_col].dropna()\n",
    "        if not soc_valid.empty:\n",
    "            soc_start = soc_valid.iloc[0]\n",
    "            soc_end = soc_valid.iloc[-1]\n",
    "            soc_gain = max(soc_end - soc_start, 0)\n",
    "            soc_drop = max(soc_start - soc_end, 0)\n",
    "\n",
    "    # --- percentage metrics (time-weighted) ---\n",
    "    def pct(mask: pd.Series) -> float:\n",
    "        if total_time <= 0:\n",
    "            return 0.0\n",
    "        return round(100.0 * seg.loc[mask, \"dt\"].sum() / total_time, 2)\n",
    "\n",
    "    # charging / discharging % by current sign\n",
    "    charging_pct = pct(mask_chg)\n",
    "    discharging_pct = pct(mask_dis)\n",
    "\n",
    "    # motion_pct: vehicle_speed_vcu > SPEED_MOTION_THRESHOLD\n",
    "    if \"vehicle_speed_vcu\" in seg.columns:\n",
    "        speed = pd.to_numeric(seg[\"vehicle_speed_vcu\"], errors=\"coerce\")\n",
    "        motion_pct = pct(speed > SPEED_MOTION_THRESHOLD)\n",
    "    else:\n",
    "        motion_pct = np.nan\n",
    "\n",
    "    # lv_pct and off_pct\n",
    "    if all(col in seg.columns for col in [\"ignitionstatus\", \"gun_connection_status\", \"vehiclereadycondition\"]):\n",
    "        ign = pd.to_numeric(seg[\"ignitionstatus\"], errors=\"coerce\")\n",
    "        gun = pd.to_numeric(seg[\"gun_connection_status\"], errors=\"coerce\")\n",
    "        ready = pd.to_numeric(seg[\"vehiclereadycondition\"], errors=\"coerce\")\n",
    "\n",
    "        lv_mask = (ign == 1) & (gun == 0) & (ready == 0)\n",
    "        off_mask = (ign == 0) & (gun == 0) & (ready == 0)\n",
    "\n",
    "        lv_pct = pct(lv_mask)\n",
    "        off_pct = pct(off_mask)\n",
    "    else:\n",
    "        lv_pct = off_pct = np.nan\n",
    "\n",
    "    return {\n",
    "        \"id\": id_val,\n",
    "        \"reg_num\": reg_num,\n",
    "        \"customer\": customer,\n",
    "        \"model\": model,\n",
    "        \"start_time\": start_time,\n",
    "        \"end_time\": end_time,\n",
    "        \"duration_mins\": duration_mins,\n",
    "        \"kwh_charging\": kwh_charging,\n",
    "        \"kwh_discharging\": kwh_discharging,\n",
    "        \"soc_start\": soc_start,\n",
    "        \"soc_end\": soc_end,\n",
    "        \"soc_gain\": soc_gain,\n",
    "        \"soc_drop\": soc_drop,\n",
    "        \"charging_pct\": charging_pct,\n",
    "        \"discharging_pct\": discharging_pct,\n",
    "        \"motion_pct\": motion_pct,\n",
    "        \"lv_pct\": lv_pct,\n",
    "        \"off_pct\": off_pct,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "341b02e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _build_sessions_for_vehicle(df_vid: pd.DataFrame) -> list[dict]:\n",
    "    \"\"\"\n",
    "    For a single vehicle, build sessions around stitched charging envelopes\n",
    "    and compute metrics for each slice.\n",
    "\n",
    "    Session boundaries:\n",
    "      - Charging envelopes from _build_charging_sessions_for_vehicle()\n",
    "      - Gaps between them\n",
    "      - Pre-first and post-last intervals\n",
    "\n",
    "    Session label:\n",
    "      - 'activity' is derived from the dominant `alt_mode` inside the slice:\n",
    "            CHARGING_ACTIVE / CHARGING_MAINTAIN / CHARGING_IDLE\n",
    "            DISCHARGING_ACTIVE / DISCHARGING_IDLE\n",
    "        falling back to simple CHARGING/DISCHARGING/UNKNOWN if needed.\n",
    "    \"\"\"\n",
    "    rows: list[dict] = []\n",
    "    if df_vid.empty:\n",
    "        return rows\n",
    "\n",
    "    df_vid = df_vid.sort_values(\"timestamp\").reset_index(drop=True)\n",
    "    n = len(df_vid)\n",
    "\n",
    "    charging_sessions = _build_charging_sessions_for_vehicle(df_vid)\n",
    "\n",
    "    BATT_KWH = 423.96  # for C-rate\n",
    "\n",
    "    def add_session(start_idx: int, end_idx: int):\n",
    "        \"\"\"Slice [start_idx, end_idx] â†’ metrics + activity.\"\"\"\n",
    "        if start_idx > end_idx or start_idx < 0 or end_idx >= n:\n",
    "            return\n",
    "\n",
    "        seg = df_vid.iloc[start_idx:end_idx + 1].copy()\n",
    "        if seg.empty:\n",
    "            return\n",
    "\n",
    "        metrics = _compute_session_metrics(seg)\n",
    "        if metrics is None:\n",
    "            return\n",
    "\n",
    "        # --- derive activity from alt_mode ---\n",
    "        activity = None\n",
    "        if \"alt_mode\" in seg.columns:\n",
    "            am = seg[\"alt_mode\"].dropna().astype(str)\n",
    "            if not am.empty:\n",
    "                activity = am.value_counts().idxmax()\n",
    "\n",
    "        if activity is None:\n",
    "            # fallback: sign of current\n",
    "            if \"total_battery_current\" in seg.columns:\n",
    "                cur = pd.to_numeric(seg[\"total_battery_current\"], errors=\"coerce\")\n",
    "                if cur.mean(skipna=True) < 0:\n",
    "                    activity = \"CHARGING\"\n",
    "                else:\n",
    "                    activity = \"DISCHARGING\"\n",
    "            else:\n",
    "                activity = \"UNKNOWN\"\n",
    "\n",
    "        # --- C-rate style metrics (same as earlier) ---\n",
    "        charge_rate = 0.0\n",
    "        discharge_rate = 0.0\n",
    "\n",
    "        if \"bat_voltage\" in seg.columns and \"total_battery_current\" in seg.columns:\n",
    "            seg[\"power_kw\"] = (seg[\"bat_voltage\"] * seg[\"total_battery_current\"]) / 1000.0\n",
    "\n",
    "            chg = seg.loc[seg[\"power_kw\"] < 0, \"power_kw\"]\n",
    "            if not chg.empty:\n",
    "                avg_chg_kw = abs(chg.mean())\n",
    "                charge_rate = avg_chg_kw / BATT_KWH\n",
    "\n",
    "            dch = seg.loc[seg[\"power_kw\"] > 0, \"power_kw\"]\n",
    "            if not dch.empty:\n",
    "                avg_dch_kw = dch.mean()\n",
    "                discharge_rate = avg_dch_kw / BATT_KWH\n",
    "\n",
    "        metrics[\"charge_rate\"] = round(charge_rate, 3) if charge_rate is not None else None\n",
    "        metrics[\"discharge_rate\"] = round(discharge_rate, 3) if discharge_rate is not None else None\n",
    "\n",
    "        metrics[\"activity\"] = activity\n",
    "        rows.append(metrics)\n",
    "\n",
    "    # --------------------------\n",
    "    # build segments around envelopes\n",
    "    # --------------------------\n",
    "    if not charging_sessions:\n",
    "        # whole day is a single discharging-family session\n",
    "        add_session(0, n - 1)\n",
    "        return rows\n",
    "\n",
    "    # pre-first-charging\n",
    "    first = charging_sessions[0]\n",
    "    if first[\"start_idx\"] > 0:\n",
    "        add_session(0, first[\"start_idx\"] - 1)\n",
    "\n",
    "    # each charging envelope + gap to next\n",
    "    for i, chg in enumerate(charging_sessions):\n",
    "        # charging region itself\n",
    "        add_session(chg[\"start_idx\"], chg[\"end_idx\"])\n",
    "\n",
    "        # gap (discharging region) to next envelope\n",
    "        if i < len(charging_sessions) - 1:\n",
    "            nxt = charging_sessions[i + 1]\n",
    "            gap_start = chg[\"end_idx\"] + 1\n",
    "            gap_end = nxt[\"start_idx\"] - 1\n",
    "            if gap_start <= gap_end:\n",
    "                add_session(gap_start, gap_end)\n",
    "\n",
    "    # post-last-charging\n",
    "    last = charging_sessions[-1]\n",
    "    if last[\"end_idx\"] < n - 1:\n",
    "        add_session(last[\"end_idx\"] + 1, n - 1)\n",
    "\n",
    "    return rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3843858f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrich_discharging_metrics(\n",
    "    session_df: pd.DataFrame,\n",
    "    raw_df: pd.DataFrame,\n",
    "    max_kmph_for_physics: float = 120.0,\n",
    "    physics_tolerance: float = 1.3,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Option 3: physics-aware, GLITCH-capable enrichment.\n",
    "\n",
    "    Adds per-session:\n",
    "      - dist_km (final, physics-sanitised)\n",
    "      - avg_speed, med_speed, max_speed\n",
    "      - avg/med/max/p95 volt_delta_mv\n",
    "      - avg/med/max/p95 batt_temp_delta\n",
    "      - energy_active_kwh, kwh_per_km\n",
    "      - odo_start, odo_end, net_odo_km\n",
    "      - dist_km_raw (pre-physics cumulative diffs)\n",
    "      - max_physical_km\n",
    "      - glitch_flag (bool) + glitch_reason (text)\n",
    "\n",
    "    If session_df has an 'activity' column, GLITCH sessions get\n",
    "    activity=\"GLITCH\".\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure time alignment\n",
    "    raw_df = raw_df.sort_values([\"id\", \"timestamp\"]).copy()\n",
    "\n",
    "    # --- Holder columns (base metrics) ---\n",
    "    session_df[\"dist_km\"] = 0.0\n",
    "    session_df[\"avg_speed\"] = 0.0\n",
    "    session_df[\"med_speed\"] = 0.0\n",
    "    session_df[\"max_speed\"] = 0.0\n",
    "\n",
    "    session_df[\"avg_volt_delta_mv\"] = 0.0\n",
    "    session_df[\"med_volt_delta_mv\"] = 0.0\n",
    "    session_df[\"max_volt_delta_mv\"] = 0.0\n",
    "    session_df[\"p95_volt_delta_mv\"] = 0.0\n",
    "\n",
    "    session_df[\"avg_batt_temp_delta\"] = 0.0\n",
    "    session_df[\"med_batt_temp_delta\"] = 0.0\n",
    "    session_df[\"max_batt_temp_delta\"] = 0.0\n",
    "    session_df[\"p95_batt_temp_delta\"] = 0.0\n",
    "\n",
    "    session_df[\"energy_active_kwh\"] = 0.0\n",
    "    session_df[\"kwh_per_km\"] = np.nan\n",
    "\n",
    "    # --- NEW diagnostic / physics fields ---\n",
    "    session_df[\"odo_start\"] = np.nan\n",
    "    session_df[\"odo_end\"]   = np.nan\n",
    "    session_df[\"net_odo_km\"] = 0.0      # odo_end - odo_start (clamped â‰¥ 0)\n",
    "    session_df[\"dist_km_raw\"] = 0.0     # sum of positive diffs before physics clamp\n",
    "    session_df[\"max_physical_km\"] = 0.0\n",
    "\n",
    "    session_df[\"glitch_flag\"] = False\n",
    "    session_df[\"glitch_reason\"] = \"\"\n",
    "\n",
    "    has_activity_col = \"activity\" in session_df.columns\n",
    "\n",
    "    # --- Loop through each session ---\n",
    "    for idx, row in session_df.iterrows():\n",
    "        vid = row[\"id\"]\n",
    "        t1  = row[\"start_time\"]\n",
    "        t2  = row[\"end_time\"]\n",
    "\n",
    "        # Keep your original intent: only DISCHARGING_ACTIVE are \"drive\" sessions\n",
    "        if has_activity_col and row[\"activity\"] != \"DISCHARGING_ACTIVE\":\n",
    "            continue\n",
    "\n",
    "        mask = (\n",
    "            (raw_df[\"id\"] == vid) &\n",
    "            (raw_df[\"timestamp\"] >= t1) &\n",
    "            (raw_df[\"timestamp\"] <= t2)\n",
    "        )\n",
    "        chunk = raw_df[mask].copy()\n",
    "\n",
    "        if chunk.empty:\n",
    "            continue\n",
    "\n",
    "        # -------------------------------\n",
    "        # 0. Choose odometer source\n",
    "        # -------------------------------\n",
    "        if \"odometer_final\" in chunk.columns:\n",
    "            odo_series = chunk[\"odometer_final\"].astype(\"float64\")\n",
    "        else:\n",
    "            odo_series = chunk[\"odometerreading\"].astype(\"float64\")\n",
    "\n",
    "        odo_series = odo_series.dropna()\n",
    "        if odo_series.empty:\n",
    "            # No odo â†’ skip distance & energy, but still do volt/temp/speed\n",
    "            odo_start = np.nan\n",
    "            odo_end = np.nan\n",
    "            net_odo = 0.0\n",
    "        else:\n",
    "            odo_start = float(odo_series.iloc[0])\n",
    "            odo_end   = float(odo_series.iloc[-1])\n",
    "            net_odo   = max(odo_end - odo_start, 0.0)\n",
    "\n",
    "        session_df.at[idx, \"odo_start\"] = odo_start\n",
    "        session_df.at[idx, \"odo_end\"]   = odo_end\n",
    "        session_df.at[idx, \"net_odo_km\"] = net_odo\n",
    "\n",
    "        # -------------------------------\n",
    "        # 1. Distance via forward-only diffs (raw)\n",
    "        # -------------------------------\n",
    "        if \"odometer_final\" in chunk.columns:\n",
    "            odo_full = chunk[\"odometer_final\"].astype(\"float64\")\n",
    "        # else:\n",
    "        #     odo_full = chunk[\"odometerreading\"].astype(\"float64\")\n",
    "\n",
    "        odo_diff = odo_full.diff()\n",
    "        # Keep only strictly positive increments\n",
    "        dist_km_raw = odo_diff[odo_diff > 0].sum(skipna=True)\n",
    "        if pd.isna(dist_km_raw):\n",
    "            dist_km_raw = 0.0\n",
    "        session_df.at[idx, \"dist_km_raw\"] = float(dist_km_raw)\n",
    "\n",
    "        # -------------------------------\n",
    "        # 2. Speed stats\n",
    "        # -------------------------------\n",
    "        v = chunk[\"vehicle_speed_vcu\"].dropna()\n",
    "        if not v.empty:\n",
    "            avg_speed = float(v.mean())\n",
    "            med_speed = float(v.median())\n",
    "            max_speed = float(v.max())\n",
    "        else:\n",
    "            avg_speed = med_speed = max_speed = 0.0\n",
    "\n",
    "        session_df.at[idx, \"avg_speed\"] = round(avg_speed, 2)\n",
    "        session_df.at[idx, \"med_speed\"] = round(med_speed,2)\n",
    "        session_df.at[idx, \"max_speed\"] = round(max_speed, 2)\n",
    "\n",
    "        # -------------------------------\n",
    "        # 3. Voltage delta stats\n",
    "        # -------------------------------\n",
    "        vd = chunk[\"volt_delta_mv\"].dropna()\n",
    "        if not vd.empty:\n",
    "            session_df.at[idx, \"avg_volt_delta_mv\"] = round(float(vd.mean()), 2)\n",
    "            session_df.at[idx, \"med_volt_delta_mv\"] = round(float(vd.median()), 2)\n",
    "            session_df.at[idx, \"max_volt_delta_mv\"] = round(float(vd.max()),2)\n",
    "            session_df.at[idx, \"p95_volt_delta_mv\"] = round(float(vd.quantile(0.95)), 2)\n",
    "\n",
    "        # -------------------------------\n",
    "        # 4. Temperature delta stats\n",
    "        # -------------------------------\n",
    "        td = chunk[\"batt_temp_delta\"].dropna()\n",
    "        if not td.empty:\n",
    "            session_df.at[idx, \"avg_batt_temp_delta\"] = round(float(td.mean()),2)\n",
    "            session_df.at[idx, \"med_batt_temp_delta\"] = round(float(td.median()),2)\n",
    "            session_df.at[idx, \"max_batt_temp_delta\"] = round(float(td.max()),2)\n",
    "            session_df.at[idx, \"p95_batt_temp_delta\"] = round(float(td.quantile(0.95)), 2)\n",
    "\n",
    "        # -------------------------------\n",
    "        # 5. Energy integration (kWh)\n",
    "        # -------------------------------\n",
    "        # Power (kW) = V * I / 1000\n",
    "        # Energy (kWh) = Î£ power * (dt_sec / 3600)\n",
    "        chunk[\"power_kw\"] = round((\n",
    "            chunk[\"bat_voltage\"].astype(\"float64\") *\n",
    "            chunk[\"total_battery_current\"].astype(\"float64\")\n",
    "        ) / 1000.0, 2)\n",
    "\n",
    "        chunk[\"energy_kwh\"] = round(chunk[\"power_kw\"] * (\n",
    "            chunk[\"dt_sec\"].astype(\"float64\") / 3600.0\n",
    "        ), 2)\n",
    "\n",
    "        energy_active_kwh = chunk.loc[chunk[\"energy_kwh\"] > 0, \"energy_kwh\"].sum()\n",
    "        if pd.isna(energy_active_kwh):\n",
    "            energy_active_kwh = 0.0\n",
    "\n",
    "        session_df.at[idx, \"energy_active_kwh\"] = round(float(energy_active_kwh), 2)\n",
    "\n",
    "        # -------------------------------\n",
    "        # 6. Physics model: max possible km\n",
    "        # -------------------------------\n",
    "        ts_min = chunk[\"timestamp\"].min()\n",
    "        ts_max = chunk[\"timestamp\"].max()\n",
    "        if pd.isna(ts_min) or pd.isna(ts_max):\n",
    "            duration_hr = 0.0\n",
    "        else:\n",
    "            duration_sec = (ts_max - ts_min).total_seconds()\n",
    "            duration_hr = max(duration_sec / 3600.0, 0.0)\n",
    "\n",
    "        # cap median speed by max_kmph_for_physics\n",
    "        eff_avg_speed = min((max_speed+med_speed)/2, max_kmph_for_physics)\n",
    "        max_physical_km = eff_avg_speed * duration_hr * physics_tolerance\n",
    "\n",
    "        session_df.at[idx, \"max_physical_km\"] = round(float(max_physical_km), 3)\n",
    "\n",
    "        # -------------------------------\n",
    "        # 7. GLITCH detection (Option 3)\n",
    "        # -------------------------------\n",
    "        glitch_flag = False\n",
    "        reasons = []\n",
    "\n",
    "        eps = 1e-6\n",
    "\n",
    "        # A: net odometer itself exceeds physics limit\n",
    "        if net_odo > max_physical_km + eps:\n",
    "            glitch_flag = True\n",
    "            reasons.append(\n",
    "                f\"net_odo {net_odo:.3f}km > max_phys {max_physical_km:.3f}km\"\n",
    "            )\n",
    "\n",
    "        # B: raw cumulative distance exceeds physics limit dramatically\n",
    "        if dist_km_raw > max_physical_km + eps:\n",
    "            glitch_flag = True\n",
    "            reasons.append(\n",
    "                f\"dist_km_raw {dist_km_raw:.3f}km > max_phys {max_physical_km:.3f}km\"\n",
    "            )\n",
    "\n",
    "        # C: backward odometer (shouldn't happen after your finaliser, but guard anyway)\n",
    "        if odo_end is not np.nan and odo_start is not np.nan and odo_end + eps < odo_start:\n",
    "            glitch_flag = True\n",
    "            reasons.append(\n",
    "                f\"odo_end {odo_end:.3f} < odo_start {odo_start:.3f}\"\n",
    "            )\n",
    "\n",
    "        # -------------------------------\n",
    "        # 8. Final distance selection\n",
    "        # -------------------------------\n",
    "        # Start with raw cumulative\n",
    "        dist_final = float(dist_km_raw)\n",
    "\n",
    "        # If raw cumulative is significantly higher than net change, it's jitter\n",
    "        if net_odo > 0 and dist_final > net_odo * physics_tolerance:\n",
    "            reasons.append(\n",
    "                f\"dist_km_raw {dist_final:.3f}km >> net_odo {net_odo:.3f}km, using net_odo\"\n",
    "            )\n",
    "            dist_final = float(net_odo)\n",
    "\n",
    "        # If GLITCH due to physics but net_odo is still sane, keep net_odo as best guess\n",
    "        if glitch_flag:\n",
    "            if net_odo <= max_physical_km + eps:\n",
    "                dist_final = float(net_odo)\n",
    "            else:\n",
    "                # Completely impossible â†’ distance is untrustworthy\n",
    "                dist_final = 0.0\n",
    "\n",
    "        session_df.at[idx, \"dist_km\"] = dist_final\n",
    "\n",
    "        # -------------------------------\n",
    "        # 9. kWh/km using final distance\n",
    "        # -------------------------------\n",
    "        if dist_final > 0:\n",
    "            session_df.at[idx, \"kwh_per_km\"] = round(float(energy_active_kwh / dist_final),2)\n",
    "        else:\n",
    "            session_df.at[idx, \"kwh_per_km\"] = np.nan\n",
    "\n",
    "        # -------------------------------\n",
    "        # 10. Persist GLITCH info\n",
    "        # -------------------------------\n",
    "        if glitch_flag:\n",
    "            session_df.at[idx, \"glitch_flag\"] = True\n",
    "            session_df.at[idx, \"glitch_reason\"] = \"; \".join(reasons)\n",
    "            if has_activity_col:\n",
    "                session_df.at[idx, \"activity\"] = \"GLITCH\"\n",
    "\n",
    "    return session_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "43b03275",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_charging_and_discharging_sessions(df_day: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build unified CHARGING / DISCHARGING sessions for a day's data.\n",
    "    Also adds bucket distributions and SOC stats.\n",
    "\n",
    "    Output columns:\n",
    "        id, reg_num, customer, model, activity, session, date,\n",
    "        start_time, end_time, duration_mins,\n",
    "        charging_pct, discharging_pct, motion_pct,\n",
    "        lv_pct, off_pct,\n",
    "        kwh_charging, kwh_discharging,\n",
    "        soc_start, soc_end, soc_gain, soc_drop,\n",
    "        ... + bucket percentage columns\n",
    "    \"\"\"\n",
    "\n",
    "    if df_day.empty:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df_day = df_day.sort_values([\"id\", \"timestamp\"]).reset_index(drop=True)\n",
    "\n",
    "    # -----------------------------------------------------------\n",
    "    # STEP 1 â€” Build sessions for each vehicle\n",
    "    # -----------------------------------------------------------\n",
    "    all_rows = []\n",
    "    for vid, df_vid in df_day.groupby(\"id\"):\n",
    "        vid_rows = _build_sessions_for_vehicle(df_vid)   # <-- your existing function\n",
    "        all_rows.extend(vid_rows)\n",
    "\n",
    "    if not all_rows:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Convert list of dicts into DataFrame\n",
    "    sessions = pd.DataFrame(all_rows)\n",
    "\n",
    "    # -----------------------------------------------------------\n",
    "    # STEP 2 â€” Sort & assign per-vehicle session number\n",
    "    # -----------------------------------------------------------\n",
    "    sessions = sessions.sort_values([\"id\", \"start_time\"]).reset_index(drop=True)\n",
    "    sessions[\"session\"] = sessions.groupby(\"id\").cumcount() + 1\n",
    "    sessions[\"date\"] = sessions[\"start_time\"].dt.date\n",
    "\n",
    "    # -----------------------------------------------------------\n",
    "    # NEW STEP 2B â€” SOC DROP GLITCH DETECTION\n",
    "    # -----------------------------------------------------------\n",
    "    THRESH_ACTIVE = 0.0    # no drop allowed during active charging\n",
    "    THRESH_MAINT  = 0.3    # small balancing jitter allowed\n",
    "    THRESH_IDLE   = 0.5    # small taper jitter allowed\n",
    "\n",
    "    if \"activity\" in sessions.columns:\n",
    "        sessions[\"glitch_flag\"] = False\n",
    "        sessions[\"glitch_reason\"] = \"\"\n",
    "\n",
    "        for idx, row in sessions.iterrows():\n",
    "            mode = row[\"activity\"]\n",
    "            if not isinstance(mode, str):\n",
    "                continue\n",
    "\n",
    "            # only apply to charging modes\n",
    "            if not mode.startswith(\"CHARGING\"):\n",
    "                continue\n",
    "\n",
    "            soc_drop = row.get(\"soc_drop\", 0) or 0\n",
    "\n",
    "            # CHARGING_ACTIVE â€“ absolutely no SOC drop expected\n",
    "            if mode == \"CHARGING_ACTIVE\" and soc_drop > THRESH_ACTIVE:\n",
    "                sessions.at[idx, \"glitch_flag\"] = True\n",
    "                sessions.at[idx, \"glitch_reason\"] = (\n",
    "                    f\"SOC dropped {soc_drop:.2f}% during CHARGING_ACTIVE\"\n",
    "                )\n",
    "                sessions.at[idx, \"activity\"] = \"GLITCH\"\n",
    "                continue\n",
    "\n",
    "            # CHARGING_MAINTAIN â€“ a tiny balancing drift is allowed\n",
    "            if mode == \"CHARGING_MAINTAIN\" and soc_drop > THRESH_MAINT:\n",
    "                sessions.at[idx, \"glitch_flag\"] = True\n",
    "                sessions.at[idx, \"glitch_reason\"] = (\n",
    "                    f\"SOC dropped {soc_drop:.2f}% during CHARGING_MAINTAIN\"\n",
    "                )\n",
    "                sessions.at[idx, \"activity\"] = \"GLITCH\"\n",
    "                continue\n",
    "\n",
    "            # CHARGING_IDLE â€“ some jitter possible due to sensor/rounding\n",
    "            if mode == \"CHARGING_IDLE\" and soc_drop > THRESH_IDLE:\n",
    "                sessions.at[idx, \"glitch_flag\"] = True\n",
    "                sessions.at[idx, \"glitch_reason\"] = (\n",
    "                    f\"SOC dropped {soc_drop:.2f}% during CHARGING_IDLE\"\n",
    "                )\n",
    "                sessions.at[idx, \"activity\"] = \"GLITCH\"\n",
    "                continue\n",
    "\n",
    "    # -----------------------------------------------------------\n",
    "    # STEP 3 â€” Push 'session' assignment back into raw df_day rows\n",
    "    # -----------------------------------------------------------\n",
    "    df_day[\"session\"] = None\n",
    "\n",
    "    for ses in sessions.itertuples(index=False):\n",
    "        mask = (\n",
    "            (df_day[\"id\"] == ses.id) &\n",
    "            (df_day[\"timestamp\"] >= ses.start_time) &\n",
    "            (df_day[\"timestamp\"] <= ses.end_time)\n",
    "        )\n",
    "        df_day.loc[mask, \"session\"] = ses.session\n",
    "\n",
    "    # -----------------------------------------------------------\n",
    "    # STEP 4 â€” Bucket distributions (TEMP, VOLT, SOC)\n",
    "    # -----------------------------------------------------------\n",
    "    BUCKET_MAP = {\n",
    "        'maxtemp_bucket': [\"<28\", \"28â€“32\", \"32â€“35\", \"35â€“40\", \">40\"],\n",
    "        'temp_delta_bucket': [\"<2\", \"2â€“5\", \"5â€“8\", \">8\"],\n",
    "        'volt_delta_bucket': [\"0â€“10\", \"10â€“20\", \"20â€“30\", \">30\"],\n",
    "        'soc_band_bucket': [\n",
    "            \"0â€“10\",\"10â€“20\",\"20â€“30\",\"30â€“40\",\"40â€“50\",\n",
    "            \"50â€“60\",\"60â€“70\",\"70â€“80\",\"80â€“90\",\"90â€“100\"\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    for col, categories in BUCKET_MAP.items():\n",
    "        if col not in df_day.columns:\n",
    "            continue\n",
    "\n",
    "        # normalize category labels\n",
    "        df_day[col] = (\n",
    "            df_day[col].astype(str).str.replace(\"-\", \"â€“\")\n",
    "        )\n",
    "        df_day[col] = pd.Categorical(df_day[col], categories=categories, ordered=True)\n",
    "\n",
    "        # compute percentage distributions\n",
    "        pct = (\n",
    "            df_day.groupby(\"session\")[col]\n",
    "                .value_counts(normalize=True)\n",
    "                .mul(100)\n",
    "                .round(2)\n",
    "        )\n",
    "\n",
    "        pct_pivot = pct.unstack(fill_value=0)\n",
    "\n",
    "        pct_pivot.columns = [\n",
    "            f\"{col}_{str(c).replace('â€“','_').replace('<','lt').replace('>','gt')}_pct\"\n",
    "            for c in pct_pivot.columns\n",
    "        ]\n",
    "\n",
    "        sessions = sessions.join(pct_pivot, on=\"session\", how=\"left\")\n",
    "\n",
    "    # -----------------------------------------------------------\n",
    "    # STEP 5 â€” Round SOC columns\n",
    "    # -----------------------------------------------------------\n",
    "    for col in [\"soc_start\", \"soc_end\", \"soc_gain\", \"soc_drop\"]:\n",
    "        if col in sessions.columns:\n",
    "            sessions[col] = sessions[col].apply(\n",
    "                lambda x: round(x, 2) if pd.notna(x) else x\n",
    "            )\n",
    "\n",
    "    # -----------------------------------------------------------\n",
    "    # STEP 6 â€” Final ordering\n",
    "    # -----------------------------------------------------------\n",
    "    ordered_cols = [\n",
    "        \"id\", \"reg_num\", \"customer\", \"model\",\n",
    "        \"activity\", \"session\", \"date\",\n",
    "        \"start_time\", \"end_time\", \"duration_mins\",\n",
    "        \"charging_pct\", \"discharging_pct\", \"motion_pct\",\n",
    "        \"lv_pct\", \"off_pct\",\n",
    "        \"kwh_charging\", \"kwh_discharging\",\"charge_rate\",\"discharge_rate\",\n",
    "        \"soc_start\", \"soc_end\", \"soc_gain\", \"soc_drop\",\n",
    "    ]\n",
    "\n",
    "    # keep any extra bucket columns also\n",
    "    ordered_cols += [c for c in sessions.columns if c not in ordered_cols]\n",
    "\n",
    "    return sessions[ordered_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "924133d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_multi_day_session_analysis(\n",
    "    parquet_path: str, \n",
    "    start_date: datetime, \n",
    "    num_days: int\n",
    "):\n",
    "    \"\"\"\n",
    "    Iteratively loads, processes, and aggregates session reports\n",
    "    (CHARGING_* / DISCHARGING_* via `activity`) for a defined\n",
    "    number of days across all vehicles.\n",
    "    \"\"\"\n",
    "    all_sessions: list[pd.DataFrame] = []\n",
    "    total_rows_ingested = 0\n",
    "\n",
    "    current_log_level = logging.getLogger().level\n",
    "    logging.getLogger().setLevel(logging.WARNING)\n",
    "\n",
    "    try:\n",
    "        progress_bar = tqdm(\n",
    "            range(num_days),\n",
    "            desc=\"Processing Daily Sessions\",\n",
    "            unit=\"day\",\n",
    "            colour=\"cyan\",\n",
    "        )\n",
    "\n",
    "        for i in progress_bar:\n",
    "            current_start_dt = start_date + timedelta(days=i)\n",
    "            current_end_dt = current_start_dt + timedelta(days=1)\n",
    "\n",
    "            progress_bar.set_postfix_str(\n",
    "                f\"Date: {current_start_dt.strftime('%Y-%m-%d')}\"\n",
    "            )\n",
    "\n",
    "            df_subset = read_parquet_subset(\n",
    "                parquet_path=parquet_path,\n",
    "                start_dt=current_start_dt,\n",
    "                end_dt=current_end_dt,\n",
    "            )\n",
    "\n",
    "            if df_subset.empty:\n",
    "                continue\n",
    "\n",
    "            total_rows_ingested += len(df_subset)\n",
    "\n",
    "            # 1) Build unified sessions (activity comes from alt_mode)\n",
    "            day_sessions = build_charging_and_discharging_sessions(df_subset)\n",
    "\n",
    "            # 2) Enrich discharging-active sessions with distance / kWh/km\n",
    "            if not day_sessions.empty:\n",
    "                day_sessions = enrich_discharging_metrics(day_sessions, df_subset)\n",
    "                all_sessions.append(day_sessions)\n",
    "\n",
    "            del df_subset\n",
    "            gc.collect()\n",
    "\n",
    "    finally:\n",
    "        logging.getLogger().setLevel(current_log_level)\n",
    "\n",
    "    if all_sessions:\n",
    "        final_df = pd.concat(all_sessions, ignore_index=True)\n",
    "    else:\n",
    "        final_df = pd.DataFrame()\n",
    "\n",
    "    return final_df, total_rows_ingested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7098d757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # =========================================================================\n",
    "# # --- Execution Example ---\n",
    "# # =========================================================================\n",
    "\n",
    "# # Define the 75-day process window\n",
    "# filter_start_date = datetime(2025, 9, 1) # Start date\n",
    "# total_days_to_process = 75\n",
    "\n",
    "# print(f\"--- Starting 75-Day Session Analysis ---\")\n",
    "# print(f\"Processing range: {filter_start_date.strftime('%Y-%m-%d')} to {(filter_start_date + timedelta(days=total_days_to_process-1)).strftime('%Y-%m-%d')}\")\n",
    "# print(\"-\" * 40)\n",
    "\n",
    "# start_time = time.time()\n",
    "\n",
    "# charge_discharge_df, total_rows = run_multi_day_session_analysis(\n",
    "#     parquet_path=\"../df_with_state.parquet\",\n",
    "#     start_date=filter_start_date,\n",
    "#     num_days=total_days_to_process\n",
    "# )\n",
    "\n",
    "# charge_discharge_df[\"charge_rate\"] = charge_discharge_df[\"charge_rate\"].round(3)\n",
    "# charge_discharge_df[\"discharge_rate\"] = charge_discharge_df[\"discharge_rate\"].round(3)\n",
    "\n",
    "# charge_discharge_df[\"start_time\"] = charge_discharge_df[\"start_time\"].dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "# charge_discharge_df[\"end_time\"] = charge_discharge_df[\"end_time\"].dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "# end_time = time.time()\n",
    "# elapsed_time_sec = end_time - start_time\n",
    "# elapsed_time_min = elapsed_time_sec / 60\n",
    "\n",
    "# # --- Final Summary ---\n",
    "# print(\"\\n\" + \"=\" * 40)\n",
    "# print(\"âœ… ANALYSIS COMPLETE\")\n",
    "# print(f\"Total time taken: {elapsed_time_sec:.2f} seconds ({elapsed_time_min:.2f} minutes)\")\n",
    "# print(f\"Days processed:   {total_days_to_process}\")\n",
    "# print(f\"Total Rows Ingested: {total_rows:,}\")\n",
    "# print(f\"Final Report Shape: {charge_discharge_df.shape} (Rows: {charge_discharge_df.shape[0]}, Columns: {charge_discharge_df.shape[1]})\")\n",
    "# print(\"=\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f27393d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# charge_discharge_df.to_parquet('charge_discharge_analysis.parquet', index=False)\n",
    "charge_discharge_df = pd.read_parquet('charge_discharge_analysis.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "01c10b77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>reg_num</th>\n",
       "      <th>customer</th>\n",
       "      <th>model</th>\n",
       "      <th>activity</th>\n",
       "      <th>session</th>\n",
       "      <th>date</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>duration_mins</th>\n",
       "      <th>charging_pct</th>\n",
       "      <th>discharging_pct</th>\n",
       "      <th>motion_pct</th>\n",
       "      <th>lv_pct</th>\n",
       "      <th>off_pct</th>\n",
       "      <th>kwh_charging</th>\n",
       "      <th>kwh_discharging</th>\n",
       "      <th>charge_rate</th>\n",
       "      <th>discharge_rate</th>\n",
       "      <th>soc_start</th>\n",
       "      <th>soc_end</th>\n",
       "      <th>soc_gain</th>\n",
       "      <th>soc_drop</th>\n",
       "      <th>glitch_flag</th>\n",
       "      <th>glitch_reason</th>\n",
       "      <th>maxtemp_bucket_lt28_pct</th>\n",
       "      <th>maxtemp_bucket_28_32_pct</th>\n",
       "      <th>maxtemp_bucket_32_35_pct</th>\n",
       "      <th>maxtemp_bucket_35_40_pct</th>\n",
       "      <th>maxtemp_bucket_gt40_pct</th>\n",
       "      <th>temp_delta_bucket_lt2_pct</th>\n",
       "      <th>temp_delta_bucket_2_5_pct</th>\n",
       "      <th>temp_delta_bucket_5_8_pct</th>\n",
       "      <th>temp_delta_bucket_gt8_pct</th>\n",
       "      <th>volt_delta_bucket_0_10_pct</th>\n",
       "      <th>volt_delta_bucket_10_20_pct</th>\n",
       "      <th>volt_delta_bucket_20_30_pct</th>\n",
       "      <th>volt_delta_bucket_gt30_pct</th>\n",
       "      <th>soc_band_bucket_0_10_pct</th>\n",
       "      <th>soc_band_bucket_10_20_pct</th>\n",
       "      <th>soc_band_bucket_20_30_pct</th>\n",
       "      <th>soc_band_bucket_30_40_pct</th>\n",
       "      <th>soc_band_bucket_40_50_pct</th>\n",
       "      <th>soc_band_bucket_50_60_pct</th>\n",
       "      <th>soc_band_bucket_60_70_pct</th>\n",
       "      <th>soc_band_bucket_70_80_pct</th>\n",
       "      <th>soc_band_bucket_80_90_pct</th>\n",
       "      <th>soc_band_bucket_90_100_pct</th>\n",
       "      <th>dist_km</th>\n",
       "      <th>avg_speed</th>\n",
       "      <th>med_speed</th>\n",
       "      <th>max_speed</th>\n",
       "      <th>avg_volt_delta_mv</th>\n",
       "      <th>med_volt_delta_mv</th>\n",
       "      <th>max_volt_delta_mv</th>\n",
       "      <th>p95_volt_delta_mv</th>\n",
       "      <th>avg_batt_temp_delta</th>\n",
       "      <th>med_batt_temp_delta</th>\n",
       "      <th>max_batt_temp_delta</th>\n",
       "      <th>p95_batt_temp_delta</th>\n",
       "      <th>energy_active_kwh</th>\n",
       "      <th>kwh_per_km</th>\n",
       "      <th>odo_start</th>\n",
       "      <th>odo_end</th>\n",
       "      <th>net_odo_km</th>\n",
       "      <th>dist_km_raw</th>\n",
       "      <th>max_physical_km</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>HR55AY9237</td>\n",
       "      <td>ZB Gurgaon</td>\n",
       "      <td>12.5</td>\n",
       "      <td>DISCHARGING_IDLE</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-09-01</td>\n",
       "      <td>2025-09-01 05:30:00</td>\n",
       "      <td>2025-09-01 05:37:36</td>\n",
       "      <td>7.59</td>\n",
       "      <td>0.00</td>\n",
       "      <td>94.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.58</td>\n",
       "      <td>89.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.18</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.082</td>\n",
       "      <td>33.2</td>\n",
       "      <td>33.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>9.05</td>\n",
       "      <td>35.99</td>\n",
       "      <td>54.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.04</td>\n",
       "      <td>16.90</td>\n",
       "      <td>38.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>75.10</td>\n",
       "      <td>24.55</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.74</td>\n",
       "      <td>44.26</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>HR55AY9237</td>\n",
       "      <td>ZB Gurgaon</td>\n",
       "      <td>12.5</td>\n",
       "      <td>CHARGING_ACTIVE</td>\n",
       "      <td>2</td>\n",
       "      <td>2025-09-01</td>\n",
       "      <td>2025-09-01 05:39:01</td>\n",
       "      <td>2025-09-01 07:22:50</td>\n",
       "      <td>103.81</td>\n",
       "      <td>96.58</td>\n",
       "      <td>2.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>302.52</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0.008</td>\n",
       "      <td>33.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.99</td>\n",
       "      <td>35.29</td>\n",
       "      <td>53.72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.47</td>\n",
       "      <td>12.65</td>\n",
       "      <td>74.86</td>\n",
       "      <td>0.02</td>\n",
       "      <td>11.26</td>\n",
       "      <td>61.32</td>\n",
       "      <td>12.12</td>\n",
       "      <td>15.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.49</td>\n",
       "      <td>12.87</td>\n",
       "      <td>14.93</td>\n",
       "      <td>20.93</td>\n",
       "      <td>8.68</td>\n",
       "      <td>8.16</td>\n",
       "      <td>12.12</td>\n",
       "      <td>17.82</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>HR55AY9237</td>\n",
       "      <td>ZB Gurgaon</td>\n",
       "      <td>12.5</td>\n",
       "      <td>DISCHARGING_ACTIVE</td>\n",
       "      <td>3</td>\n",
       "      <td>2025-09-01</td>\n",
       "      <td>2025-09-01 07:23:05</td>\n",
       "      <td>2025-09-01 18:00:51</td>\n",
       "      <td>637.76</td>\n",
       "      <td>15.96</td>\n",
       "      <td>68.81</td>\n",
       "      <td>65.57</td>\n",
       "      <td>13.98</td>\n",
       "      <td>1.42</td>\n",
       "      <td>108.84</td>\n",
       "      <td>439.01</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.137</td>\n",
       "      <td>100.0</td>\n",
       "      <td>22.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.6</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>8.47</td>\n",
       "      <td>88.29</td>\n",
       "      <td>3.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.16</td>\n",
       "      <td>88.25</td>\n",
       "      <td>8.59</td>\n",
       "      <td>0.00</td>\n",
       "      <td>90.08</td>\n",
       "      <td>7.73</td>\n",
       "      <td>1.18</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.28</td>\n",
       "      <td>14.70</td>\n",
       "      <td>30.90</td>\n",
       "      <td>22.15</td>\n",
       "      <td>4.94</td>\n",
       "      <td>4.18</td>\n",
       "      <td>6.50</td>\n",
       "      <td>14.36</td>\n",
       "      <td>330.250</td>\n",
       "      <td>34.92</td>\n",
       "      <td>32.79</td>\n",
       "      <td>85.61</td>\n",
       "      <td>8.52</td>\n",
       "      <td>7.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>4.61</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>372.52</td>\n",
       "      <td>1.13</td>\n",
       "      <td>8679.00</td>\n",
       "      <td>9009.250</td>\n",
       "      <td>330.250</td>\n",
       "      <td>330.250</td>\n",
       "      <td>818.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>HR55AY9237</td>\n",
       "      <td>ZB Gurgaon</td>\n",
       "      <td>12.5</td>\n",
       "      <td>CHARGING_ACTIVE</td>\n",
       "      <td>4</td>\n",
       "      <td>2025-09-01</td>\n",
       "      <td>2025-09-01 18:00:52</td>\n",
       "      <td>2025-09-01 20:32:22</td>\n",
       "      <td>151.50</td>\n",
       "      <td>82.09</td>\n",
       "      <td>5.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.19</td>\n",
       "      <td>357.59</td>\n",
       "      <td>5.61</td>\n",
       "      <td>0.407</td>\n",
       "      <td>0.098</td>\n",
       "      <td>22.4</td>\n",
       "      <td>100.0</td>\n",
       "      <td>77.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>0.05</td>\n",
       "      <td>60.10</td>\n",
       "      <td>39.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.53</td>\n",
       "      <td>6.73</td>\n",
       "      <td>91.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>19.61</td>\n",
       "      <td>49.31</td>\n",
       "      <td>13.64</td>\n",
       "      <td>17.44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.37</td>\n",
       "      <td>15.94</td>\n",
       "      <td>7.52</td>\n",
       "      <td>7.70</td>\n",
       "      <td>13.18</td>\n",
       "      <td>7.59</td>\n",
       "      <td>8.94</td>\n",
       "      <td>17.77</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>HR55AY9237</td>\n",
       "      <td>ZB Gurgaon</td>\n",
       "      <td>12.5</td>\n",
       "      <td>DISCHARGING_ACTIVE</td>\n",
       "      <td>5</td>\n",
       "      <td>2025-09-01</td>\n",
       "      <td>2025-09-01 20:32:23</td>\n",
       "      <td>2025-09-01 23:59:59</td>\n",
       "      <td>207.60</td>\n",
       "      <td>13.15</td>\n",
       "      <td>81.61</td>\n",
       "      <td>62.56</td>\n",
       "      <td>4.06</td>\n",
       "      <td>10.00</td>\n",
       "      <td>33.05</td>\n",
       "      <td>135.19</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.110</td>\n",
       "      <td>100.0</td>\n",
       "      <td>76.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.2</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>63.30</td>\n",
       "      <td>36.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>99.81</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>68.19</td>\n",
       "      <td>11.62</td>\n",
       "      <td>2.98</td>\n",
       "      <td>17.21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.91</td>\n",
       "      <td>28.49</td>\n",
       "      <td>63.59</td>\n",
       "      <td>129.625</td>\n",
       "      <td>35.68</td>\n",
       "      <td>37.14</td>\n",
       "      <td>97.96</td>\n",
       "      <td>14.96</td>\n",
       "      <td>7.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>115.18</td>\n",
       "      <td>0.89</td>\n",
       "      <td>9009.25</td>\n",
       "      <td>9133.875</td>\n",
       "      <td>124.625</td>\n",
       "      <td>129.625</td>\n",
       "      <td>303.834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     reg_num    customer model            activity  session        date  \\\n",
       "0  16  HR55AY9237  ZB Gurgaon  12.5    DISCHARGING_IDLE        1  2025-09-01   \n",
       "1  16  HR55AY9237  ZB Gurgaon  12.5     CHARGING_ACTIVE        2  2025-09-01   \n",
       "2  16  HR55AY9237  ZB Gurgaon  12.5  DISCHARGING_ACTIVE        3  2025-09-01   \n",
       "3  16  HR55AY9237  ZB Gurgaon  12.5     CHARGING_ACTIVE        4  2025-09-01   \n",
       "4  16  HR55AY9237  ZB Gurgaon  12.5  DISCHARGING_ACTIVE        5  2025-09-01   \n",
       "\n",
       "            start_time             end_time  duration_mins  charging_pct  \\\n",
       "0  2025-09-01 05:30:00  2025-09-01 05:37:36           7.59          0.00   \n",
       "1  2025-09-01 05:39:01  2025-09-01 07:22:50         103.81         96.58   \n",
       "2  2025-09-01 07:23:05  2025-09-01 18:00:51         637.76         15.96   \n",
       "3  2025-09-01 18:00:52  2025-09-01 20:32:22         151.50         82.09   \n",
       "4  2025-09-01 20:32:23  2025-09-01 23:59:59         207.60         13.15   \n",
       "\n",
       "   discharging_pct  motion_pct  lv_pct  off_pct  kwh_charging  \\\n",
       "0            94.85        0.00   10.58    89.42          0.00   \n",
       "1             2.13        0.00    0.00     0.03        302.52   \n",
       "2            68.81       65.57   13.98     1.42        108.84   \n",
       "3             5.44        0.00    0.00     6.19        357.59   \n",
       "4            81.61       62.56    4.06    10.00         33.05   \n",
       "\n",
       "   kwh_discharging  charge_rate  discharge_rate  soc_start  soc_end  soc_gain  \\\n",
       "0             4.18        0.000           0.082       33.2     33.2       0.0   \n",
       "1             0.12        0.427           0.008       33.2    100.0      66.8   \n",
       "2           439.01        0.152           0.137      100.0     22.4       0.0   \n",
       "3             5.61        0.407           0.098       22.4    100.0      77.6   \n",
       "4           135.19        0.167           0.110      100.0     76.8       0.0   \n",
       "\n",
       "   soc_drop  glitch_flag glitch_reason  maxtemp_bucket_lt28_pct  \\\n",
       "0       0.0        False                                   9.05   \n",
       "1       0.0        False                                   0.00   \n",
       "2      77.6        False                                   8.47   \n",
       "3       0.0        False                                   0.05   \n",
       "4      23.2        False                                  63.30   \n",
       "\n",
       "   maxtemp_bucket_28_32_pct  maxtemp_bucket_32_35_pct  \\\n",
       "0                     35.99                     54.96   \n",
       "1                     10.99                     35.29   \n",
       "2                     88.29                      3.23   \n",
       "3                     60.10                     39.85   \n",
       "4                     36.70                      0.00   \n",
       "\n",
       "   maxtemp_bucket_35_40_pct  maxtemp_bucket_gt40_pct  \\\n",
       "0                      0.00                      0.0   \n",
       "1                     53.72                      0.0   \n",
       "2                      0.00                      0.0   \n",
       "3                      0.00                      0.0   \n",
       "4                      0.00                      0.0   \n",
       "\n",
       "   temp_delta_bucket_lt2_pct  temp_delta_bucket_2_5_pct  \\\n",
       "0                      45.04                      16.90   \n",
       "1                      12.47                      12.65   \n",
       "2                       3.16                      88.25   \n",
       "3                       1.53                       6.73   \n",
       "4                       0.00                      99.81   \n",
       "\n",
       "   temp_delta_bucket_5_8_pct  temp_delta_bucket_gt8_pct  \\\n",
       "0                      38.06                       0.00   \n",
       "1                      74.86                       0.02   \n",
       "2                       8.59                       0.00   \n",
       "3                      91.75                       0.00   \n",
       "4                       0.19                       0.00   \n",
       "\n",
       "   volt_delta_bucket_0_10_pct  volt_delta_bucket_10_20_pct  \\\n",
       "0                       75.10                        24.55   \n",
       "1                       11.26                        61.32   \n",
       "2                       90.08                         7.73   \n",
       "3                       19.61                        49.31   \n",
       "4                       68.19                        11.62   \n",
       "\n",
       "   volt_delta_bucket_20_30_pct  volt_delta_bucket_gt30_pct  \\\n",
       "0                         0.34                        0.00   \n",
       "1                        12.12                       15.30   \n",
       "2                         1.18                        1.01   \n",
       "3                        13.64                       17.44   \n",
       "4                         2.98                       17.21   \n",
       "\n",
       "   soc_band_bucket_0_10_pct  soc_band_bucket_10_20_pct  \\\n",
       "0                       0.0                        0.0   \n",
       "1                       0.0                        0.0   \n",
       "2                       0.0                        0.0   \n",
       "3                       0.0                        0.0   \n",
       "4                       0.0                        0.0   \n",
       "\n",
       "   soc_band_bucket_20_30_pct  soc_band_bucket_30_40_pct  \\\n",
       "0                      55.74                      44.26   \n",
       "1                       4.49                      12.87   \n",
       "2                       2.28                      14.70   \n",
       "3                      21.37                      15.94   \n",
       "4                       0.00                       0.00   \n",
       "\n",
       "   soc_band_bucket_40_50_pct  soc_band_bucket_50_60_pct  \\\n",
       "0                       0.00                       0.00   \n",
       "1                      14.93                      20.93   \n",
       "2                      30.90                      22.15   \n",
       "3                       7.52                       7.70   \n",
       "4                       0.00                       0.00   \n",
       "\n",
       "   soc_band_bucket_60_70_pct  soc_band_bucket_70_80_pct  \\\n",
       "0                       0.00                       0.00   \n",
       "1                       8.68                       8.16   \n",
       "2                       4.94                       4.18   \n",
       "3                      13.18                       7.59   \n",
       "4                       0.00                       7.91   \n",
       "\n",
       "   soc_band_bucket_80_90_pct  soc_band_bucket_90_100_pct  dist_km  avg_speed  \\\n",
       "0                       0.00                        0.00    0.000       0.00   \n",
       "1                      12.12                       17.82    0.000       0.00   \n",
       "2                       6.50                       14.36  330.250      34.92   \n",
       "3                       8.94                       17.77    0.000       0.00   \n",
       "4                      28.49                       63.59  129.625      35.68   \n",
       "\n",
       "   med_speed  max_speed  avg_volt_delta_mv  med_volt_delta_mv  \\\n",
       "0       0.00       0.00               0.00                0.0   \n",
       "1       0.00       0.00               0.00                0.0   \n",
       "2      32.79      85.61               8.52                7.0   \n",
       "3       0.00       0.00               0.00                0.0   \n",
       "4      37.14      97.96              14.96                7.0   \n",
       "\n",
       "   max_volt_delta_mv  p95_volt_delta_mv  avg_batt_temp_delta  \\\n",
       "0                0.0                0.0                 0.00   \n",
       "1                0.0                0.0                 0.00   \n",
       "2               96.0               22.0                 4.61   \n",
       "3                0.0                0.0                 0.00   \n",
       "4              101.0               56.0                 4.20   \n",
       "\n",
       "   med_batt_temp_delta  max_batt_temp_delta  p95_batt_temp_delta  \\\n",
       "0                  0.0                  0.0                  0.0   \n",
       "1                  0.0                  0.0                  0.0   \n",
       "2                  5.0                  7.0                  6.0   \n",
       "3                  0.0                  0.0                  0.0   \n",
       "4                  4.0                  6.0                  5.0   \n",
       "\n",
       "   energy_active_kwh  kwh_per_km  odo_start   odo_end  net_odo_km  \\\n",
       "0               0.00         NaN        NaN       NaN       0.000   \n",
       "1               0.00         NaN        NaN       NaN       0.000   \n",
       "2             372.52        1.13    8679.00  9009.250     330.250   \n",
       "3               0.00         NaN        NaN       NaN       0.000   \n",
       "4             115.18        0.89    9009.25  9133.875     124.625   \n",
       "\n",
       "   dist_km_raw  max_physical_km  \n",
       "0        0.000            0.000  \n",
       "1        0.000            0.000  \n",
       "2      330.250          818.035  \n",
       "3        0.000            0.000  \n",
       "4      129.625          303.834  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charge_discharge_df[charge_discharge_df.id == '16'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "afab41c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "charge_discharge_df.to_excel('charge_discharge_analysis.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f0fcabb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3091.000000\n",
       "mean      292.096720\n",
       "std       164.559055\n",
       "min         2.780000\n",
       "50%       271.660000\n",
       "90%       495.630000\n",
       "95%       616.235000\n",
       "99%       835.033000\n",
       "max      1439.960000\n",
       "Name: duration_mins, dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charge_discharge_df[charge_discharge_df.activity == 'DISCHARGING_ACTIVE'].duration_mins.describe(percentiles=[0.5, 0.9, 0.95, 0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8fb8843b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       28.000000\n",
       "mean     32245.391429\n",
       "std      24811.879779\n",
       "min          4.240000\n",
       "10%        852.435000\n",
       "20%       5279.746000\n",
       "30%      14310.865000\n",
       "40%      25110.724000\n",
       "50%      25786.395000\n",
       "60%      30952.718000\n",
       "70%      54857.203000\n",
       "80%      60447.466000\n",
       "90%      65007.077000\n",
       "95%      68144.179000\n",
       "99%      70052.662200\n",
       "max      70148.010000\n",
       "Name: duration_mins, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charge_discharge_df[charge_discharge_df.activity == 'DISCHARGING_ACTIVE'].groupby(['id',])['duration_mins'].sum().describe(percentiles=[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9, 0.95, 0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "26c7d763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2747.000000\n",
       "mean      184.434183\n",
       "std        90.291079\n",
       "min         0.420000\n",
       "50%       202.740000\n",
       "90%       288.998000\n",
       "95%       312.541000\n",
       "99%       365.740400\n",
       "99.9%     469.736620\n",
       "max       634.250000\n",
       "Name: kwh_charging, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charge_discharge_df[charge_discharge_df.activity == 'CHARGING_ACTIVE'].kwh_charging.describe(percentiles=[0.5, 0.9, 0.95, 0.99,0.999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "863edf03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>charge_rate</th>\n",
       "      <th>discharge_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2747.000000</td>\n",
       "      <td>2747.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.458489</td>\n",
       "      <td>0.008691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.094900</td>\n",
       "      <td>0.013200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.485000</td>\n",
       "      <td>0.009000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>0.544000</td>\n",
       "      <td>0.014000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>0.551000</td>\n",
       "      <td>0.017000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99%</th>\n",
       "      <td>0.561000</td>\n",
       "      <td>0.025540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99.9%</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.133842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.662000</td>\n",
       "      <td>0.494000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       charge_rate  discharge_rate\n",
       "count  2747.000000     2747.000000\n",
       "mean      0.458489        0.008691\n",
       "std       0.094900        0.013200\n",
       "min       0.052000        0.000000\n",
       "50%       0.485000        0.009000\n",
       "90%       0.544000        0.014000\n",
       "95%       0.551000        0.017000\n",
       "99%       0.561000        0.025540\n",
       "99.9%     0.600000        0.133842\n",
       "max       0.662000        0.494000"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charge_discharge_df[charge_discharge_df.activity == 'CHARGING_ACTIVE'][['charge_rate','discharge_rate']].describe(percentiles=[0.5, 0.9, 0.95, 0.99,0.999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ce7fed51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>charge_rate</th>\n",
       "      <th>discharge_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3091.000000</td>\n",
       "      <td>3091.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.117675</td>\n",
       "      <td>0.133911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.027075</td>\n",
       "      <td>0.036808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.117000</td>\n",
       "      <td>0.137000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>0.151000</td>\n",
       "      <td>0.178000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.189000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99%</th>\n",
       "      <td>0.182100</td>\n",
       "      <td>0.215200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99.9%</th>\n",
       "      <td>0.209820</td>\n",
       "      <td>0.257650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.392000</td>\n",
       "      <td>0.272000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       charge_rate  discharge_rate\n",
       "count  3091.000000     3091.000000\n",
       "mean      0.117675        0.133911\n",
       "std       0.027075        0.036808\n",
       "min       0.000000        0.007000\n",
       "50%       0.117000        0.137000\n",
       "90%       0.151000        0.178000\n",
       "95%       0.160000        0.189000\n",
       "99%       0.182100        0.215200\n",
       "99.9%     0.209820        0.257650\n",
       "max       0.392000        0.272000"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charge_discharge_df[charge_discharge_df.activity == 'DISCHARGING_ACTIVE'][['charge_rate','discharge_rate']].describe(percentiles=[0.5, 0.9, 0.95, 0.99,0.999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e1ecfd8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'reg_num', 'customer', 'model', 'activity', 'session', 'date',\n",
       "       'start_time', 'end_time', 'duration_mins', 'charging_pct',\n",
       "       'discharging_pct', 'motion_pct', 'lv_pct', 'off_pct', 'kwh_charging',\n",
       "       'kwh_discharging', 'charge_rate', 'discharge_rate', 'soc_start',\n",
       "       'soc_end', 'soc_gain', 'soc_drop', 'glitch_flag', 'glitch_reason',\n",
       "       'maxtemp_bucket_lt28_pct', 'maxtemp_bucket_28_32_pct',\n",
       "       'maxtemp_bucket_32_35_pct', 'maxtemp_bucket_35_40_pct',\n",
       "       'maxtemp_bucket_gt40_pct', 'temp_delta_bucket_lt2_pct',\n",
       "       'temp_delta_bucket_2_5_pct', 'temp_delta_bucket_5_8_pct',\n",
       "       'temp_delta_bucket_gt8_pct', 'volt_delta_bucket_0_10_pct',\n",
       "       'volt_delta_bucket_10_20_pct', 'volt_delta_bucket_20_30_pct',\n",
       "       'volt_delta_bucket_gt30_pct', 'soc_band_bucket_0_10_pct',\n",
       "       'soc_band_bucket_10_20_pct', 'soc_band_bucket_20_30_pct',\n",
       "       'soc_band_bucket_30_40_pct', 'soc_band_bucket_40_50_pct',\n",
       "       'soc_band_bucket_50_60_pct', 'soc_band_bucket_60_70_pct',\n",
       "       'soc_band_bucket_70_80_pct', 'soc_band_bucket_80_90_pct',\n",
       "       'soc_band_bucket_90_100_pct', 'dist_km', 'avg_speed', 'med_speed',\n",
       "       'max_speed', 'avg_volt_delta_mv', 'med_volt_delta_mv',\n",
       "       'max_volt_delta_mv', 'p95_volt_delta_mv', 'avg_batt_temp_delta',\n",
       "       'med_batt_temp_delta', 'max_batt_temp_delta', 'p95_batt_temp_delta',\n",
       "       'energy_active_kwh', 'kwh_per_km', 'odo_start', 'odo_end', 'net_odo_km',\n",
       "       'dist_km_raw', 'max_physical_km'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charge_discharge_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e6ec6c70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration%</th>\n",
       "      <th>lower</th>\n",
       "      <th>upper</th>\n",
       "      <th>num_vehicles</th>\n",
       "      <th>vehicle_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20â€“30%</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 24, 25, 26, 27, 28, 29, 3, 30, 31, 32, 33, 41, 42, 46, 6, 7, 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30â€“40%</td>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>28</td>\n",
       "      <td>10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 22, 24, 25, 26, 27, 28, 29, 3, 30, 31, 32, 33, 41, 42, 46, 6, 7, 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&gt;40%</td>\n",
       "      <td>40</td>\n",
       "      <td>âˆž</td>\n",
       "      <td>27</td>\n",
       "      <td>10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 22, 25, 26, 27, 28, 29, 3, 30, 31, 32, 33, 41, 42, 46, 6, 7, 9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  duration%  lower upper  num_vehicles  \\\n",
       "0    20â€“30%     20    30            29   \n",
       "1    30â€“40%     30    40            28   \n",
       "2      >40%     40     âˆž            27   \n",
       "\n",
       "                                                                                                      vehicle_ids  \n",
       "0  10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 24, 25, 26, 27, 28, 29, 3, 30, 31, 32, 33, 41, 42, 46, 6, 7, 9  \n",
       "1      10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 22, 24, 25, 26, 27, 28, 29, 3, 30, 31, 32, 33, 41, 42, 46, 6, 7, 9  \n",
       "2          10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 22, 25, 26, 27, 28, 29, 3, 30, 31, 32, 33, 41, 42, 46, 6, 7, 9  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration%</th>\n",
       "      <th>lower</th>\n",
       "      <th>upper</th>\n",
       "      <th>num_vehicles</th>\n",
       "      <th>vehicle_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20â€“30%</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>28</td>\n",
       "      <td>10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 22, 24, 25, 26, 27, 28, 29, 3, 30, 31, 32, 33, 41, 42, 46, 6, 7, 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30â€“40%</td>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>23</td>\n",
       "      <td>10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 25, 27, 28, 29, 3, 30, 31, 33, 46, 6, 7, 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&gt;40%</td>\n",
       "      <td>40</td>\n",
       "      <td>âˆž</td>\n",
       "      <td>18</td>\n",
       "      <td>11, 12, 13, 14, 15, 16, 18, 19, 20, 27, 28, 29, 3, 31, 33, 6, 7, 9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  duration%  lower upper  num_vehicles  \\\n",
       "0    20â€“30%     20    30            28   \n",
       "1    30â€“40%     30    40            23   \n",
       "2      >40%     40     âˆž            18   \n",
       "\n",
       "                                                                                                  vehicle_ids  \n",
       "0  10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 22, 24, 25, 26, 27, 28, 29, 3, 30, 31, 32, 33, 41, 42, 46, 6, 7, 9  \n",
       "1                      10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 25, 27, 28, 29, 3, 30, 31, 33, 46, 6, 7, 9  \n",
       "2                                          11, 12, 13, 14, 15, 16, 18, 19, 20, 27, 28, 29, 3, 31, 33, 6, 7, 9  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration%</th>\n",
       "      <th>lower</th>\n",
       "      <th>upper</th>\n",
       "      <th>num_vehicles</th>\n",
       "      <th>vehicle_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35â€“40%</td>\n",
       "      <td>35</td>\n",
       "      <td>40</td>\n",
       "      <td>26</td>\n",
       "      <td>10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 25, 26, 27, 28, 29, 3, 30, 31, 32, 33, 42, 46, 6, 7, 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&gt;40%</td>\n",
       "      <td>40</td>\n",
       "      <td>âˆž</td>\n",
       "      <td>23</td>\n",
       "      <td>11, 12, 13, 14, 15, 16, 18, 19, 20, 25, 27, 28, 29, 3, 30, 31, 32, 33, 42, 46, 6, 7, 9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  duration%  lower upper  num_vehicles  \\\n",
       "0    35â€“40%     35    40            26   \n",
       "1      >40%     40     âˆž            23   \n",
       "\n",
       "                                                                                          vehicle_ids  \n",
       "0  10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 25, 26, 27, 28, 29, 3, 30, 31, 32, 33, 42, 46, 6, 7, 9  \n",
       "1              11, 12, 13, 14, 15, 16, 18, 19, 20, 25, 27, 28, 29, 3, 30, 31, 32, 33, 42, 46, 6, 7, 9  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def extract_bucket_vehicle_lists(\n",
    "    df,\n",
    "    bucket_cols,\n",
    "    ranges,\n",
    "    id_col=\"id\",\n",
    "):\n",
    "    \"\"\"\n",
    "    df            : charge_discharge_df\n",
    "    bucket_cols   : list of bucket percentage columns (e.g., [\"temp_delta_bucket_5_8_pct\", \"temp_delta_bucket_gt8_pct\"])\n",
    "    ranges        : list of tuples (label, LOWER, UPPER or None)\n",
    "                     Example:\n",
    "                       [(\"20-30%\", 20, 30),\n",
    "                        (\"30-40%\", 30, 40),\n",
    "                        (\">40%\", 40, None)]\n",
    "\n",
    "    Returns: DataFrame with one row per range.\n",
    "    \"\"\"\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    for label, low, high in ranges:\n",
    "        # Build condition for all bucket columns\n",
    "        cond = False\n",
    "        for col in bucket_cols:\n",
    "            if high is None:\n",
    "                cond |= (df[col] >= low)\n",
    "            else:\n",
    "                cond |= (df[col].between(low, high))\n",
    "\n",
    "        matched_ids = sorted(df.loc[cond, id_col].unique())\n",
    "\n",
    "        rows.append({\n",
    "            \"duration%\": label,\n",
    "            \"lower\": low,\n",
    "            \"upper\": high if high is not None else \"âˆž\",\n",
    "            \"num_vehicles\": len(matched_ids),\n",
    "            \"vehicle_ids\": \", \".join(matched_ids),\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "##Delta Temperature Buckets\n",
    "bucket_cols = [\n",
    "    \"temp_delta_bucket_5_8_pct\",\n",
    "    \"temp_delta_bucket_gt8_pct\"\n",
    "]\n",
    "\n",
    "ranges = [\n",
    "    (\"20â€“30%\", 20, 30),\n",
    "    (\"30â€“40%\", 30, 40),\n",
    "    (\">40%\", 40, None)\n",
    "]\n",
    "\n",
    "result = extract_bucket_vehicle_lists(charge_discharge_df, bucket_cols, ranges)\n",
    "display(result)\n",
    "\n",
    "##Voltage Delta Buckets\n",
    "bucket_cols = [\n",
    "    \"volt_delta_bucket_20_30_pct\",\n",
    "    \"volt_delta_bucket_gt30_pct\"\n",
    "]\n",
    "ranges = [\n",
    "    (\"20â€“30%\", 20, 30),\n",
    "    (\"30â€“40%\", 30, 40),\n",
    "    (\">40%\", 40, None)\n",
    "]   \n",
    "result = extract_bucket_vehicle_lists(charge_discharge_df, bucket_cols, ranges)\n",
    "display(result) \n",
    "\n",
    "#maxtemp_bucket\n",
    "bucket_cols = [\n",
    "    \"maxtemp_bucket_35_40_pct\",\n",
    "    \"maxtemp_bucket_gt40_pct\"\n",
    "]\n",
    "ranges = [\n",
    "    (\"35â€“40%\", 35, 40),\n",
    "    (\">40%\", 40, None)\n",
    "]   \n",
    "result = extract_bucket_vehicle_lists(charge_discharge_df, bucket_cols, ranges)\n",
    "display(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "naarni_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
