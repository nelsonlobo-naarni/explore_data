{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e5118c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import ctypes\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import platform\n",
    "import logging\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "from typing import Optional\n",
    "import shutil\n",
    "import zipfile\n",
    "import duckdb \n",
    "import warnings\n",
    "import fastparquet\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# Optional: adjust pandas display for debugging; you can comment these out\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed3575c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded mapping table with 27 entries.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>reg_num</th>\n",
       "      <th>customer</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>AP39WF8593</td>\n",
       "      <td>FB Guntur</td>\n",
       "      <td>12.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>AP39WG0252</td>\n",
       "      <td>FB Guntur</td>\n",
       "      <td>12.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>AP39WF8589</td>\n",
       "      <td>FB Guntur</td>\n",
       "      <td>12.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>AP39WF8584</td>\n",
       "      <td>FB Guntur</td>\n",
       "      <td>12.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>AP39WG0271</td>\n",
       "      <td>FB Guntur</td>\n",
       "      <td>12.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     reg_num   customer  model\n",
       "0  11  AP39WF8593  FB Guntur   12.5\n",
       "1   9  AP39WG0252  FB Guntur   12.5\n",
       "2   7  AP39WF8589  FB Guntur   12.5\n",
       "3  13  AP39WF8584  FB Guntur   12.5\n",
       "4  14  AP39WG0271  FB Guntur   12.5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_file = \"../../../data_points/Naarni VehicleID_RegNo_links - Vehicle_mapping.csv\"\n",
    "try:\n",
    "    df_mapping = pd.read_csv(mapping_file)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Mapping file '{mapping_file}' not found. Cannot enrich data.\")\n",
    "    # Create an empty mapping table to allow the rest of the script to run without crashing\n",
    "    df_mapping = pd.DataFrame(columns=[\"id\", \"reg_num\", \"customer\", \"model\"])\n",
    "else:\n",
    "    df_mapping = df_mapping.rename(columns={\n",
    "        \"Device No.\": \"id\",\n",
    "        \"Registration No\": \"reg_num\",\n",
    "        \"Customer\": \"customer\",\n",
    "        \"Model\": \"model\"\n",
    "    })\n",
    "    # Ensure the merge key ('id') is a string to match the chunks\n",
    "    if \"id\" in df_mapping.columns:\n",
    "        df_mapping[\"id\"] = df_mapping[\"id\"].astype(str)\n",
    "        df_mapping = df_mapping[[\"id\", \"reg_num\", \"customer\", \"model\"]]\n",
    "    else:\n",
    "        print(\"Warning: 'Device No.' column not found in mapping file.\")\n",
    "        df_mapping = pd.DataFrame(columns=[\"id\", \"reg_num\", \"customer\", \"model\"])\n",
    "\n",
    "print(f\"Loaded mapping table with {len(df_mapping)} entries.\")\n",
    "# df_mapping is now ready to be passed into the processing function\n",
    "\n",
    "df_mapping.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0cf6c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "CORE_COLS = [\n",
    "    \"id\", \"timestamp\", \"dt\",\n",
    "    \"vehiclereadycondition\", \"gun_connection_status\", \"ignitionstatus\",\n",
    "    \"vehicle_speed_vcu\", \"gear_position\",\n",
    "    \"bat_soc\", \"soh\", \"total_battery_current\",\n",
    "    \"pack1_cellmax_temperature\", \"pack1_cell_min_temperature\",\n",
    "    \"pack1_maxtemperature_cell_number\", \"pack1_celltemperature_cellnumber\",\n",
    "    \"bat_voltage\", \"cellmax_voltagecellnumber\", \"cellminvoltagecellnumber\", \n",
    "    \"cell_min_voltage\",\"cell_max_voltage\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7067d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def free_mem():\n",
    "    \"\"\"Try to return freed memory back to the OS (no-op on some platforms).\"\"\"\n",
    "    try:\n",
    "        libc = ctypes.CDLL(None)\n",
    "        if hasattr(libc, \"malloc_trim\"):\n",
    "            libc.malloc_trim(0)\n",
    "    except Exception:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d35fd70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_battery_temp_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Uses df.rename(inplace=False), creating one copy, which is fine for chunks\n",
    "    rename_map = {\n",
    "        \"pack1_cellmax_temperature\": \"batt_maxtemp\",\n",
    "        \"pack1_cell_min_temperature\": \"batt_mintemp\",\n",
    "        \"pack1_maxtemperature_cell_number\":\"batt_maxtemp_tc\", \n",
    "        \"pack1_celltemperature_cellnumber\":\"batt_mintemp_tc\",\n",
    "        \"cell_max_voltage\":\"batt_maxvolt\",\n",
    "        \"cellmax_voltagecellnumber\":\"batt_maxvolt_cell\",\n",
    "        \"cell_min_voltage\":\"batt_minvolt\",\n",
    "        \"cellminvoltagecellnumber\":\"batt_minvolt_cell\", \n",
    "    }\n",
    "    existing = {k: v for k, v in rename_map.items() if k in df.columns}\n",
    "    if not existing:\n",
    "        return df\n",
    "    return df.rename(columns=existing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12c43ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing_values(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # This uses df.loc, which *can* cause copies but is the necessary imputation logic\n",
    "    df = df.sort_values([\"id\", \"timestamp\"])\n",
    "    for vid, grp in df.groupby(\"id\", sort=False):\n",
    "        idx = grp.index\n",
    "        # Imputation logic...\n",
    "        for col, limit in [(\"batt_maxtemp\", 60), (\"batt_mintemp\", 60), \n",
    "                           (\"batt_maxtemp_tc\",60),(\"batt_mintemp_tc\",60),\n",
    "                           (\"batt_maxvolt\", 30), (\"batt_minvolt\", 30), \n",
    "                           (\"batt_maxvolt_cell\",30),(\"batt_minvolt_cell\",30),\n",
    "                           (\"bat_voltage\", 20), (\"bat_soc\", 300), (\"soh\", 300)]:\n",
    "            if col in df.columns:\n",
    "                df.loc[idx, col] = grp[col].ffill(limit=limit)\n",
    "        \n",
    "        if \"total_battery_current\" in df.columns:\n",
    "            df.loc[idx, \"total_battery_current\"] = grp[\"total_battery_current\"].interpolate(\n",
    "                limit=10, limit_direction=\"both\"\n",
    "            )\n",
    "        for col in [\"vehiclereadycondition\", \"gun_connection_status\"]:\n",
    "            if col in df.columns:\n",
    "                 df.loc[idx, col] = grp[col].ffill().bfill()\n",
    "\n",
    "    return df # Returns the modified chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92a1c397",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_df_with_state(df: pd.DataFrame, df_mapping:pd.DataFrame) -> pd.DataFrame:\n",
    "    # CRITICAL: This line creates the necessary copy, but now it's only a small chunk!\n",
    "    out = df.copy() \n",
    "    \n",
    "    # 1. Merge Vehicle Information\n",
    "    out[\"id\"] = out[\"id\"].astype(str) # Ensure merge key type consistency\n",
    "    out = out.merge(\n",
    "        df_mapping, \n",
    "        on=\"id\", \n",
    "        how=\"left\", \n",
    "        validate=\"m:1\"\n",
    "    )\n",
    "\n",
    "    # --- NEW: Fill Missing Mapping Information ---\n",
    "    # Create the standby values based on the 'id' column for rows where the merge failed (NaNs)\n",
    "    \n",
    "    # 1a. Fill 'reg_num'\n",
    "    # Use .mask to replace NaN only where 'reg_num' is NaN, using the formatted ID\n",
    "    out[\"reg_num\"] = out[\"reg_num\"].mask(\n",
    "        out[\"reg_num\"].isna(), \n",
    "        \"REGNUM_\" + out[\"id\"].astype(str)\n",
    "    )\n",
    "    \n",
    "    # 1b. Fill 'customer'\n",
    "    out[\"customer\"] = out[\"customer\"].mask(\n",
    "        out[\"customer\"].isna(), \n",
    "        \"CUST_\" + out[\"id\"].astype(str)\n",
    "    )\n",
    "\n",
    "    # 1c. Fill 'model'\n",
    "    out[\"model\"] = out[\"model\"].mask(\n",
    "        out[\"model\"].isna(), \n",
    "        \"MDL_\" + out[\"id\"].astype(str)\n",
    "    )    \n",
    "    \n",
    "    # --- CRITICAL FIX: Ensure new columns are explicitly string type for PyArrow ---\n",
    "    out[\"reg_num\"] = out[\"reg_num\"].astype(str)\n",
    "    out[\"customer\"] = out[\"customer\"].astype(str)\n",
    "    out[\"model\"] = out[\"model\"].astype(str)\n",
    "    # -----------------------------------------------------------------------------\n",
    "\n",
    "    # 2. Basic Cleanup & Sorting\n",
    "    # --- NEW: TIMEZONE CONVERSION TO IST ---\n",
    "    # Assuming the original timestamps are stored as naive UTC time\n",
    "    out[\"timestamp\"] = (\n",
    "        out[\"timestamp\"]\n",
    "        .dt.tz_localize(\"UTC\")\n",
    "        .dt.tz_convert(\"Asia/Kolkata\")\n",
    "    )    \n",
    "    out[\"timestamp\"] = pd.to_datetime(out[\"timestamp\"], errors=\"coerce\")\n",
    "    out = out.dropna(subset=[\"timestamp\"]).sort_values([\"id\", \"timestamp\"]).reset_index(drop=True)\n",
    "    \n",
    "    # 3. Mode calculation\n",
    "    gcs_raw = out[\"gun_connection_status\"]\n",
    "    gcs_num = pd.to_numeric(gcs_raw, errors=\"coerce\")\n",
    "    gcs_str = gcs_raw.astype(str).str.strip().str.lower()\n",
    "    gun_connected = (gcs_num == 1) | gcs_str.isin({\"1\", \"true\", \"yes\", \"y\", \"connected\", \"on\"})\n",
    "    out[\"mode\"] = np.where(gun_connected, \"CHARGING\", \"DISCHARGING\")\n",
    "    \n",
    "    # 4. Delta calculations\n",
    "    for col in [\"batt_maxtemp\", \"batt_mintemp\", \"batt_maxvolt\", \"batt_minvolt\"]:\n",
    "        if col in out.columns:\n",
    "            out[col] = pd.to_numeric(out[col], errors=\"coerce\")\n",
    "            \n",
    "    out[\"batt_temp_delta\"] = out[\"batt_maxtemp\"] - out[\"batt_mintemp\"]\n",
    "    out[\"volt_delta_mv\"] = round((out[\"batt_maxvolt\"] - out[\"batt_minvolt\"]) * 1000.0,0)\n",
    "    out[\"dt_sec\"] = out.groupby(\"id\")[\"timestamp\"].diff().dt.total_seconds().fillna(0)\n",
    "    \n",
    "    # 5. --- NEW: Create Feature Buckets (Binning) ---\n",
    "    temp_bins = [-np.inf, 28, 32, 35, 40, np.inf]\n",
    "    temp_labels = [\"<28\", \"28â€“32\", \"32â€“35\", \"35â€“40\", \">40\"]\n",
    "\n",
    "    delta_bins = [-np.inf, 2, 5, 8, np.inf]\n",
    "    delta_labels = [\"<2\", \"2â€“5\", \"5â€“8\", \">8\"]\n",
    "\n",
    "    volt_bins = [0, 10, 20, 30, np.inf]\n",
    "    volt_labels = [\"0â€“10\", \"10â€“20\", \"20â€“30\", \">30\"]\n",
    "    \n",
    "    # **NOTE:** Corrected df to use the local working DataFrame 'out'\n",
    "    out[\"maxtemp_bucket\"] = pd.cut(out[\"batt_maxtemp\"], bins=temp_bins, labels=temp_labels)\n",
    "    out[\"temp_delta_bucket\"] = pd.cut(out[\"batt_temp_delta\"], bins=delta_bins, labels=delta_labels)\n",
    "    out[\"volt_delta_bucket\"] = pd.cut(out[\"volt_delta_mv\"], bins=volt_bins, labels=volt_labels)\n",
    "    # -------------------------------------------------\n",
    "\n",
    "    cols_keep = [\n",
    "        \"id\", \"reg_num\",\"customer\",\"model\",\"timestamp\",\"dt_sec\",\"mode\",\n",
    "        \"vehiclereadycondition\", \"gun_connection_status\",\n",
    "        \"batt_maxtemp\", \"batt_mintemp\", \"batt_temp_delta\",\"maxtemp_bucket\",\"temp_delta_bucket\",\n",
    "        \"batt_maxvolt\", \"batt_minvolt\", \"volt_delta_mv\",\"volt_delta_bucket\",\n",
    "        \"batt_maxtemp_tc\",\"batt_mintemp_tc\",\n",
    "        \"batt_maxvolt_cell\",\"batt_minvolt_cell\",\n",
    "        \"bat_voltage\", \"total_battery_current\",\n",
    "        \"bat_soc\", \"soh\",\n",
    "    ]\n",
    "    cols_keep = [c for c in cols_keep if c in out.columns]\n",
    "    # This final filter also creates a copy, but again, only of the small chunk\n",
    "    out = out[cols_keep]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e2e67c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- DUCKDB CHUNK GENERATOR (Fixed) ---\n",
    "\n",
    "def duckdb_chunk_generator(conn, sql_query, chunk_size):\n",
    "    \"\"\"Generates Pandas DataFrames in chunks directly from DuckDB cursor.\"\"\"\n",
    "    cursor = conn.cursor() \n",
    "    cursor.execute(sql_query)\n",
    "    \n",
    "    while True:\n",
    "        # Uses the corrected method name: fetch_df_chunk\n",
    "        chunk = cursor.fetch_df_chunk(chunk_size) \n",
    "        if chunk is None or chunk.empty:\n",
    "            break\n",
    "        yield chunk\n",
    "\n",
    "# --- ROBUST FILE EXTRACTION (Fixed from OSErrors) ---\n",
    "\n",
    "def extract_files_to_disk(zip_path, output_dir):\n",
    "    \"\"\"Cleans directory and extracts all Parquet files from ZIP.\"\"\"\n",
    "    if output_dir.exists():\n",
    "        logging.info(f\"ðŸ§¹ Clearing existing directory: {output_dir.resolve()}\")\n",
    "        # Robust cleanup to avoid OS/lock issues\n",
    "        try:\n",
    "            shutil.rmtree(output_dir)\n",
    "        except OSError:\n",
    "             for item in output_dir.iterdir():\n",
    "                if item.is_dir():\n",
    "                    shutil.rmtree(item)\n",
    "                else:\n",
    "                    os.remove(item) \n",
    "             os.rmdir(output_dir)\n",
    "\n",
    "    output_dir.mkdir(parents=True)\n",
    "        \n",
    "    logging.info(\"ðŸ”„ Extracting ALL Parquet files from ZIP to disk...\")\n",
    "    try:\n",
    "        with zipfile.ZipFile(zip_path, \"r\") as z:\n",
    "            all_files_to_extract = [f for f in z.namelist() if f.endswith(\".parquet\")]\n",
    "            logging.info(f\"ðŸ”Ž Found {len(all_files_to_extract)} total Parquet files in archive.\")\n",
    "            for filename in all_files_to_extract:\n",
    "                z.extract(filename, path=output_dir)\n",
    "            return len(all_files_to_extract)\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"âŒ ZIP file not found at: {zip_path}\") from None\n",
    "\n",
    "def setup_duckdb_query(output_dir, utc_start, utc_end, core_cols):\n",
    "    \"\"\"Sets up DuckDB connection and SQL query.\"\"\"\n",
    "    parquet_glob_path = str(output_dir.joinpath(\"**/*.parquet\"))\n",
    "    # Only select the columns you need for Stage 1 processing\n",
    "    column_list = \", \".join([f'\"{c}\"' for c in core_cols])\n",
    "    \n",
    "    # CRITICAL: Predicate Pushdown filter on the internal 'timestamp' column\n",
    "    sql_query = f\"\"\"\n",
    "        SELECT {column_list}\n",
    "        FROM read_parquet('{parquet_glob_path}')\n",
    "        WHERE \n",
    "            \"timestamp\" >= '{utc_start.isoformat()}' AND \n",
    "            \"timestamp\" < '{utc_end.isoformat()}'\n",
    "    \"\"\"\n",
    "    return duckdb.connect(), sql_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3dc1a962",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_stage1_data_setup(analysis_start_date_str: str, \n",
    "                          analysis_end_date_str: str, \n",
    "                          zip_path: Path, \n",
    "                          extraction_dir: Path,\n",
    "                          force_extraction: bool = False) -> tuple[datetime, datetime, int]:\n",
    "    \"\"\"\n",
    "    Handles date range setup, IST-to-UTC conversion, file extraction, \n",
    "    and checks if data is available for processing.\n",
    "    \n",
    "    Args:\n",
    "        analysis_start_date_str: Start date in YYYY-MM-DD format.\n",
    "        analysis_end_date_str: End date in YYYY-MM-DD format.\n",
    "        zip_path: Path to the source ZIP file.\n",
    "        extraction_dir: Target directory for extracted Parquet files.\n",
    "        force_extraction: If True, always clean and re-extract files. \n",
    "                          If False, skips extraction if the directory exists.\n",
    "    \n",
    "    Returns: (utc_start, utc_end, file_count)\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Date Parsing and UTC Conversion (Assuming +5:30 IST offset)\n",
    "    target_date = datetime.strptime(analysis_start_date_str, \"%Y-%m-%d\").date()\n",
    "    ist_start = datetime.combine(target_date, datetime.min.time())\n",
    "    \n",
    "    end_date_obj = datetime.strptime(analysis_end_date_str, \"%Y-%m-%d\").date()\n",
    "    ist_end = datetime.combine(end_date_obj, datetime.min.time()) + timedelta(days=1)\n",
    "    \n",
    "    utc_start = ist_start - timedelta(hours=5, minutes=30)\n",
    "    utc_end = ist_end - timedelta(hours=5, minutes=30)\n",
    "    \n",
    "    logging.info(f\"ðŸ” Analysis window (UTC): {utc_start} â†’ {utc_end}\")\n",
    "\n",
    "    # 2. FILE EXTRACTION CONTROL\n",
    "    file_count = 0\n",
    "    \n",
    "    if extraction_dir.exists() and not force_extraction:\n",
    "        logging.info(\"â™»ï¸ Skipping file extraction: Directory exists and force_extraction=False.\")\n",
    "        # Recursively count all .parquet files in the existing directory\n",
    "        file_count = len(list(extraction_dir.rglob('*.parquet')))\n",
    "        if file_count > 0:\n",
    "             logging.info(f\"âœ… Found {file_count} existing files. Proceeding to DuckDB loading.\")\n",
    "        \n",
    "    else:\n",
    "        # If directory doesn't exist, or force_extraction is True, run the full extraction.\n",
    "        logging.info(\"ðŸ”„ Running full extraction (Cleanup + Extract)...\")\n",
    "        # This relies on the robust `extract_files_to_disk` function\n",
    "        file_count = extract_files_to_disk(zip_path, extraction_dir)\n",
    "        \n",
    "    # 3. Validation Check\n",
    "    if file_count == 0:\n",
    "        logging.warning(\"ðŸ›‘ Skipping analysis: No files were found.\")\n",
    "        sys.exit() # Exit the script cleanly if no files were found\n",
    "\n",
    "    return utc_start, utc_end, file_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2aee4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 02:15:31 - INFO - ðŸ” Analysis window (UTC): 2025-08-31 18:30:00 â†’ 2025-11-15 18:30:00\n",
      "2025-11-23 02:15:31 - INFO - â™»ï¸ Skipping file extraction: Directory exists and force_extraction=False.\n",
      "2025-11-23 02:15:31 - INFO - âœ… Found 474 existing files. Proceeding to DuckDB loading.\n"
     ]
    }
   ],
   "source": [
    "# --- CONFIGURATION (Ensure these are defined at the top of your script) ---\n",
    "ZIP_FILE_PATH = \"../../../data_points/naarni75_cpoall.zip\" \n",
    "EXTRACTION_DIR = Path(\"../extracted_parts\") \n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "# --- Set 75-Day Date Range (Using your target dates) ---\n",
    "analysis_start_date_str = \"2025-09-01\" \n",
    "# NOTE: Using 2025-11-14 since 75 days starts on 2025-09-01 and ends on 2025-11-14.\n",
    "# Using 2025-11-15 will include the start of the 76th day (if data exists).\n",
    "analysis_end_date_str = \"2025-11-15\"   \n",
    "# --------------------------------------------------------\n",
    "\n",
    "# NEW STAGE 1 EXECUTION:\n",
    "utc_start, utc_end, file_count = run_stage1_data_setup(\n",
    "    analysis_start_date_str=analysis_start_date_str,\n",
    "    analysis_end_date_str=analysis_end_date_str,\n",
    "    zip_path=ZIP_FILE_PATH,\n",
    "    extraction_dir=EXTRACTION_DIR,\n",
    "    force_extraction = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b4e8cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 02:15:31 - INFO - âœ… Found 29 unique vehicle IDs in the dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '22', '24', '25', '26', '27', '28', '29', '3', '30', '31', '32', '33', '41', '42', '46', '6', '7', '9']\n"
     ]
    }
   ],
   "source": [
    "# 2. SETUP DUCKDB QUERY\n",
    "conn, sql_query = setup_duckdb_query(EXTRACTION_DIR, utc_start, utc_end, CORE_COLS)\n",
    "\n",
    "# A quick DuckDB query to get the distinct IDs from the 75-day filtered dataset\n",
    "get_ids_query = f\"\"\"\n",
    "    SELECT DISTINCT id \n",
    "    FROM ({sql_query})\n",
    "\"\"\"\n",
    "# Fetch the list of IDs (this is a very small amount of data)\n",
    "vehicle_ids = conn.execute(get_ids_query).fetchdf()[\"id\"].astype(str).tolist()\n",
    "# vehicle_ids = ['3','16','18','19','32','42','6','7','9','11','12','13','14','15','20','25','27','28','29','30','31','33','35','41','46']\n",
    "\n",
    "logging.info(f\"âœ… Found {len(vehicle_ids)} unique vehicle IDs in the dataset.\")\n",
    "print(sorted(vehicle_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97dfd198",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# NOTE: The functions 'duckdb_chunk_generator', 'rename_battery_temp_columns', \n",
    "# 'impute_missing_values', 'prepare_df_with_state', and 'free_mem' \n",
    "# MUST be defined in your Jupyter Notebook environment before calling this.\n",
    "\n",
    "def process_and_save_data(\n",
    "    conn: duckdb.DuckDBPyConnection, \n",
    "    sql_query: str, \n",
    "    chunk_size: int, \n",
    "    parquet_feather_path: str,\n",
    "    vehicle_ids: List[str],\n",
    "    df_mapping: pd.DataFrame,\n",
    "    skip_if_exists: bool = True\n",
    ") -> int:\n",
    "    \"\"\"\n",
    "    Executes the memory-safe chunked processing loop for Stage 1.\n",
    "    \n",
    "    Loads raw data from DuckDB query (75 days) in chunks, preprocesses (renaming, \n",
    "    imputation, state preparation), filters by vehicle ID, and saves the result \n",
    "    to a single Feather file on disk.\n",
    "    \n",
    "    Args:\n",
    "        conn: The active DuckDB connection.\n",
    "        sql_query: The SQL query containing the timestamp filter.\n",
    "        chunk_size: The maximum number of rows to load into RAM per chunk.\n",
    "        feather_path: The name/path of the final output Feather file.\n",
    "        vehicle_ids: List of specific vehicle IDs to include.\n",
    "        \n",
    "    Returns:\n",
    "        The total number of rows processed and saved to the Feather file.\n",
    "    \"\"\"\n",
    "    \n",
    "    logging.info(f\"ðŸ§  Processing data in {chunk_size:,} row chunks...\")\n",
    "    logging.info(f\"ðŸ’¾ Output path set to: {parquet_feather_path}\")\n",
    "    \n",
    "    output_path = Path(parquet_feather_path)    \n",
    "    if skip_if_exists and output_path.exists():\n",
    "            conn.close() # Close the connection before returning\n",
    "            \n",
    "            # Safely retrieve the row count from the existing file using DuckDB\n",
    "            conn_count = duckdb.connect()\n",
    "            try:\n",
    "                total_rows = conn_count.execute(f\"SELECT count(*) FROM '{parquet_feather_path}'\").fetchone()[0]\n",
    "                logging.info(f\"âœ… Skipping processing: Found existing file with {total_rows:,} rows.\")\n",
    "                return total_rows\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error reading row count from existing file: {e}. Re-running processing.\")\n",
    "                # If the count fails, let the function continue and overwrite the file\n",
    "            finally:\n",
    "                conn_count.close()\n",
    "\n",
    "    # 1. Initialization\n",
    "    first_chunk = True\n",
    "    total_processed_rows = 0\n",
    "\n",
    "    # 2. Use the generator to stream data\n",
    "    for chunk in duckdb_chunk_generator(conn, sql_query, chunk_size):\n",
    "        \n",
    "        df_chunk = chunk\n",
    "        \n",
    "        # 3.1 Renaming and ID cleanup\n",
    "        df_chunk = rename_battery_temp_columns(df_chunk)\n",
    "        \n",
    "        if \"id\" in df_chunk.columns:\n",
    "            df_chunk[\"id\"] = df_chunk[\"id\"].astype(str)\n",
    "            \n",
    "            # Filter by vehicle ID on the small chunk\n",
    "            if vehicle_ids: # Only filter if the list is NOT empty\n",
    "                df_chunk = df_chunk[df_chunk[\"id\"].isin(vehicle_ids)]\n",
    "            \n",
    "            # --- Type Casting Optimization: Explicitly cast types after ID filter ---\n",
    "            df_chunk = df_chunk.convert_dtypes() # Use Pandas native types\n",
    "        \n",
    "        # 3.2 Imputation and State Preparation\n",
    "        df_chunk[\"timestamp\"] = pd.to_datetime(df_chunk[\"timestamp\"], errors=\"coerce\")\n",
    "        df_chunk = impute_missing_values(df_chunk)\n",
    "        \n",
    "        # State preparation uses df.copy(), which is now safe on the small chunk\n",
    "        df_chunk_with_state = prepare_df_with_state(df_chunk,df_mapping)\n",
    "        \n",
    "        # 3.3 Memory Check and Save\n",
    "        if df_chunk_with_state.empty:\n",
    "            del df_chunk, df_chunk_with_state\n",
    "            gc.collect()\n",
    "            free_mem()\n",
    "            continue\n",
    "            \n",
    "        # 3.4 Save Chunk (Append to Feather file)\n",
    "        total_processed_rows += len(df_chunk_with_state)\n",
    "        \n",
    "        if first_chunk:\n",
    "            # Overwrite file if it's the first chunk\n",
    "            # df_chunk_with_state.to_feather(feather_path, compression='zstd')\n",
    "            df_chunk_with_state.to_parquet(parquet_feather_path, compression='zstd', index=False)\n",
    "            first_chunk = False\n",
    "        else:\n",
    "            # Append all subsequent chunks (Requires pyarrow 'a' mode)\n",
    "            # df_chunk_with_state.to_feather(feather_path, compression='zstd', mode='a')\n",
    "            # df_chunk_with_state.to_parquet(parquet_feather_path, compression='zstd', index=False, engine='fastparquet', mode='append')\n",
    "            fastparquet.write(\n",
    "                    parquet_feather_path, \n",
    "                    df_chunk_with_state, \n",
    "                    compression='zstd', \n",
    "                    write_index=False, # Equivalent to index=False in pandas\n",
    "                    append=True        # The correct argument for appending with fastparquet\n",
    "                )            \n",
    "            \n",
    "        logging.info(f\"   Processed {total_processed_rows:,} rows so far...\")\n",
    "        \n",
    "        # 3.5 Clean up memory after processing each chunk (CRITICAL STEP)\n",
    "        del df_chunk, df_chunk_with_state\n",
    "        gc.collect()\n",
    "        free_mem() # Aggressively free memory\n",
    "        \n",
    "    conn.close()\n",
    "    \n",
    "    return total_processed_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122a454a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 02:15:31 - INFO - ðŸ§  Processing data in 10,000 row chunks...\n",
      "2025-11-23 02:15:31 - INFO - ðŸ’¾ Output path set to: df_with_state_30days.parquet\n",
      "2025-11-23 02:15:31 - INFO - âœ… Skipping processing: Found existing file with 52,888,998 rows.\n",
      "2025-11-23 02:15:31 - INFO - ðŸŽ‰ Final DataFrame saved. Total rows processed: 52,888,998\n",
      "2025-11-23 02:15:31 - INFO - âœ… Data Processing (Stage 1) complete. Feather file ready for analysis.\n"
     ]
    }
   ],
   "source": [
    "# --- ASSUMING run_stage1_data_setup WAS CALLED AND RETURNED utc_start, utc_end ---\n",
    "# Example configuration that needs to be available:\n",
    "# EXTRACTION_DIR = Path(\"../extracted_parts\") \n",
    "# CORE_COLS = [...]\n",
    "# CRITICAL FIX: Drastically reduced chunk size to prevent memory spike\n",
    "CHUNK_SIZE = 10_000 # Process 50,000 rows max at any time\n",
    "\n",
    "\n",
    "# 1. Setup DuckDB Query (as shown previously)\n",
    "conn, sql_query = setup_duckdb_query(EXTRACTION_DIR, utc_start, utc_end, CORE_COLS)\n",
    "\n",
    "# 2. Define Inputs\n",
    "# output_feather_file = \"df_with_state_30days.feather\"\n",
    "output_parquet_file = \"df_with_state.parquet\"\n",
    "\n",
    "# 3. Run the memory-safe processing loop\n",
    "total_rows = process_and_save_data(\n",
    "    conn=conn,\n",
    "    sql_query=sql_query,\n",
    "    chunk_size=CHUNK_SIZE,\n",
    "    parquet_feather_path=output_parquet_file,\n",
    "    vehicle_ids=vehicle_ids,\n",
    "    df_mapping=df_mapping,\n",
    "    skip_if_exists =True\n",
    ")\n",
    "\n",
    "logging.info(f\"ðŸŽ‰ Final DataFrame saved. Total rows processed: {total_rows:,}\")\n",
    "logging.info(\"âœ… Data Processing (Stage 1) complete. Feather file ready for analysis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d803154e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_parquet_subset(parquet_path: str, start_dt: datetime, end_dt: datetime) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reads a subset of the processed Feather file using a date filter\n",
    "    applied directly by DuckDB (predicate pushdown).\n",
    "    \n",
    "    Args:\n",
    "        feather_path: Path to the processed Feather file.\n",
    "        start_dt: Start datetime for the filter (inclusive).\n",
    "        end_dt: End datetime for the filter (exclusive).\n",
    "        \n",
    "    Returns:\n",
    "        A new DataFrame containing only the filtered data.\n",
    "    \"\"\"\n",
    "    logging.info(f\"Loading data subset from {start_dt} to {end_dt}...\")\n",
    "    \n",
    "    # Use DuckDB to query the Feather file directly on disk\n",
    "    con = duckdb.connect()\n",
    "    \n",
    "    # The SQL query filters rows on the disk file based on the 'timestamp' column.\n",
    "    sql_query = f\"\"\"\n",
    "        SELECT *\n",
    "        FROM read_parquet('{parquet_path}')\n",
    "        WHERE \n",
    "            \"timestamp\" >= '{start_dt.isoformat()}' AND \n",
    "            \"timestamp\" < '{end_dt.isoformat()}'\n",
    "    \"\"\"\n",
    "    \n",
    "    # Fetch the filtered, smaller DataFrame\n",
    "    df_subset = con.execute(sql_query).fetchdf()\n",
    "    con.close()\n",
    "    \n",
    "    logging.info(f\"âœ… Loaded {len(df_subset):,} rows for the requested subset.\")\n",
    "    return df_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a52164d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the 30-day filter window\n",
    "# filter_start_date = datetime(2025, 9, 1)\n",
    "# filter_end_date = datetime(2025, 9, 2) # Exclusive end date\n",
    "\n",
    "# # 1. Load the filtered subset safely\n",
    "# df_subset = read_parquet_subset(\n",
    "#     parquet_path=\"df_with_state_30days.parquet\",\n",
    "#     start_dt=filter_start_date,\n",
    "#     end_dt=filter_end_date\n",
    "# )\n",
    "\n",
    "# display(df_subset.head())\n",
    "# 2. Perform analysis on the smaller DataFrame\n",
    "# ... run get_veh_temp_hotspots, compute_batt_condition_metrics, etc., on df_subset ...\n",
    "\n",
    "# # 3. Aggressive memory cleanup after use (CRITICAL)\n",
    "# del df_subset\n",
    "# gc.collect()\n",
    "# free_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61cb889f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_subset.timestamp.min(),df_subset.timestamp.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7540202a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- FIXED CATEGORY DEFINITIONS ---\n",
    "# These fixed labels ensure your output columns are consistent across all data chunks.\n",
    "FIXED_CATEGORIES = {\n",
    "    'maxtemp_bucket': [\"<28\", \"28â€“32\", \"32â€“35\", \"35â€“40\", \">40\"],\n",
    "    'temp_delta_bucket': [\"<2\", \"2â€“5\", \"5â€“8\", \">8\"],\n",
    "    # ðŸ’¥ UPDATED BUCKET: Using the new labels for volt_delta_bucket ðŸ’¥\n",
    "    'volt_delta_bucket': [\"0â€“10\", \"10â€“20\", \"20â€“30\", \">30\"] \n",
    "}\n",
    "# ----------------------------------\n",
    "\n",
    "def create_session_report(\n",
    "    df: pd.DataFrame, \n",
    "    timezone: str = 'Asia/Kolkata',\n",
    "    min_discharging_duration_min: float = 1.0\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Performs sessionization and calculates the percentage distribution of \n",
    "    key operational buckets per session using a fixed set of categories.\n",
    "    \"\"\"\n",
    "    # 1. CRITICAL STEP: Ensure data is sorted by ID and Timestamp\n",
    "    df = df.sort_values(['id', 'timestamp']).reset_index(drop=True)\n",
    "    \n",
    "    # Ensure 'timestamp' is timezone-aware IST\n",
    "    if not isinstance(df['timestamp'].dtype, pd.DatetimeTZDtype):\n",
    "        try:\n",
    "            df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce', utc=True).dt.tz_convert(timezone)\n",
    "        except Exception:\n",
    "            df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')\n",
    "\n",
    "    # 2. Identify the start of a new session\n",
    "    df['id_change'] = df['id'].ne(df['id'].shift())\n",
    "    df['mode_change'] = df['mode'].ne(df['mode'].shift())\n",
    "    df['session_start'] = df['id_change'] | df['mode_change']\n",
    "    df['unique_session_id'] = df['session_start'].cumsum()\n",
    "\n",
    "    # 3. Aggregate Session Metrics (Non-bucket columns)\n",
    "    session_df = df.groupby('unique_session_id').agg(\n",
    "        id=('id', 'first'),\n",
    "        reg_num=('reg_num', 'first'),\n",
    "        customer=('customer', 'first'),\n",
    "        model=('model', 'first'),\n",
    "        mode=('mode', 'first'),\n",
    "        start_time=('timestamp', 'min'),\n",
    "        end_time=('timestamp', 'max'),\n",
    "    ) # Unique_session_id is the index\n",
    "\n",
    "    # 4. --- NEW: Calculate Percentage of Buckets per Session using FIXED CATEGORIES ---\n",
    "    bucket_cols = ['maxtemp_bucket', 'temp_delta_bucket', 'volt_delta_bucket']\n",
    "    agg_dfs = []\n",
    "    \n",
    "    for col in bucket_cols:\n",
    "        if col in df.columns and col in FIXED_CATEGORIES:\n",
    "            \n",
    "            # --- Key Fix: Convert to CategoricalDtype with fixed categories ---\n",
    "            # This ensures all categories are present, even those with zero count.\n",
    "            df[col] = pd.Categorical(df[col], categories=FIXED_CATEGORIES[col], ordered=True)\n",
    "            # -------------------------------------------------------------------\n",
    "            \n",
    "            # Calculate value counts normalized to get percentages\n",
    "            pct_series = round(df.groupby('unique_session_id')[col].value_counts(normalize=True) * 100,2)\n",
    "            \n",
    "            # Unstack the bucket labels to create new columns, fill missing (zero) categories\n",
    "            pivot_df = pct_series.unstack(fill_value=0)\n",
    "            \n",
    "            # Rename columns for clear identification and safe use (e.g., replaces 'â€“' with '_')\n",
    "            pivot_df.columns = [\n",
    "                f\"{col}_{str(c).replace('â€“', '_').replace('<', 'lt').replace('>', 'gt')}_pct\" \n",
    "                for c in pivot_df.columns\n",
    "            ]\n",
    "            agg_dfs.append(pivot_df)\n",
    "\n",
    "    # Merge all percentage tables back into the main session_df\n",
    "    if agg_dfs:\n",
    "        for agg_df in agg_dfs:\n",
    "            session_df = session_df.join(agg_df, how='left')\n",
    "    \n",
    "    session_df = session_df.reset_index(drop=True) # Now reset index\n",
    "\n",
    "    # 5. Final Calculations and Formatting\n",
    "    \n",
    "    # Calculate Duration in MINUTES (seconds / 60) and round to 2 decimal places\n",
    "    session_df['duration'] = (\n",
    "        (session_df['end_time'] - session_df['start_time']).dt.total_seconds() / 60\n",
    "    ).round(2)\n",
    "\n",
    "    # Add sequential session number (e.g., 1, 2, 3...) per vehicle ID\n",
    "    session_df['session'] = session_df.groupby('id').cumcount() + 1\n",
    "    \n",
    "    # 6. Final Output Selection and Formatting\n",
    "    \n",
    "    session_report = session_df.copy()\n",
    "\n",
    "    # Define the core columns to ensure they are first\n",
    "    core_cols = ['id', 'reg_num', 'customer', 'model', 'mode', 'session', 'start_time', 'end_time', 'duration']\n",
    "    \n",
    "    # Order columns: core columns first, then new percentage columns\n",
    "    new_cols = [c for c in session_report.columns if c not in core_cols]\n",
    "    session_report = session_report[core_cols + new_cols]\n",
    "    \n",
    "    # --- FINAL FORMATTING ---\n",
    "    # Round times to seconds precision (floor)\n",
    "    session_report['start_time'] = session_report['start_time'].dt.floor('S')\n",
    "    session_report['end_time'] = session_report['end_time'].dt.floor('S')\n",
    "\n",
    "    # Drop Timezone information (+05:30)\n",
    "    session_report['start_time'] = session_report['start_time'].dt.tz_localize(None)\n",
    "    session_report['end_time'] = session_report['end_time'].dt.tz_localize(None)\n",
    "    # -------------------------\n",
    "\n",
    "    return session_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb937bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting 75-Day Session Analysis ---\n",
      "Processing range: 2025-09-01 to 2025-11-14\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Daily Sessions: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [03:12<00:00,  2.56s/day, Date: 2025-11-14]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "âœ… ANALYSIS COMPLETE\n",
      "Total time taken: 192.18 seconds (3.20 minutes)\n",
      "Days processed:   75\n",
      "Total Rows Ingested: 51,788,694\n",
      "Final Report Shape: (11770, 22) (Rows: 11770, Columns: 22)\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import gc\n",
    "import logging # Required for managing log levels\n",
    "from tqdm.auto import tqdm \n",
    "import time # For timing the execution\n",
    "\n",
    "# NOTE: The create_session_report and read_parquet_subset functions \n",
    "# must be defined/imported before running this code.\n",
    "\n",
    "def run_multi_day_session_analysis(\n",
    "    parquet_path: str, \n",
    "    start_date: datetime, \n",
    "    num_days: int\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Iteratively loads, processes, and aggregates session reports for a defined number of days,\n",
    "    displaying a progress bar and suppressing INFO logging during the process.\n",
    "    \"\"\"\n",
    "    all_reports = []\n",
    "    total_rows_ingested = 0 # <--- ADD THIS LINE HERE\n",
    "\n",
    "    # --- Logging Suppression: Temporarily set log level to WARNING to hide INFO messages ---\n",
    "    current_log_level = logging.getLogger().level\n",
    "    logging.getLogger().setLevel(logging.WARNING) \n",
    "    \n",
    "    try:\n",
    "        progress_bar = tqdm(range(num_days), desc=\"Processing Daily Sessions\", unit=\"day\")\n",
    "        \n",
    "        for i in progress_bar:\n",
    "            current_start_dt = start_date + timedelta(days=i)\n",
    "            current_end_dt = current_start_dt + timedelta(days=1)\n",
    "            \n",
    "            progress_bar.set_postfix_str(f\"Date: {current_start_dt.strftime('%Y-%m-%d')}\")\n",
    "            \n",
    "            # 1. Load the small subset (Logging is suppressed here)\n",
    "            df_subset = read_parquet_subset(\n",
    "                parquet_path=parquet_path,\n",
    "                start_dt=current_start_dt,\n",
    "                end_dt=current_end_dt\n",
    "            )\n",
    "            \n",
    "            if df_subset.empty:\n",
    "                del df_subset\n",
    "                gc.collect()\n",
    "                continue\n",
    "            \n",
    "            total_rows_ingested += len(df_subset)   #count rows being processed\n",
    "\n",
    "            # 2. Process the subset\n",
    "            session_report_chunk = create_session_report(df_subset)\n",
    "            \n",
    "            # 3. Aggregate the result\n",
    "            all_reports.append(session_report_chunk)\n",
    "            \n",
    "            # 4. Explicit Memory Management\n",
    "            del df_subset \n",
    "            gc.collect()  \n",
    "            \n",
    "    finally:\n",
    "        # --- Restore Logging Level ---\n",
    "        logging.getLogger().setLevel(current_log_level)\n",
    "        \n",
    "    # 5. Final Concatenation\n",
    "    if all_reports:\n",
    "        final_report_df = pd.concat(all_reports, ignore_index=True)\n",
    "        return final_report_df, total_rows_ingested\n",
    "    else:\n",
    "        return pd.DataFrame(), total_rows_ingested\n",
    "\n",
    "# =========================================================================\n",
    "# --- Execution Example ---\n",
    "# =========================================================================\n",
    "\n",
    "# Define the 75-day process window\n",
    "filter_start_date = datetime(2025, 9, 1) # Start date\n",
    "total_days_to_process = 75\n",
    "\n",
    "print(f\"--- Starting 75-Day Session Analysis ---\")\n",
    "print(f\"Processing range: {filter_start_date.strftime('%Y-%m-%d')} to {(filter_start_date + timedelta(days=total_days_to_process-1)).strftime('%Y-%m-%d')}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Run the iterative analysis\n",
    "session_report_df, total_rows = run_multi_day_session_analysis(\n",
    "    parquet_path=\"df_with_state.parquet\",\n",
    "    start_date=filter_start_date,\n",
    "    num_days=total_days_to_process\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time_sec = end_time - start_time\n",
    "elapsed_time_min = elapsed_time_sec / 60\n",
    "\n",
    "# --- Final Summary ---\n",
    "print(\"\\n\" + \"=\" * 40)\n",
    "print(\"âœ… ANALYSIS COMPLETE\")\n",
    "print(f\"Total time taken: {elapsed_time_sec:.2f} seconds ({elapsed_time_min:.2f} minutes)\")\n",
    "print(f\"Days processed:   {total_days_to_process}\")\n",
    "print(f\"Total Rows Ingested: {total_rows:,}\")\n",
    "print(f\"Final Report Shape: {session_report_df.shape} (Rows: {session_report_df.shape[0]}, Columns: {session_report_df.shape[1]})\")\n",
    "print(\"=\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9607f0e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>reg_num</th>\n",
       "      <th>customer</th>\n",
       "      <th>model</th>\n",
       "      <th>mode</th>\n",
       "      <th>session</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>duration</th>\n",
       "      <th>maxtemp_bucket_lt28_pct</th>\n",
       "      <th>maxtemp_bucket_28_32_pct</th>\n",
       "      <th>maxtemp_bucket_32_35_pct</th>\n",
       "      <th>maxtemp_bucket_35_40_pct</th>\n",
       "      <th>maxtemp_bucket_gt40_pct</th>\n",
       "      <th>temp_delta_bucket_lt2_pct</th>\n",
       "      <th>temp_delta_bucket_2_5_pct</th>\n",
       "      <th>temp_delta_bucket_5_8_pct</th>\n",
       "      <th>temp_delta_bucket_gt8_pct</th>\n",
       "      <th>volt_delta_bucket_0_10_pct</th>\n",
       "      <th>volt_delta_bucket_10_20_pct</th>\n",
       "      <th>volt_delta_bucket_20_30_pct</th>\n",
       "      <th>volt_delta_bucket_gt30_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>HR55AY9237</td>\n",
       "      <td>ZB Gurgaon</td>\n",
       "      <td>12.5</td>\n",
       "      <td>DISCHARGING</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-09-01 05:30:00</td>\n",
       "      <td>2025-09-01 05:37:36</td>\n",
       "      <td>7.59</td>\n",
       "      <td>3.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>96.72</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>96.72</td>\n",
       "      <td>1.64</td>\n",
       "      <td>41.67</td>\n",
       "      <td>56.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>HR55AY9237</td>\n",
       "      <td>ZB Gurgaon</td>\n",
       "      <td>12.5</td>\n",
       "      <td>CHARGING</td>\n",
       "      <td>2</td>\n",
       "      <td>2025-09-01 05:39:01</td>\n",
       "      <td>2025-09-01 06:13:04</td>\n",
       "      <td>34.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>38.84</td>\n",
       "      <td>61.11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>99.90</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.10</td>\n",
       "      <td>92.85</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>HR55AY9237</td>\n",
       "      <td>ZB Gurgaon</td>\n",
       "      <td>12.5</td>\n",
       "      <td>DISCHARGING</td>\n",
       "      <td>3</td>\n",
       "      <td>2025-09-01 06:13:05</td>\n",
       "      <td>2025-09-01 06:13:06</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>HR55AY9237</td>\n",
       "      <td>ZB Gurgaon</td>\n",
       "      <td>12.5</td>\n",
       "      <td>CHARGING</td>\n",
       "      <td>4</td>\n",
       "      <td>2025-09-01 06:13:07</td>\n",
       "      <td>2025-09-01 07:22:50</td>\n",
       "      <td>69.71</td>\n",
       "      <td>0.03</td>\n",
       "      <td>16.74</td>\n",
       "      <td>32.25</td>\n",
       "      <td>50.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>99.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>49.75</td>\n",
       "      <td>21.03</td>\n",
       "      <td>29.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>HR55AY9237</td>\n",
       "      <td>ZB Gurgaon</td>\n",
       "      <td>12.5</td>\n",
       "      <td>DISCHARGING</td>\n",
       "      <td>5</td>\n",
       "      <td>2025-09-01 07:23:05</td>\n",
       "      <td>2025-09-01 18:03:03</td>\n",
       "      <td>639.97</td>\n",
       "      <td>34.98</td>\n",
       "      <td>53.80</td>\n",
       "      <td>11.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>84.33</td>\n",
       "      <td>15.61</td>\n",
       "      <td>0.01</td>\n",
       "      <td>75.65</td>\n",
       "      <td>18.80</td>\n",
       "      <td>3.82</td>\n",
       "      <td>1.72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     reg_num    customer model         mode  session          start_time  \\\n",
       "0  16  HR55AY9237  ZB Gurgaon  12.5  DISCHARGING        1 2025-09-01 05:30:00   \n",
       "1  16  HR55AY9237  ZB Gurgaon  12.5     CHARGING        2 2025-09-01 05:39:01   \n",
       "2  16  HR55AY9237  ZB Gurgaon  12.5  DISCHARGING        3 2025-09-01 06:13:05   \n",
       "3  16  HR55AY9237  ZB Gurgaon  12.5     CHARGING        4 2025-09-01 06:13:07   \n",
       "4  16  HR55AY9237  ZB Gurgaon  12.5  DISCHARGING        5 2025-09-01 07:23:05   \n",
       "\n",
       "             end_time  duration  maxtemp_bucket_lt28_pct  \\\n",
       "0 2025-09-01 05:37:36      7.59                     3.28   \n",
       "1 2025-09-01 06:13:04     34.05                     0.05   \n",
       "2 2025-09-01 06:13:06      0.02                     0.00   \n",
       "3 2025-09-01 07:22:50     69.71                     0.03   \n",
       "4 2025-09-01 18:03:03    639.97                    34.98   \n",
       "\n",
       "   maxtemp_bucket_28_32_pct  maxtemp_bucket_32_35_pct  \\\n",
       "0                      0.00                     96.72   \n",
       "1                      0.00                     38.84   \n",
       "2                      0.00                      0.00   \n",
       "3                     16.74                     32.25   \n",
       "4                     53.80                     11.22   \n",
       "\n",
       "   maxtemp_bucket_35_40_pct  maxtemp_bucket_gt40_pct  \\\n",
       "0                      0.00                      0.0   \n",
       "1                     61.11                      0.0   \n",
       "2                    100.00                      0.0   \n",
       "3                     50.99                      0.0   \n",
       "4                      0.00                      0.0   \n",
       "\n",
       "   temp_delta_bucket_lt2_pct  temp_delta_bucket_2_5_pct  \\\n",
       "0                       1.64                       0.00   \n",
       "1                       0.05                       0.05   \n",
       "2                       0.00                       0.00   \n",
       "3                       0.03                       0.00   \n",
       "4                       0.04                      84.33   \n",
       "\n",
       "   temp_delta_bucket_5_8_pct  temp_delta_bucket_gt8_pct  \\\n",
       "0                      96.72                       1.64   \n",
       "1                      99.90                       0.00   \n",
       "2                     100.00                       0.00   \n",
       "3                      99.97                       0.00   \n",
       "4                      15.61                       0.01   \n",
       "\n",
       "   volt_delta_bucket_0_10_pct  volt_delta_bucket_10_20_pct  \\\n",
       "0                       41.67                        56.67   \n",
       "1                        7.10                        92.85   \n",
       "2                        0.00                       100.00   \n",
       "3                        0.00                        49.75   \n",
       "4                       75.65                        18.80   \n",
       "\n",
       "   volt_delta_bucket_20_30_pct  volt_delta_bucket_gt30_pct  \n",
       "0                         0.00                        1.67  \n",
       "1                         0.05                        0.00  \n",
       "2                         0.00                        0.00  \n",
       "3                        21.03                       29.22  \n",
       "4                         3.82                        1.72  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# session_report_df.to_csv('bcs_analysis_sessions.csv')\n",
    "session_report_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b806329a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def weighted_avg_factory(df, weight_col='duration'):\n",
    "    \"\"\"\n",
    "    Creates a callable function for pandas aggregation that calculates \n",
    "    the weighted average of a series using a specific weight column from the \n",
    "    original DataFrame (df) based on the group's indices.\n",
    "    \"\"\"\n",
    "    def weighted_avg(series):\n",
    "        # Retrieve the original 'duration' (weights) for the rows in the current group (series)\n",
    "        weights = df.loc[series.index, weight_col]\n",
    "        \n",
    "        # Guard against division by zero (e.g., if total duration is 0)\n",
    "        if weights.sum() == 0:\n",
    "            return 0.0\n",
    "            \n",
    "        # Weighted average calculation\n",
    "        return ((series * weights).sum() / weights.sum()).round(4)\n",
    "\n",
    "    return weighted_avg\n",
    "\n",
    "# --- ASSUMING session_report_df is your input DataFrame (the 75-day report) ---\n",
    "# NOTE: Replace 'session_report_df' with the actual variable name from your script (e.g., the output of run_multi_day_session_analysis)\n",
    "df = session_report_df \n",
    "\n",
    "# Ensure 'duration' is numeric and set up the weighted average function\n",
    "df['duration'] = pd.to_numeric(df['duration'], errors='coerce')\n",
    "w_avg = weighted_avg_factory(df, 'duration')\n",
    "\n",
    "# Define all percentage columns for aggregation\n",
    "pct_cols = [col for col in df.columns if col.endswith('_pct')]\n",
    "\n",
    "# Define the full aggregation dictionary\n",
    "agg_dict = {\n",
    "    'reg_num': 'first',\n",
    "    'customer': 'first',\n",
    "    'model': 'first',\n",
    "    'session': 'count',  # Becomes total_sessions\n",
    "    'duration': 'sum'   # Becomes total_duration\n",
    "}\n",
    "\n",
    "# Add weighted average for all percentage columns\n",
    "weighted_agg_dict = {col: w_avg for col in pct_cols}\n",
    "agg_dict.update(weighted_agg_dict)\n",
    "\n",
    "# 1. Perform aggregation grouped by 'id' and 'mode'\n",
    "report_agg = df.groupby(['id', 'mode']).agg(agg_dict).reset_index()\n",
    "\n",
    "# 2. Final Formatting and Column Renaming/Reordering\n",
    "report_agg = report_agg.rename(columns={'session': 'total_sessions', 'duration': 'total_duration'})\n",
    "report_agg['total_duration'] = report_agg['total_duration'].round(2)\n",
    "\n",
    "report_agg['maxtemp_bucket_lt28_pct'] = report_agg['maxtemp_bucket_lt28_pct'].round(2)\n",
    "report_agg['maxtemp_bucket_28_32_pct'] = report_agg['maxtemp_bucket_28_32_pct'].round(2)\n",
    "report_agg['maxtemp_bucket_32_35_pct'] = report_agg['maxtemp_bucket_32_35_pct'].round(2)\n",
    "report_agg['maxtemp_bucket_35_40_pct'] = report_agg['maxtemp_bucket_35_40_pct'].round(2)\n",
    "report_agg['maxtemp_bucket_gt40_pct'] = report_agg['maxtemp_bucket_gt40_pct'].round(2)\n",
    "\n",
    "report_agg['temp_delta_bucket_lt2_pct'] = report_agg['temp_delta_bucket_lt2_pct'].round(2)\n",
    "report_agg['temp_delta_bucket_2_5_pct'] = report_agg['temp_delta_bucket_2_5_pct'].round(2)\n",
    "report_agg['temp_delta_bucket_5_8_pct'] = report_agg['temp_delta_bucket_5_8_pct'].round(2)\n",
    "report_agg['temp_delta_bucket_gt8_pct'] = report_agg['temp_delta_bucket_gt8_pct'].round(2)\n",
    "\n",
    "report_agg['volt_delta_bucket_0_10_pct'] = report_agg['volt_delta_bucket_0_10_pct'].round(2)\n",
    "report_agg['volt_delta_bucket_10_20_pct'] = report_agg['volt_delta_bucket_10_20_pct'].round(2)\n",
    "report_agg['volt_delta_bucket_20_30_pct'] = report_agg['volt_delta_bucket_20_30_pct'].round(2)\n",
    "report_agg['volt_delta_bucket_gt30_pct'] = report_agg['volt_delta_bucket_gt30_pct'].round(2)\n",
    "\n",
    "\n",
    "# Reorder columns as requested\n",
    "final_columns = [\n",
    "    'id', 'reg_num', 'customer', 'model', 'mode', 'total_sessions', 'total_duration'\n",
    "] + pct_cols\n",
    "\n",
    "report_agg = report_agg[final_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b6d8c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>reg_num</th>\n",
       "      <th>customer</th>\n",
       "      <th>model</th>\n",
       "      <th>mode</th>\n",
       "      <th>total_sessions</th>\n",
       "      <th>total_duration</th>\n",
       "      <th>maxtemp_bucket_lt28_pct</th>\n",
       "      <th>maxtemp_bucket_28_32_pct</th>\n",
       "      <th>maxtemp_bucket_32_35_pct</th>\n",
       "      <th>maxtemp_bucket_35_40_pct</th>\n",
       "      <th>maxtemp_bucket_gt40_pct</th>\n",
       "      <th>temp_delta_bucket_lt2_pct</th>\n",
       "      <th>temp_delta_bucket_2_5_pct</th>\n",
       "      <th>temp_delta_bucket_5_8_pct</th>\n",
       "      <th>temp_delta_bucket_gt8_pct</th>\n",
       "      <th>volt_delta_bucket_0_10_pct</th>\n",
       "      <th>volt_delta_bucket_10_20_pct</th>\n",
       "      <th>volt_delta_bucket_20_30_pct</th>\n",
       "      <th>volt_delta_bucket_gt30_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>REGNUM_10</td>\n",
       "      <td>CUST_10</td>\n",
       "      <td>MDL_10</td>\n",
       "      <td>CHARGING</td>\n",
       "      <td>20</td>\n",
       "      <td>681.50</td>\n",
       "      <td>18.18</td>\n",
       "      <td>72.23</td>\n",
       "      <td>9.59</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>41.03</td>\n",
       "      <td>53.94</td>\n",
       "      <td>4.99</td>\n",
       "      <td>0.04</td>\n",
       "      <td>70.45</td>\n",
       "      <td>17.11</td>\n",
       "      <td>4.32</td>\n",
       "      <td>8.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>REGNUM_10</td>\n",
       "      <td>CUST_10</td>\n",
       "      <td>MDL_10</td>\n",
       "      <td>DISCHARGING</td>\n",
       "      <td>33</td>\n",
       "      <td>3981.14</td>\n",
       "      <td>52.91</td>\n",
       "      <td>42.04</td>\n",
       "      <td>5.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>48.95</td>\n",
       "      <td>46.84</td>\n",
       "      <td>4.04</td>\n",
       "      <td>0.17</td>\n",
       "      <td>80.58</td>\n",
       "      <td>16.64</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>AP39WF8593</td>\n",
       "      <td>FB Guntur</td>\n",
       "      <td>12.5</td>\n",
       "      <td>CHARGING</td>\n",
       "      <td>329</td>\n",
       "      <td>18984.66</td>\n",
       "      <td>1.79</td>\n",
       "      <td>20.42</td>\n",
       "      <td>49.12</td>\n",
       "      <td>27.23</td>\n",
       "      <td>1.44</td>\n",
       "      <td>3.17</td>\n",
       "      <td>75.90</td>\n",
       "      <td>20.84</td>\n",
       "      <td>0.09</td>\n",
       "      <td>47.02</td>\n",
       "      <td>38.35</td>\n",
       "      <td>3.25</td>\n",
       "      <td>11.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>AP39WF8593</td>\n",
       "      <td>FB Guntur</td>\n",
       "      <td>12.5</td>\n",
       "      <td>DISCHARGING</td>\n",
       "      <td>397</td>\n",
       "      <td>80097.73</td>\n",
       "      <td>5.89</td>\n",
       "      <td>47.43</td>\n",
       "      <td>39.58</td>\n",
       "      <td>7.03</td>\n",
       "      <td>0.07</td>\n",
       "      <td>17.12</td>\n",
       "      <td>77.47</td>\n",
       "      <td>5.41</td>\n",
       "      <td>0.00</td>\n",
       "      <td>81.63</td>\n",
       "      <td>13.81</td>\n",
       "      <td>1.93</td>\n",
       "      <td>2.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>TN14AR3907</td>\n",
       "      <td>FB Bangalore</td>\n",
       "      <td>12.5</td>\n",
       "      <td>CHARGING</td>\n",
       "      <td>270</td>\n",
       "      <td>11245.60</td>\n",
       "      <td>3.48</td>\n",
       "      <td>28.12</td>\n",
       "      <td>44.66</td>\n",
       "      <td>21.45</td>\n",
       "      <td>2.30</td>\n",
       "      <td>3.03</td>\n",
       "      <td>54.65</td>\n",
       "      <td>40.19</td>\n",
       "      <td>2.13</td>\n",
       "      <td>25.13</td>\n",
       "      <td>46.62</td>\n",
       "      <td>10.19</td>\n",
       "      <td>18.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     reg_num      customer   model         mode  total_sessions  \\\n",
       "0  10   REGNUM_10       CUST_10  MDL_10     CHARGING              20   \n",
       "1  10   REGNUM_10       CUST_10  MDL_10  DISCHARGING              33   \n",
       "2  11  AP39WF8593     FB Guntur    12.5     CHARGING             329   \n",
       "3  11  AP39WF8593     FB Guntur    12.5  DISCHARGING             397   \n",
       "4  12  TN14AR3907  FB Bangalore    12.5     CHARGING             270   \n",
       "\n",
       "   total_duration  maxtemp_bucket_lt28_pct  maxtemp_bucket_28_32_pct  \\\n",
       "0          681.50                    18.18                     72.23   \n",
       "1         3981.14                    52.91                     42.04   \n",
       "2        18984.66                     1.79                     20.42   \n",
       "3        80097.73                     5.89                     47.43   \n",
       "4        11245.60                     3.48                     28.12   \n",
       "\n",
       "   maxtemp_bucket_32_35_pct  maxtemp_bucket_35_40_pct  \\\n",
       "0                      9.59                      0.00   \n",
       "1                      5.05                      0.00   \n",
       "2                     49.12                     27.23   \n",
       "3                     39.58                      7.03   \n",
       "4                     44.66                     21.45   \n",
       "\n",
       "   maxtemp_bucket_gt40_pct  temp_delta_bucket_lt2_pct  \\\n",
       "0                     0.00                      41.03   \n",
       "1                     0.00                      48.95   \n",
       "2                     1.44                       3.17   \n",
       "3                     0.07                      17.12   \n",
       "4                     2.30                       3.03   \n",
       "\n",
       "   temp_delta_bucket_2_5_pct  temp_delta_bucket_5_8_pct  \\\n",
       "0                      53.94                       4.99   \n",
       "1                      46.84                       4.04   \n",
       "2                      75.90                      20.84   \n",
       "3                      77.47                       5.41   \n",
       "4                      54.65                      40.19   \n",
       "\n",
       "   temp_delta_bucket_gt8_pct  volt_delta_bucket_0_10_pct  \\\n",
       "0                       0.04                       70.45   \n",
       "1                       0.17                       80.58   \n",
       "2                       0.09                       47.02   \n",
       "3                       0.00                       81.63   \n",
       "4                       2.13                       25.13   \n",
       "\n",
       "   volt_delta_bucket_10_20_pct  volt_delta_bucket_20_30_pct  \\\n",
       "0                        17.11                         4.32   \n",
       "1                        16.64                         0.46   \n",
       "2                        38.35                         3.25   \n",
       "3                        13.81                         1.93   \n",
       "4                        46.62                        10.19   \n",
       "\n",
       "   volt_delta_bucket_gt30_pct  \n",
       "0                        8.11  \n",
       "1                        0.35  \n",
       "2                       11.38  \n",
       "3                        2.63  \n",
       "4                       18.06  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# report_agg.to_csv('bcs_analysis_report_v1.csv')\n",
    "report_agg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b9a55d64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>reg_num</th>\n",
       "      <th>customer</th>\n",
       "      <th>model</th>\n",
       "      <th>mode</th>\n",
       "      <th>session</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>duration</th>\n",
       "      <th>maxtemp_bucket_lt28_pct</th>\n",
       "      <th>maxtemp_bucket_28_32_pct</th>\n",
       "      <th>maxtemp_bucket_32_35_pct</th>\n",
       "      <th>maxtemp_bucket_35_40_pct</th>\n",
       "      <th>maxtemp_bucket_gt40_pct</th>\n",
       "      <th>temp_delta_bucket_lt2_pct</th>\n",
       "      <th>temp_delta_bucket_2_5_pct</th>\n",
       "      <th>temp_delta_bucket_5_8_pct</th>\n",
       "      <th>temp_delta_bucket_gt8_pct</th>\n",
       "      <th>volt_delta_bucket_0_10_pct</th>\n",
       "      <th>volt_delta_bucket_10_20_pct</th>\n",
       "      <th>volt_delta_bucket_20_30_pct</th>\n",
       "      <th>volt_delta_bucket_gt30_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>HR55AY9237</td>\n",
       "      <td>ZB Gurgaon</td>\n",
       "      <td>12.5</td>\n",
       "      <td>CHARGING</td>\n",
       "      <td>2</td>\n",
       "      <td>2025-09-01 05:39:01</td>\n",
       "      <td>2025-09-01 06:13:04</td>\n",
       "      <td>34.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>38.84</td>\n",
       "      <td>61.11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>99.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.10</td>\n",
       "      <td>92.85</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>HR55AY9237</td>\n",
       "      <td>ZB Gurgaon</td>\n",
       "      <td>12.5</td>\n",
       "      <td>DISCHARGING</td>\n",
       "      <td>3</td>\n",
       "      <td>2025-09-01 06:13:05</td>\n",
       "      <td>2025-09-01 06:13:06</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>HR55AY9237</td>\n",
       "      <td>ZB Gurgaon</td>\n",
       "      <td>12.5</td>\n",
       "      <td>CHARGING</td>\n",
       "      <td>4</td>\n",
       "      <td>2025-09-01 06:13:07</td>\n",
       "      <td>2025-09-01 07:22:50</td>\n",
       "      <td>69.71</td>\n",
       "      <td>0.03</td>\n",
       "      <td>16.74</td>\n",
       "      <td>32.25</td>\n",
       "      <td>50.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>99.97</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>49.75</td>\n",
       "      <td>21.03</td>\n",
       "      <td>29.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3</td>\n",
       "      <td>HR55AY7626</td>\n",
       "      <td>ZB Gurgaon</td>\n",
       "      <td>12.5</td>\n",
       "      <td>CHARGING</td>\n",
       "      <td>2</td>\n",
       "      <td>2025-09-01 06:22:48</td>\n",
       "      <td>2025-09-01 07:00:22</td>\n",
       "      <td>37.56</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.82</td>\n",
       "      <td>88.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.14</td>\n",
       "      <td>99.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.91</td>\n",
       "      <td>44.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3</td>\n",
       "      <td>HR55AY7626</td>\n",
       "      <td>ZB Gurgaon</td>\n",
       "      <td>12.5</td>\n",
       "      <td>DISCHARGING</td>\n",
       "      <td>3</td>\n",
       "      <td>2025-09-01 07:00:23</td>\n",
       "      <td>2025-09-01 07:01:41</td>\n",
       "      <td>1.29</td>\n",
       "      <td>1.52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>98.48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>98.48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id     reg_num    customer model         mode  session  \\\n",
       "1   16  HR55AY9237  ZB Gurgaon  12.5     CHARGING        2   \n",
       "2   16  HR55AY9237  ZB Gurgaon  12.5  DISCHARGING        3   \n",
       "3   16  HR55AY9237  ZB Gurgaon  12.5     CHARGING        4   \n",
       "28   3  HR55AY7626  ZB Gurgaon  12.5     CHARGING        2   \n",
       "29   3  HR55AY7626  ZB Gurgaon  12.5  DISCHARGING        3   \n",
       "\n",
       "            start_time            end_time  duration  maxtemp_bucket_lt28_pct  \\\n",
       "1  2025-09-01 05:39:01 2025-09-01 06:13:04     34.05                     0.05   \n",
       "2  2025-09-01 06:13:05 2025-09-01 06:13:06      0.02                     0.00   \n",
       "3  2025-09-01 06:13:07 2025-09-01 07:22:50     69.71                     0.03   \n",
       "28 2025-09-01 06:22:48 2025-09-01 07:00:22     37.56                     0.05   \n",
       "29 2025-09-01 07:00:23 2025-09-01 07:01:41      1.29                     1.52   \n",
       "\n",
       "    maxtemp_bucket_28_32_pct  maxtemp_bucket_32_35_pct  \\\n",
       "1                       0.00                     38.84   \n",
       "2                       0.00                      0.00   \n",
       "3                      16.74                     32.25   \n",
       "28                      0.00                     11.82   \n",
       "29                      0.00                      0.00   \n",
       "\n",
       "    maxtemp_bucket_35_40_pct  maxtemp_bucket_gt40_pct  \\\n",
       "1                      61.11                      0.0   \n",
       "2                     100.00                      0.0   \n",
       "3                      50.99                      0.0   \n",
       "28                     88.14                      0.0   \n",
       "29                     98.48                      0.0   \n",
       "\n",
       "    temp_delta_bucket_lt2_pct  temp_delta_bucket_2_5_pct  \\\n",
       "1                        0.05                       0.05   \n",
       "2                        0.00                       0.00   \n",
       "3                        0.03                       0.00   \n",
       "28                       0.05                       0.14   \n",
       "29                       1.52                       0.00   \n",
       "\n",
       "    temp_delta_bucket_5_8_pct  temp_delta_bucket_gt8_pct  \\\n",
       "1                       99.90                        0.0   \n",
       "2                      100.00                        0.0   \n",
       "3                       99.97                        0.0   \n",
       "28                      99.81                        0.0   \n",
       "29                      98.48                        0.0   \n",
       "\n",
       "    volt_delta_bucket_0_10_pct  volt_delta_bucket_10_20_pct  \\\n",
       "1                         7.10                        92.85   \n",
       "2                         0.00                       100.00   \n",
       "3                         0.00                        49.75   \n",
       "28                       55.91                        44.09   \n",
       "29                      100.00                         0.00   \n",
       "\n",
       "    volt_delta_bucket_20_30_pct  volt_delta_bucket_gt30_pct  \n",
       "1                          0.05                        0.00  \n",
       "2                          0.00                        0.00  \n",
       "3                         21.03                       29.22  \n",
       "28                         0.00                        0.00  \n",
       "29                         0.00                        0.00  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session_report_df[(session_report_df.maxtemp_bucket_35_40_pct>40)|(session_report_df.maxtemp_bucket_gt40_pct>40)].to_csv('bcs_session_maxT.csv')\n",
    "session_report_df[(session_report_df.maxtemp_bucket_35_40_pct>40)|(session_report_df.maxtemp_bucket_gt40_pct>40)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f6f019fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>reg_num</th>\n",
       "      <th>customer</th>\n",
       "      <th>model</th>\n",
       "      <th>mode</th>\n",
       "      <th>session</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>duration</th>\n",
       "      <th>maxtemp_bucket_lt28_pct</th>\n",
       "      <th>maxtemp_bucket_28_32_pct</th>\n",
       "      <th>maxtemp_bucket_32_35_pct</th>\n",
       "      <th>maxtemp_bucket_35_40_pct</th>\n",
       "      <th>maxtemp_bucket_gt40_pct</th>\n",
       "      <th>temp_delta_bucket_lt2_pct</th>\n",
       "      <th>temp_delta_bucket_2_5_pct</th>\n",
       "      <th>temp_delta_bucket_5_8_pct</th>\n",
       "      <th>temp_delta_bucket_gt8_pct</th>\n",
       "      <th>volt_delta_bucket_0_10_pct</th>\n",
       "      <th>volt_delta_bucket_10_20_pct</th>\n",
       "      <th>volt_delta_bucket_20_30_pct</th>\n",
       "      <th>volt_delta_bucket_gt30_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>HR55AY9237</td>\n",
       "      <td>ZB Gurgaon</td>\n",
       "      <td>12.5</td>\n",
       "      <td>DISCHARGING</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-09-01 05:30:00</td>\n",
       "      <td>2025-09-01 05:37:36</td>\n",
       "      <td>7.59</td>\n",
       "      <td>3.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>96.72</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>96.72</td>\n",
       "      <td>1.64</td>\n",
       "      <td>41.67</td>\n",
       "      <td>56.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>HR55AY9237</td>\n",
       "      <td>ZB Gurgaon</td>\n",
       "      <td>12.5</td>\n",
       "      <td>CHARGING</td>\n",
       "      <td>2</td>\n",
       "      <td>2025-09-01 05:39:01</td>\n",
       "      <td>2025-09-01 06:13:04</td>\n",
       "      <td>34.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>38.84</td>\n",
       "      <td>61.11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>99.90</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.10</td>\n",
       "      <td>92.85</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>HR55AY9237</td>\n",
       "      <td>ZB Gurgaon</td>\n",
       "      <td>12.5</td>\n",
       "      <td>DISCHARGING</td>\n",
       "      <td>3</td>\n",
       "      <td>2025-09-01 06:13:05</td>\n",
       "      <td>2025-09-01 06:13:06</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>HR55AY9237</td>\n",
       "      <td>ZB Gurgaon</td>\n",
       "      <td>12.5</td>\n",
       "      <td>CHARGING</td>\n",
       "      <td>4</td>\n",
       "      <td>2025-09-01 06:13:07</td>\n",
       "      <td>2025-09-01 07:22:50</td>\n",
       "      <td>69.71</td>\n",
       "      <td>0.03</td>\n",
       "      <td>16.74</td>\n",
       "      <td>32.25</td>\n",
       "      <td>50.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>99.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>49.75</td>\n",
       "      <td>21.03</td>\n",
       "      <td>29.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16</td>\n",
       "      <td>HR55AY9237</td>\n",
       "      <td>ZB Gurgaon</td>\n",
       "      <td>12.5</td>\n",
       "      <td>CHARGING</td>\n",
       "      <td>6</td>\n",
       "      <td>2025-09-01 18:03:04</td>\n",
       "      <td>2025-09-01 18:05:26</td>\n",
       "      <td>2.36</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.74</td>\n",
       "      <td>98.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.00</td>\n",
       "      <td>98.53</td>\n",
       "      <td>0.74</td>\n",
       "      <td>35.56</td>\n",
       "      <td>62.96</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     reg_num    customer model         mode  session          start_time  \\\n",
       "0  16  HR55AY9237  ZB Gurgaon  12.5  DISCHARGING        1 2025-09-01 05:30:00   \n",
       "1  16  HR55AY9237  ZB Gurgaon  12.5     CHARGING        2 2025-09-01 05:39:01   \n",
       "2  16  HR55AY9237  ZB Gurgaon  12.5  DISCHARGING        3 2025-09-01 06:13:05   \n",
       "3  16  HR55AY9237  ZB Gurgaon  12.5     CHARGING        4 2025-09-01 06:13:07   \n",
       "5  16  HR55AY9237  ZB Gurgaon  12.5     CHARGING        6 2025-09-01 18:03:04   \n",
       "\n",
       "             end_time  duration  maxtemp_bucket_lt28_pct  \\\n",
       "0 2025-09-01 05:37:36      7.59                     3.28   \n",
       "1 2025-09-01 06:13:04     34.05                     0.05   \n",
       "2 2025-09-01 06:13:06      0.02                     0.00   \n",
       "3 2025-09-01 07:22:50     69.71                     0.03   \n",
       "5 2025-09-01 18:05:26      2.36                     0.74   \n",
       "\n",
       "   maxtemp_bucket_28_32_pct  maxtemp_bucket_32_35_pct  \\\n",
       "0                      0.00                     96.72   \n",
       "1                      0.00                     38.84   \n",
       "2                      0.00                      0.00   \n",
       "3                     16.74                     32.25   \n",
       "5                      0.74                     98.53   \n",
       "\n",
       "   maxtemp_bucket_35_40_pct  maxtemp_bucket_gt40_pct  \\\n",
       "0                      0.00                      0.0   \n",
       "1                     61.11                      0.0   \n",
       "2                    100.00                      0.0   \n",
       "3                     50.99                      0.0   \n",
       "5                      0.00                      0.0   \n",
       "\n",
       "   temp_delta_bucket_lt2_pct  temp_delta_bucket_2_5_pct  \\\n",
       "0                       1.64                       0.00   \n",
       "1                       0.05                       0.05   \n",
       "2                       0.00                       0.00   \n",
       "3                       0.03                       0.00   \n",
       "5                       0.74                       0.00   \n",
       "\n",
       "   temp_delta_bucket_5_8_pct  temp_delta_bucket_gt8_pct  \\\n",
       "0                      96.72                       1.64   \n",
       "1                      99.90                       0.00   \n",
       "2                     100.00                       0.00   \n",
       "3                      99.97                       0.00   \n",
       "5                      98.53                       0.74   \n",
       "\n",
       "   volt_delta_bucket_0_10_pct  volt_delta_bucket_10_20_pct  \\\n",
       "0                       41.67                        56.67   \n",
       "1                        7.10                        92.85   \n",
       "2                        0.00                       100.00   \n",
       "3                        0.00                        49.75   \n",
       "5                       35.56                        62.96   \n",
       "\n",
       "   volt_delta_bucket_20_30_pct  volt_delta_bucket_gt30_pct  \n",
       "0                         0.00                        1.67  \n",
       "1                         0.05                        0.00  \n",
       "2                         0.00                        0.00  \n",
       "3                        21.03                       29.22  \n",
       "5                         0.74                        0.74  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session_report_df[(session_report_df.temp_delta_bucket_5_8_pct>40)|(session_report_df.temp_delta_bucket_gt8_pct>40)].to_csv('bcs_session_deltaT.csv')\n",
    "session_report_df[(session_report_df.temp_delta_bucket_5_8_pct>40)|(session_report_df.temp_delta_bucket_gt8_pct>40)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "91ab3446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>reg_num</th>\n",
       "      <th>customer</th>\n",
       "      <th>model</th>\n",
       "      <th>mode</th>\n",
       "      <th>session</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>duration</th>\n",
       "      <th>maxtemp_bucket_lt28_pct</th>\n",
       "      <th>maxtemp_bucket_28_32_pct</th>\n",
       "      <th>maxtemp_bucket_32_35_pct</th>\n",
       "      <th>maxtemp_bucket_35_40_pct</th>\n",
       "      <th>maxtemp_bucket_gt40_pct</th>\n",
       "      <th>temp_delta_bucket_lt2_pct</th>\n",
       "      <th>temp_delta_bucket_2_5_pct</th>\n",
       "      <th>temp_delta_bucket_5_8_pct</th>\n",
       "      <th>temp_delta_bucket_gt8_pct</th>\n",
       "      <th>volt_delta_bucket_0_10_pct</th>\n",
       "      <th>volt_delta_bucket_10_20_pct</th>\n",
       "      <th>volt_delta_bucket_20_30_pct</th>\n",
       "      <th>volt_delta_bucket_gt30_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>16</td>\n",
       "      <td>HR55AY9237</td>\n",
       "      <td>ZB Gurgaon</td>\n",
       "      <td>12.5</td>\n",
       "      <td>CHARGING</td>\n",
       "      <td>18</td>\n",
       "      <td>2025-09-01 19:32:06</td>\n",
       "      <td>2025-09-01 20:03:09</td>\n",
       "      <td>31.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.10</td>\n",
       "      <td>87.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>99.94</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>45.21</td>\n",
       "      <td>51.71</td>\n",
       "      <td>3.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>16</td>\n",
       "      <td>HR55AY9237</td>\n",
       "      <td>ZB Gurgaon</td>\n",
       "      <td>12.5</td>\n",
       "      <td>CHARGING</td>\n",
       "      <td>20</td>\n",
       "      <td>2025-09-01 20:04:05</td>\n",
       "      <td>2025-09-01 20:32:22</td>\n",
       "      <td>28.29</td>\n",
       "      <td>0.07</td>\n",
       "      <td>72.54</td>\n",
       "      <td>27.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>32.33</td>\n",
       "      <td>67.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.21</td>\n",
       "      <td>2.28</td>\n",
       "      <td>8.85</td>\n",
       "      <td>87.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>16</td>\n",
       "      <td>HR55AY9237</td>\n",
       "      <td>ZB Gurgaon</td>\n",
       "      <td>12.5</td>\n",
       "      <td>CHARGING</td>\n",
       "      <td>20</td>\n",
       "      <td>2025-09-02 19:00:55</td>\n",
       "      <td>2025-09-02 19:34:57</td>\n",
       "      <td>34.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>67.06</td>\n",
       "      <td>32.94</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>78.84</td>\n",
       "      <td>21.11</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4.71</td>\n",
       "      <td>2.60</td>\n",
       "      <td>21.45</td>\n",
       "      <td>71.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>3</td>\n",
       "      <td>HR55AY7626</td>\n",
       "      <td>ZB Gurgaon</td>\n",
       "      <td>12.5</td>\n",
       "      <td>CHARGING</td>\n",
       "      <td>10</td>\n",
       "      <td>2025-09-02 20:07:28</td>\n",
       "      <td>2025-09-02 20:53:13</td>\n",
       "      <td>45.76</td>\n",
       "      <td>0.05</td>\n",
       "      <td>62.67</td>\n",
       "      <td>37.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>30.99</td>\n",
       "      <td>68.91</td>\n",
       "      <td>0.05</td>\n",
       "      <td>7.63</td>\n",
       "      <td>3.84</td>\n",
       "      <td>25.24</td>\n",
       "      <td>63.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>3</td>\n",
       "      <td>HR55AY7626</td>\n",
       "      <td>ZB Gurgaon</td>\n",
       "      <td>12.5</td>\n",
       "      <td>CHARGING</td>\n",
       "      <td>12</td>\n",
       "      <td>2025-09-02 20:53:16</td>\n",
       "      <td>2025-09-02 20:56:25</td>\n",
       "      <td>3.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id     reg_num    customer model      mode  session          start_time  \\\n",
       "17  16  HR55AY9237  ZB Gurgaon  12.5  CHARGING       18 2025-09-01 19:32:06   \n",
       "19  16  HR55AY9237  ZB Gurgaon  12.5  CHARGING       20 2025-09-01 20:04:05   \n",
       "51  16  HR55AY9237  ZB Gurgaon  12.5  CHARGING       20 2025-09-02 19:00:55   \n",
       "65   3  HR55AY7626  ZB Gurgaon  12.5  CHARGING       10 2025-09-02 20:07:28   \n",
       "67   3  HR55AY7626  ZB Gurgaon  12.5  CHARGING       12 2025-09-02 20:53:16   \n",
       "\n",
       "              end_time  duration  maxtemp_bucket_lt28_pct  \\\n",
       "17 2025-09-01 20:03:09     31.05                     0.00   \n",
       "19 2025-09-01 20:32:22     28.29                     0.07   \n",
       "51 2025-09-02 19:34:57     34.03                     0.00   \n",
       "65 2025-09-02 20:53:13     45.76                     0.05   \n",
       "67 2025-09-02 20:56:25      3.14                     0.00   \n",
       "\n",
       "    maxtemp_bucket_28_32_pct  maxtemp_bucket_32_35_pct  \\\n",
       "17                     12.10                     87.90   \n",
       "19                     72.54                     27.40   \n",
       "51                     67.06                     32.94   \n",
       "65                     62.67                     37.28   \n",
       "67                    100.00                      0.00   \n",
       "\n",
       "    maxtemp_bucket_35_40_pct  maxtemp_bucket_gt40_pct  \\\n",
       "17                       0.0                      0.0   \n",
       "19                       0.0                      0.0   \n",
       "51                       0.0                      0.0   \n",
       "65                       0.0                      0.0   \n",
       "67                       0.0                      0.0   \n",
       "\n",
       "    temp_delta_bucket_lt2_pct  temp_delta_bucket_2_5_pct  \\\n",
       "17                       0.00                       0.00   \n",
       "19                       0.07                      32.33   \n",
       "51                       0.00                      78.84   \n",
       "65                       0.05                      30.99   \n",
       "67                       0.00                       0.00   \n",
       "\n",
       "    temp_delta_bucket_5_8_pct  temp_delta_bucket_gt8_pct  \\\n",
       "17                      99.94                       0.06   \n",
       "19                      67.61                       0.00   \n",
       "51                      21.11                       0.05   \n",
       "65                      68.91                       0.05   \n",
       "67                     100.00                       0.00   \n",
       "\n",
       "    volt_delta_bucket_0_10_pct  volt_delta_bucket_10_20_pct  \\\n",
       "17                        0.00                        45.21   \n",
       "19                        1.21                         2.28   \n",
       "51                        4.71                         2.60   \n",
       "65                        7.63                         3.84   \n",
       "67                        0.00                         0.00   \n",
       "\n",
       "    volt_delta_bucket_20_30_pct  volt_delta_bucket_gt30_pct  \n",
       "17                        51.71                        3.08  \n",
       "19                         8.85                       87.66  \n",
       "51                        21.45                       71.24  \n",
       "65                        25.24                       63.29  \n",
       "67                         0.00                      100.00  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session_report_df[(session_report_df.volt_delta_bucket_20_30_pct>40)|(session_report_df.volt_delta_bucket_gt30_pct>40)].to_csv('bcs_session_deltaV.csv')\n",
    "session_report_df[(session_report_df.volt_delta_bucket_20_30_pct>40)|(session_report_df.volt_delta_bucket_gt30_pct>40)].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "naarni_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
