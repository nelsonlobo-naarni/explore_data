{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85713bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import platform\n",
    "import logging\n",
    "import argparse\n",
    "import trino\n",
    "import io\n",
    "import boto3\n",
    "from itertools import islice\n",
    "from datetime import datetime, date, timedelta\n",
    "import pendulum\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ef76437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Python version: 3.13.7\n"
     ]
    }
   ],
   "source": [
    "# Add parent directory to path\n",
    "repo_path = '/Users/apple/Documents/naarni/repo/dview-naarni-data-platform'\n",
    "sys.path.append(os.path.join(repo_path, 'tasks'))\n",
    "\n",
    "# Import necessary files and its respective functions\n",
    "from common.db_operations import connect_to_trino, fetch_data_for_day, write_df_to_iceberg,drop_table,execute_query\n",
    "from common.optimizer_logic import optimize_dataframe_memory\n",
    "\n",
    "# Import business logic functions\n",
    "from biz_logic.energy_mileage.energy_mileage_daily_v0 import energy_mileage_stats ,impute_odometer_readings\n",
    "\n",
    "from biz_logic.energy_consumption.energy_consumption_report import energy_consumption_stats\n",
    "\n",
    "# Configure basic logging\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Print the Python version being used\n",
    "print(f\"Using Python version: {platform.python_version()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70291a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- reporting config (edit ONLY this) ----\n",
    "TABLE_NAME = \"can_parsed_output_100\"   # <‚Äî change only this\n",
    "\n",
    "# derived (don‚Äôt edit)\n",
    "REPORT_TABLE = f\"adhoc.facts_prod.{TABLE_NAME}\"\n",
    "REPORT_S3_LOCATION = f\"s3a://naarni-data-lake/aqua/warehouse/facts_prod.db/{TABLE_NAME}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14140356",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-08 20:25:11 - INFO - üîç Query window (UTC): 2025-10-26 18:30:00 ‚Üí 2025-10-27 18:30:00\n",
      "2025-11-08 20:25:11 - INFO - üîç Query window (IST): 2025-10-27 00:00:00 ‚Üí 2025-10-28 00:00:00\n"
     ]
    }
   ],
   "source": [
    "date_str = \"2025-10-27\"  # Date for which data is to be processed\n",
    "\n",
    "# Parse the date string as a date object\n",
    "target_date = datetime.strptime(date_str, \"%Y-%m-%d\").date()\n",
    "\n",
    "# Create datetime objects for the start and end of the day in IST\n",
    "ist_start = datetime.combine(target_date, datetime.min.time())\n",
    "ist_end = ist_start + timedelta(days=1)\n",
    "\n",
    "# Convert IST to UTC for the database query\n",
    "# IST is UTC+5:30, so we subtract 5 hours and 30 minutes\n",
    "utc_start = ist_start - timedelta(hours=5, minutes=30)\n",
    "utc_end = ist_end - timedelta(hours=5, minutes=30)\n",
    "\n",
    "logging.info(f\"üîç Query window (UTC): {utc_start} ‚Üí {utc_end}\")\n",
    "logging.info(f\"üîç Query window (IST): {ist_start} ‚Üí {ist_end}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c77dd55",
   "metadata": {},
   "source": [
    "### AC Fault Code:\n",
    "1. No_Fault\n",
    "2. Low_Voltage\n",
    "3. Outside_Temp_Sensor_Fault\n",
    "4. High_Voltage\n",
    "5. Exhaust_Temp_Protection\n",
    "6. Eva_Temp_Sesnor_Fault\n",
    "7. AC Communication Fail\n",
    "\n",
    "### AC Status:\n",
    "1. Start\n",
    "2. Stop\n",
    "\n",
    "### TMS Fault Code:\n",
    "1. No Fault\n",
    "2. Water_Sensor_Failure\n",
    "3. Water_Pump_Failure\n",
    "4. Water_IN_Sensor_Failure\n",
    "5. Exhaust_Temp_Protection\n",
    "6. Low_Water_Level_Alarm\n",
    "7. LV Undervoltage\n",
    "\n",
    "### TMS Working Mode:\n",
    "1. Charging_Cooling\n",
    "2. Fast_Discharge_Cooling\n",
    "3. Self_Circulation\n",
    "4. Low_Coolant\n",
    "5. Off\n",
    "\n",
    "### B2T TMS Control Cmd:\n",
    "1. Charging_Cooling\n",
    "2. Fast_Discharge_Cooling\n",
    "3. Self_Circulation\n",
    "4. Off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ff69d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-08 20:25:11 - INFO - üîå STEP 1: Connecting to Trino...\n",
      "2025-11-08 20:25:11 - INFO - ‚úÖ STEP 1: Connected to Trino\n",
      "2025-11-08 20:25:11 - INFO - ‚öôÔ∏è Executing query...\n",
      "2025-11-08 20:25:11 - ERROR - ‚ùå ERROR: Query execution failed: error 404\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = f\"\"\"\n",
    "select \n",
    "    id,date(timestamp + interval '5:30' hour to minute) as dateval,count(*) \n",
    "FROM \n",
    "    facts_prod.can_parsed_output_100\n",
    "where \n",
    "    id in ('6') and \n",
    "    timestamp >= TIMESTAMP '{utc_start.strftime('%Y-%m-%d %H:%M:%S')}' and\n",
    "    timestamp < TIMESTAMP '{utc_end.strftime('%Y-%m-%d %H:%M:%S')}'\n",
    "group by 1,2\"\"\"\n",
    "\n",
    "conn = connect_to_trino(host=\"analytics.internal.naarni.com\",port=443,user=\"admin\",catalog=\"adhoc\",schema=\"default\")\n",
    "\n",
    "df = execute_query(conn, f\"SELECT * FROM {REPORT_TABLE} LIMIT 5\", return_results=True)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3fdb3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_battery_data(start_date, end_date, vehicle_ids):\n",
    "    \"\"\"\n",
    "    Fetch raw battery data from the database for the specified date range and vehicle IDs.\n",
    "    \n",
    "    Args:\n",
    "        start_date: Start date in 'YYYY-MM-DD' format\n",
    "        end_date: End date in 'YYYY-MM-DD' format\n",
    "        vehicle_ids: List of vehicle IDs\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (df_cpo100, df_can_ac) containing raw data from both tables\n",
    "    \"\"\"\n",
    "    logging.info(f\"Fetching raw battery data from {start_date} to {end_date} for vehicles {vehicle_ids}\")\n",
    "    \n",
    "    # Format vehicle IDs for the query\n",
    "    vehicle_ids_str = ', '.join([f\"'{vid}'\" for vid in vehicle_ids])\n",
    "    \n",
    "    # Connect to Trino\n",
    "    conn = connect_to_trino(host=\"analytics.internal.naarni.com\", port=443, user=\"admin\", \n",
    "                           catalog=\"adhoc\", schema=\"default\")\n",
    "\n",
    "    # Query for cpo100 data\n",
    "    cpo100_query = f\"\"\"\n",
    "    SELECT \n",
    "        id, CAST(timestamp AS TIMESTAMP) AT TIME ZONE 'Asia/Kolkata' as timestamp, dt, \n",
    "        batterycoolingstate, batterycoolanttemperature,\n",
    "        temperaturedifferencealarm, chargingcurrentalarm, dischargecurrentalarm,\n",
    "        vehiclereadycondition, gun_connection_status, ignitionstatus,\n",
    "        vehicle_speed_vcu,gear_position,bat_soc,\n",
    "        pack1_cellmax_temperature, pack1_cell_min_temperature, pack1_maxtemperature_cell_number,  pack1_celltemperature_cellnumber,\n",
    "        bat_voltage,cellmax_voltagecellnumber,cell_max_voltage,cellminvoltagecellnumber,cell_min_voltage,\n",
    "        lowpressureoilpumpfaultcode,bms_fault_code,vcu_fault_code,fiveinone_faultcode\n",
    "    FROM \n",
    "        facts_prod.can_parsed_output_100\n",
    "    WHERE \n",
    "        id IN ({vehicle_ids_str})\n",
    "        AND DATE(timestamp AT TIME ZONE 'Asia/Kolkata') >= DATE('{start_date}')\n",
    "        AND DATE(timestamp AT TIME ZONE 'Asia/Kolkata') <= DATE('{end_date}')\n",
    "    \"\"\"\n",
    "\n",
    "    # Query for can_ac data\n",
    "    can_ac_query = f\"\"\"\n",
    "    SELECT \n",
    "        id, CAST(timestamp AS TIMESTAMP) AT TIME ZONE 'Asia/Kolkata' as timestamp, date,\n",
    "        b2t_tms_control_cmd, b2t_set_water_out_temp, b2t_battery_min_temp, b2t_battery_max_temp,\n",
    "        tms_working_mode, tms_fault_code, ac_fault_code, coolant_out_temp, coolant_in_temp,\n",
    "        comp_status,comp_target_hz as comp_target_freq,\n",
    "        comp_running_frequency as comp_running_freq,\n",
    "        v2t_vehicle_coolant_low, comp_current, hv_voltage\n",
    "    FROM \n",
    "        facts_prod.can_output_ac\n",
    "    WHERE\n",
    "        id IN ({vehicle_ids_str})\n",
    "        AND DATE(timestamp AT TIME ZONE 'Asia/Kolkata')  >= DATE('{start_date}')\n",
    "        AND DATE(timestamp AT TIME ZONE 'Asia/Kolkata') <= DATE('{end_date}')\n",
    "        and b2t_battery_min_temp > 0\n",
    "        and b2t_battery_max_temp > 0\n",
    "        and coolant_in_temp > 0\n",
    "    \"\"\"\n",
    "\n",
    "    # Execute queries and fetch data\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    # Fetch cpo100 data\n",
    "    cur.execute(cpo100_query)\n",
    "    cpo100_columns = [desc[0] for desc in cur.description]\n",
    "    cpo100_rows = cur.fetchall()\n",
    "    df_cpo100 = pd.DataFrame(cpo100_rows, columns=cpo100_columns)\n",
    "\n",
    "    # Fetch can_ac data\n",
    "    cur.execute(can_ac_query)\n",
    "    can_ac_columns = [desc[0] for desc in cur.description]\n",
    "    can_ac_rows = cur.fetchall()\n",
    "    df_can_ac = pd.DataFrame(can_ac_rows, columns=can_ac_columns)\n",
    "\n",
    "    logging.info(f\"Done Fetching data.\")\n",
    "    logging.info(f\"Retrieved {len(df_cpo100)} cpo100 records and {len(df_can_ac)} can_ac records\")\n",
    "    \n",
    "    # Close connections\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    \n",
    "    return df_cpo100, df_can_ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c336bdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_battery_data(df_cpo100, df_can_ac):\n",
    "    \"\"\"\n",
    "    Process raw battery data to create the final merged dataset.\n",
    "    \n",
    "    Args:\n",
    "        df_cpo100: Raw DataFrame from can_parsed_output_100 table\n",
    "        df_can_ac: Raw DataFrame from can_output_ac table\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (result_df, df_cpo100_processed, df_can_ac_processed)\n",
    "        where result_df is the final merged dataset and the others are processed versions\n",
    "    \"\"\"\n",
    "    logging.info(\"Processing battery data\")\n",
    "    \n",
    "    # Convert timestamp columns to datetime if they aren't already\n",
    "    df_cpo100['timestamp'] = pd.to_datetime(df_cpo100['timestamp'])\n",
    "    df_can_ac['timestamp'] = pd.to_datetime(df_can_ac['timestamp'])\n",
    "    \n",
    "    # Perform minute truncation in pandas\n",
    "    df_cpo100['ts_mins'] = df_cpo100['timestamp'].dt.floor('min')\n",
    "    df_can_ac['ts_mins_cac'] = df_can_ac['timestamp'].dt.floor('min')\n",
    "\n",
    "    # Add row numbers (equivalent to SQL row_number() window function)\n",
    "    # For cpo100\n",
    "    df_cpo100 = df_cpo100.sort_values(['id', 'ts_mins', 'timestamp'])\n",
    "    df_cpo100['cpo_rn'] = df_cpo100.groupby(['id', 'ts_mins']).cumcount() + 1\n",
    "\n",
    "    # For can_ac\n",
    "    df_can_ac = df_can_ac.sort_values(['id', 'ts_mins_cac', 'timestamp'])\n",
    "    df_can_ac['cac_rn'] = df_can_ac.groupby(['id', 'ts_mins_cac']).cumcount() + 1\n",
    "\n",
    "    # Perform the join in pandas (equivalent to SQL right join)\n",
    "    merged_df = pd.merge(\n",
    "        df_can_ac,\n",
    "        df_cpo100,\n",
    "        left_on=['id', 'ts_mins_cac', 'cac_rn'],\n",
    "        right_on=['id', 'ts_mins', 'cpo_rn'],\n",
    "        how='left',\n",
    "        suffixes=('_can_ac','_cpo100')\n",
    "    )\n",
    "\n",
    "    # Select only the columns we need\n",
    "    result_columns = []\n",
    "\n",
    "    # Add id column\n",
    "    if 'id' in merged_df.columns:\n",
    "        result_columns.append('id')\n",
    "    elif 'id_cpo100' in merged_df.columns:\n",
    "        result_columns.append('id_cpo100')\n",
    "\n",
    "    # Add other columns from cpo100\n",
    "    cpo100_cols = ['dt', 'ignitionstatus', 'vehiclereadycondition', 'gun_connection_status',\n",
    "                   'vehicle_speed_vcu','gear_position','bat_soc',\n",
    "                # pack1_cellmax_temperature, pack1_cell_min_temperature, pack1_maxtemperature_cell_number, pack1_celltemperature_cellnumber,                   \n",
    "                   'pack1_cellmax_temperature', 'pack1_cell_min_temperature',\n",
    "                   'pack1_maxtemperature_cell_number','pack1_celltemperature_cellnumber',\n",
    "                   'bat_voltage','cellmax_voltagecellnumber','cell_max_voltage','cellminvoltagecellnumber','cell_min_voltage']\n",
    "    \n",
    "    for col in cpo100_cols:\n",
    "        if col in merged_df.columns:\n",
    "            result_columns.append(col)\n",
    "        elif f'{col}_cpo100' in merged_df.columns:\n",
    "            result_columns.append(f'{col}_cpo100')\n",
    "\n",
    "    # Add timestamp (from cpo100)\n",
    "    if 'timestamp_cpo100' in merged_df.columns:\n",
    "        result_columns.append('timestamp_cpo100')\n",
    "    elif 'timestamp' in merged_df.columns:\n",
    "        result_columns.append('timestamp')\n",
    "\n",
    "    # Add ts_mins (from cpo100)\n",
    "    if 'ts_mins_cpo100' in merged_df.columns:\n",
    "        result_columns.append('ts_mins_cpo100')\n",
    "    elif 'ts_mins' in merged_df.columns:\n",
    "        result_columns.append('ts_mins')\n",
    "\n",
    "    # Add columns from can_ac\n",
    "    can_ac_cols = ['b2t_tms_control_cmd', 'b2t_set_water_out_temp', \n",
    "                  'b2t_battery_min_temp', 'b2t_battery_max_temp', 'tms_working_mode',\n",
    "                  'coolant_out_temp', 'coolant_in_temp', 'hv_voltage',\n",
    "                  'comp_target_freq','comp_running_freq',\n",
    "                  'comp_status','tms_fault_code','ac_fault_code']\n",
    "\n",
    "    for col in can_ac_cols:\n",
    "        if col in merged_df.columns:\n",
    "            result_columns.append(col)\n",
    "        elif f'{col}_can_ac' in merged_df.columns:\n",
    "            result_columns.append(f'{col}_can_ac')\n",
    "\n",
    "    # Create result DataFrame with selected columns\n",
    "    result_df = merged_df[result_columns].copy()\n",
    "\n",
    "    # Rename columns to match original query output\n",
    "    rename_dict = {}\n",
    "    if 'id_cpo100' in result_df.columns:\n",
    "        rename_dict['id_cpo100'] = 'id'\n",
    "    if 'timestamp_cpo100' in result_df.columns:\n",
    "        rename_dict['timestamp_cpo100'] = 'timestamp'\n",
    "    if 'ts_mins_cpo100' in result_df.columns:\n",
    "        rename_dict['ts_mins_cpo100'] = 'ts_mins'\n",
    "\n",
    "    # Rename any columns with _can_ac suffix\n",
    "    for col in result_df.columns:\n",
    "        if col.endswith('_can_ac'):\n",
    "            rename_dict[col] = col[:-7]  # Remove the '_can_ac' suffix\n",
    "\n",
    "    result_df = result_df.rename(columns=rename_dict)\n",
    "\n",
    "    # Sort the result as in the original query\n",
    "    result_df = result_df.sort_values(['id', 'timestamp'])\n",
    "\n",
    "    logging.info(f\"Processed {len(result_df)} battery data records\")\n",
    "    return result_df, df_cpo100, df_can_ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e137cc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_battery_data(start_date, end_date, vehicle_ids):\n",
    "    \"\"\"\n",
    "    Fetch and process all battery data for the specified date range and vehicle IDs.\n",
    "    \n",
    "    Args:\n",
    "        start_date: Start date in 'YYYY-MM-DD' format\n",
    "        end_date: End date in 'YYYY-MM-DD' format\n",
    "        vehicle_ids: List of vehicle IDs\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with battery data\n",
    "    \"\"\"\n",
    "    # Fetch raw data\n",
    "    df_cpo100, df_can_ac = fetch_battery_data(start_date, end_date, vehicle_ids)\n",
    "    \n",
    "    # Process the data\n",
    "    result_df, df_cpo100_processed, df_can_ac_processed = process_battery_data(df_cpo100, df_can_ac)\n",
    "    \n",
    "    return result_df, df_cpo100_processed, df_can_ac_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c3f3d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-08 20:25:11 - INFO - Fetching raw battery data from 2025-10-01 to 2025-10-02 for vehicles ['6']\n",
      "2025-11-08 20:25:11 - INFO - üîå STEP 1: Connecting to Trino...\n",
      "2025-11-08 20:25:11 - INFO - ‚úÖ STEP 1: Connected to Trino\n"
     ]
    },
    {
     "ename": "HttpError",
     "evalue": "error 404",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHttpError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df, df_cpo100, df_can_ac = \u001b[43mget_all_battery_data\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m2025-10-01\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m2025-10-02\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m6\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mget_all_battery_data\u001b[39m\u001b[34m(start_date, end_date, vehicle_ids)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03mFetch and process all battery data for the specified date range and vehicle IDs.\u001b[39;00m\n\u001b[32m      4\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     11\u001b[39m \u001b[33;03m    DataFrame with battery data\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Fetch raw data\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m df_cpo100, df_can_ac = \u001b[43mfetch_battery_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvehicle_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Process the data\u001b[39;00m\n\u001b[32m     17\u001b[39m result_df, df_cpo100_processed, df_can_ac_processed = process_battery_data(df_cpo100, df_can_ac)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 65\u001b[39m, in \u001b[36mfetch_battery_data\u001b[39m\u001b[34m(start_date, end_date, vehicle_ids)\u001b[39m\n\u001b[32m     62\u001b[39m cur = conn.cursor()\n\u001b[32m     64\u001b[39m \u001b[38;5;66;03m# Fetch cpo100 data\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m \u001b[43mcur\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcpo100_query\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m cpo100_columns = [desc[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m desc \u001b[38;5;129;01min\u001b[39;00m cur.description]\n\u001b[32m     67\u001b[39m cpo100_rows = cur.fetchall()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/naarni/repo/naarni_env/lib/python3.13/site-packages/trino/dbapi.py:640\u001b[39m, in \u001b[36mCursor.execute\u001b[39m\u001b[34m(self, operation, params)\u001b[39m\n\u001b[32m    637\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    638\u001b[39m     \u001b[38;5;28mself\u001b[39m._query = trino.client.TrinoQuery(\u001b[38;5;28mself\u001b[39m._request, query=operation,\n\u001b[32m    639\u001b[39m                                           legacy_primitive_types=\u001b[38;5;28mself\u001b[39m._legacy_primitive_types)\n\u001b[32m--> \u001b[39m\u001b[32m640\u001b[39m     \u001b[38;5;28mself\u001b[39m._iterator = \u001b[38;5;28miter\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_query\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    641\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/naarni/repo/naarni_env/lib/python3.13/site-packages/trino/client.py:895\u001b[39m, in \u001b[36mTrinoQuery.execute\u001b[39m\u001b[34m(self, additional_http_headers)\u001b[39m\n\u001b[32m    893\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m requests.exceptions.RequestException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    894\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m trino.exceptions.TrinoConnectionError(\u001b[33m\"\u001b[39m\u001b[33mfailed to execute: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(e))\n\u001b[32m--> \u001b[39m\u001b[32m895\u001b[39m status = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    896\u001b[39m \u001b[38;5;28mself\u001b[39m._info_uri = status.info_uri\n\u001b[32m    897\u001b[39m \u001b[38;5;28mself\u001b[39m._query_id = status.id\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/naarni/repo/naarni_env/lib/python3.13/site-packages/trino/client.py:693\u001b[39m, in \u001b[36mTrinoRequest.process\u001b[39m\u001b[34m(self, http_response)\u001b[39m\n\u001b[32m    691\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m, http_response: Response) -> TrinoStatus:\n\u001b[32m    692\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m http_response.ok:\n\u001b[32m--> \u001b[39m\u001b[32m693\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraise_response_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp_response\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    695\u001b[39m     http_response.encoding = \u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    696\u001b[39m     response = json.loads(http_response.text)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/naarni/repo/naarni_env/lib/python3.13/site-packages/trino/client.py:684\u001b[39m, in \u001b[36mTrinoRequest.raise_response_error\u001b[39m\u001b[34m(http_response)\u001b[39m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_response.status_code == \u001b[32m504\u001b[39m:\n\u001b[32m    682\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions.Http504Error(\u001b[33m\"\u001b[39m\u001b[33merror 504: gateway timeout\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m684\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exceptions.HttpError(\n\u001b[32m    685\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33merror \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    686\u001b[39m         http_response.status_code,\n\u001b[32m    687\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(http_response.content) \u001b[38;5;28;01mif\u001b[39;00m http_response.content \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    688\u001b[39m     )\n\u001b[32m    689\u001b[39m )\n",
      "\u001b[31mHttpError\u001b[39m: error 404"
     ]
    }
   ],
   "source": [
    "df, df_cpo100, df_can_ac = get_all_battery_data('2025-10-01', '2025-10-02', ['6'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bb2ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbf1c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02a3a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_can_ac.comp_running_freq.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c157919e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_can_ac.comp_running_freq.value_counts(dropna=False).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5362c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cpo100.batterycoolingstate.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d75f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cpo100.bat_soc.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d28bb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(df_cpo100.head())\n",
    "# display(df_cpo100.lowpressureoilpumpfaultcode.value_counts())\n",
    "# display(df_cpo100.bms_fault_code.value_counts())\n",
    "# display(df_cpo100.fiveinone_faultcode.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4121d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_freq(series):\n",
    "    \"\"\"Convert to numeric, drop garbage, and fill short missing runs smoothly.\"\"\"\n",
    "    if series is None:\n",
    "        return None\n",
    "    s = pd.to_numeric(series, errors=\"coerce\")\n",
    "    \n",
    "    # If everything is NaN, return as-is (don‚Äôt invent values)\n",
    "    if s.dropna().empty:\n",
    "        return s\n",
    "    \n",
    "    # Light smoothing: forward-fill then back-fill to close small gaps\n",
    "    s = s.ffill().bfill()\n",
    "    \n",
    "    return s\n",
    "\n",
    "def safe_get(df, col):\n",
    "    return df[col] if col in df.columns else pd.Series(dtype=float)\n",
    "\n",
    "def safe_min(series):\n",
    "    \"\"\"Return min safely without warnings on empty or all-NaN slices.\"\"\"\n",
    "    s = pd.to_numeric(series, errors='coerce').dropna()\n",
    "    return round(s.min(), 3) if len(s) > 0 else np.nan\n",
    "\n",
    "def safe_max(series):\n",
    "    \"\"\"Return max safely without warnings on empty or all-NaN slices.\"\"\"\n",
    "    s = pd.to_numeric(series, errors='coerce').dropna()\n",
    "    return round(s.max(), 3) if len(s) > 0 else np.nan\n",
    "\n",
    "def safe_median(series):\n",
    "    \"\"\"Return median safely without warnings on empty or all-NaN slices.\"\"\"\n",
    "    s = pd.to_numeric(series, errors='coerce').dropna()\n",
    "    return round(s.median(), 3) if len(s) > 0 else np.nan\n",
    "\n",
    "def safe_mean(series):\n",
    "    \"\"\"Return mean safely without warnings on empty or all-NaN slices.\"\"\"\n",
    "    s = pd.to_numeric(series, errors='coerce').dropna()\n",
    "    return round(s.mean(), 3) if len(s) > 0 else np.nan\n",
    "\n",
    "\n",
    "def scalar_mode(s: pd.Series):\n",
    "    \"\"\"Return a single scalar mode value from a pandas Series.\"\"\"\n",
    "    s = s.dropna()\n",
    "    if s.empty:\n",
    "        return np.nan\n",
    "    m = s.mode(dropna=True)\n",
    "    return m.iloc[0] if not m.empty else np.nan\n",
    "\n",
    "\n",
    "def process_tms_transitions(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Identify transitions in TMS state parameters and summarize continuous states\n",
    "    with temperature and cell voltage details.\n",
    "    \"\"\"\n",
    "    # --- Preprocess timestamp ---\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')\n",
    "    df = df.sort_values('timestamp').reset_index(drop=True)\n",
    "\n",
    "    # --- Clean compressor status ---\n",
    "    df[\"comp_status\"] = (df[\"comp_status\"].ffill().replace({\"nan\": np.nan}))\n",
    "    # ensure first value isn't NaN to avoid false trigger at start\n",
    "    if pd.isna(df.loc[0, \"comp_status\"]):\n",
    "        df.loc[0, \"comp_status\"] = \"Off\"  # or whichever baseline makes sense\n",
    "\n",
    "    df[\"comp_target_freq\"] = df[\"comp_target_freq\"].ffill().replace({\"nan\": np.nan})\n",
    "    # ensure first value isn't NaN to avoid false trigger at start\n",
    "    if pd.isna(df.loc[0, \"comp_target_freq\"]):\n",
    "        df.loc[0, \"comp_target_freq\"] = 0  # or whichever baseline makes sense\n",
    "\n",
    "    df[\"comp_running_freq\"] = df[\"comp_running_freq\"].ffill().replace({\"nan\": np.nan})\n",
    "    # ensure first value isn't NaN to avoid false trigger at start\n",
    "    if pd.isna(df.loc[0, \"comp_running_freq\"]):\n",
    "        df.loc[0, \"comp_running_freq\"] = 0  # or whichever baseline makes sense\n",
    "\n",
    "\n",
    "    # --- Clean AC fault code ---\n",
    "    df[\"ac_fault_code\"] = (df[\"ac_fault_code\"].ffill().replace({\"nan\": np.nan}))\n",
    "    # ensure first value isn't NaN to avoid false trigger at start\n",
    "    if pd.isna(df.loc[0, \"ac_fault_code\"]):\n",
    "        df.loc[0, \"ac_fault_code\"] = \"No Fault\"  # or whichever baseline makes sense\n",
    "\n",
    "    rename_map = {\n",
    "        \"b2t_battery_min_temp\": \"batt_mintemp\",\n",
    "        \"b2t_battery_max_temp\": \"batt_maxtemp\",        \n",
    "        \"coolant_in_temp\": \"coolant_in\",\n",
    "        \"coolant_out_temp\": \"coolant_out\",\n",
    "        \"bat_soc\": \"soc\",\n",
    "        \"pack1_celltemperature_cellnumber\": \"mintemp_cellnum\",\n",
    "        \"pack1_maxtemperature_cell_number\": \"maxtemp_cellnum\",\n",
    "        \"cellminvoltagecellnumber\": \"minvolt_cellnum\",\n",
    "        \"cellmax_voltagecellnumber\": \"maxvolt_cellnum\",\n",
    "        \"cell_max_voltage\": \"max_cellvolt\",\n",
    "        \"cell_min_voltage\": \"min_cellvolt\",\n",
    "        \"vehiclereadycondition\": \"veh_status\",\n",
    "        \"gun_connection_status\": \"gun_status\",\n",
    "    }\n",
    "    df.rename(columns={k: v for k, v in rename_map.items() if k in df.columns}, inplace=True)\n",
    "\n",
    "    # --- Define key columns ---\n",
    "    transition_cols = [\"b2t_tms_control_cmd\", \"tms_working_mode\"]\n",
    "    # \"b2t_set_water_out_temp\", \n",
    "    temp_cols = [\"batt_mintemp\", \"batt_maxtemp\", \"coolant_out\", \"coolant_in\", \n",
    "                 \"mintemp_cellnum\", \"maxtemp_cellnum\", \"minvolt_cellnum\", \"maxvolt_cellnum\",\n",
    "                 \"max_cellvolt\", \"min_cellvolt\", \"bat_voltage\", \"hv_voltage\", \"soc\"]\n",
    "    \n",
    "    # --- Identify transitions ---\n",
    "    change_mask = (df[transition_cols] != df[transition_cols].shift()).any(axis=1)\n",
    "    df[\"state_group\"] = change_mask.cumsum()\n",
    "\n",
    "    # --- Summarize each state group ---\n",
    "    summary_list = []\n",
    "    for group_id, group in df.groupby(\"state_group\"):\n",
    "        if group.empty:\n",
    "            continue\n",
    "\n",
    "        start_row = group.iloc[0]\n",
    "        end_row = group.iloc[-1]\n",
    "\n",
    "        # Determine vehicle mode\n",
    "        ignition = start_row.get(\"ignitionstatus\", np.nan)\n",
    "        vehicle_ready = start_row.get(\"veh_status\", np.nan)\n",
    "        gun_status = start_row.get(\"gun_status\", np.nan)\n",
    "        if vehicle_ready == 1.0:\n",
    "            mode = \"Drive\"\n",
    "        elif gun_status == 1.0:\n",
    "            mode = \"Charging/Park\"\n",
    "        else:\n",
    "            mode = \"Idle/Other\"\n",
    "\n",
    "        # --- Compressor metrics within the group ---\n",
    "        comp_col = \"comp_status\"\n",
    "        if comp_col in group.columns:\n",
    "            comp = group[[\"timestamp\", comp_col]].copy()\n",
    "            comp[comp_col] = comp[comp_col].astype(str).str.strip().str.lower()\n",
    "            comp[\"next_time\"] = comp[\"timestamp\"].shift(-1)\n",
    "            comp[\"interval_min\"] = (comp[\"next_time\"] - comp[\"timestamp\"]).dt.total_seconds() / 60.0\n",
    "\n",
    "            # Calculate total minutes in each state\n",
    "            on_time = comp.loc[comp[comp_col] == \"on\", \"interval_min\"].sum(skipna=True)\n",
    "            off_time = comp.loc[comp[comp_col] == \"off\", \"interval_min\"].sum(skipna=True)\n",
    "            duty_cycle = (on_time * 100.0) / (on_time + off_time) if (on_time + off_time) > 0 else np.nan\n",
    "        else:\n",
    "            on_time = off_time = duty_cycle = np.nan\n",
    "\n",
    "\n",
    "        # Build summary record\n",
    "        record = {\n",
    "            \"start_time\": start_row[\"timestamp\"],\n",
    "            \"end_time\": end_row[\"timestamp\"],\n",
    "            \"duration_mins\": round((end_row[\"timestamp\"] - start_row[\"timestamp\"]).total_seconds() / 60.0, 2),\n",
    "            \"mode\": mode,\n",
    "            \"vehicle_speed_start\": round(start_row.get(\"vehicle_speed_vcu\", np.nan), 1),\n",
    "            \"ignitionstatus_start\": start_row.get(\"ignitionstatus\", np.nan),\n",
    "            \"veh_status_start\": start_row.get(\"veh_status\", np.nan),\n",
    "            \"gun_status_start\": start_row.get(\"gun_status\", np.nan),\n",
    "            **{f\"{col}_start\": start_row[col] for col in temp_cols},\n",
    "            **{f\"{col}_end\": end_row[col] for col in temp_cols},\n",
    "            **{col: start_row[col] for col in transition_cols},\n",
    "            \n",
    "            # Temperature statistics\n",
    "            \"batt_mintemp_lowest\": safe_min(group[\"batt_mintemp\"]),\n",
    "            \"batt_maxtemp_highest\": safe_max(group[\"batt_maxtemp\"]),\n",
    "            \"batt_mintemp_med\": safe_median(group[\"batt_mintemp\"]),\n",
    "            \"batt_maxtemp_med\": safe_median(group[\"batt_maxtemp\"]),\n",
    "            \"coolant_out_med\": safe_median(group[\"coolant_out\"]),\n",
    "            \"coolant_in_med\": safe_median(group[\"coolant_in\"]),\n",
    "\n",
    "            # Temperature cell data\n",
    "            \"mintemp_cellnum_mode\": scalar_mode(group[\"mintemp_cellnum\"]),            \n",
    "            \"maxtemp_cellnum_mode\": scalar_mode(group[\"maxtemp_cellnum\"]),\n",
    "\n",
    "            # Compressor metrics\n",
    "            \"comp_status_on_time\": round(on_time, 2),\n",
    "            \"comp_status_off_time\": round(off_time, 2),\n",
    "            \"comp_duty_cycle\": round(duty_cycle, 2),\n",
    "\n",
    "            # Voltage cell data\n",
    "            \"minvolt_cellnum_mode\": scalar_mode(safe_get(group, \"minvolt_cellnum\")),\n",
    "            \"maxvolt_cellnum_mode\": scalar_mode(safe_get(group, \"maxvolt_cellnum\")),\n",
    "            \"min_cellvolt_med\": safe_median(group[\"min_cellvolt\"]),\n",
    "            \"max_cellvolt_med\": safe_median(group[\"max_cellvolt\"]),\n",
    "            \"bat_voltage_med\": safe_median(group[\"bat_voltage\"]),\n",
    "        }\n",
    "\n",
    "        summary_list.append(record)\n",
    "\n",
    "    # --- Build final DataFrame ---\n",
    "    state_summary = pd.DataFrame(summary_list)\n",
    "    state_summary = state_summary[state_summary[\"duration_mins\"] > 0]\n",
    "\n",
    "    # --- Reorder columns for readability ---\n",
    "    ordered_cols = [\n",
    "        \"start_time\", \"end_time\", \"duration_mins\", \"mode\", \"b2t_tms_control_cmd\", \"tms_working_mode\",\n",
    "        \"vehicle_speed_start\", \"veh_status_start\", \"gun_status_start\",\"soc_start\",\"soc_end\",\n",
    "        \"batt_maxtemp_start\", \"batt_maxtemp_end\", \"batt_maxtemp_med\",\"batt_maxtemp_highest\",\n",
    "        \"batt_mintemp_start\", \"batt_mintemp_end\", \"batt_mintemp_med\",\"batt_mintemp_lowest\",\n",
    "        \"mintemp_cellnum_start\", \"mintemp_cellnum_end\", \"mintemp_cellnum_mode\",\n",
    "        \"maxtemp_cellnum_start\", \"maxtemp_cellnum_end\", \"maxtemp_cellnum_mode\",\n",
    "        \"comp_status_on_time\",\"comp_status_off_time\",\"comp_duty_cycle\",\n",
    "        \"coolant_out_start\", \"coolant_out_end\", \"coolant_out_med\",\n",
    "        \"coolant_in_start\", \"coolant_in_end\", \"coolant_in_med\", \n",
    "        \"min_cellvolt_start\", \"min_cellvolt_end\",\"min_cellvolt_med\",                \n",
    "        \"minvolt_cellnum_start\", \"minvolt_cellnum_end\", \"minvolt_cellnum_mode\",\n",
    "        \"max_cellvolt_start\", \"max_cellvolt_end\",\"max_cellvolt_med\",        \n",
    "        \"maxvolt_cellnum_start\", \"maxvolt_cellnum_end\", \"maxvolt_cellnum_mode\",\n",
    "        \"bat_voltage_start\", \"bat_voltage_end\", \"bat_voltage_med\"\n",
    "    ]\n",
    "\n",
    "    # --- Clean up integer-like columns ---\n",
    "    int_like_cols = [\n",
    "        \"vehilceready_start\", \"gun_connection_status_start\",\n",
    "        \"mintemp_cellnum_start\", \"mintemp_cellnum_end\", \"mintemp_cellnum_mode\",\n",
    "        \"maxtemp_cellnum_start\", \"maxtemp_cellnum_end\", \"maxtemp_cellnum_mode\",\n",
    "        \"minvolt_cellnum_start\", \"minvolt_cellnum_end\", \"minvolt_cellnum_mode\",\n",
    "        \"maxvolt_cellnum_start\", \"maxvolt_cellnum_end\", \"maxvolt_cellnum_mode\"\n",
    "    ]\n",
    "\n",
    "    for col in int_like_cols:\n",
    "        if col in state_summary.columns:\n",
    "            # Convert float values that are actually integers into proper integers\n",
    "            state_summary[col] = (\n",
    "                pd.to_numeric(state_summary[col], errors='coerce')\n",
    "                .astype(\"Int64\")  # Pandas nullable integer type (keeps NaN clean)\n",
    "            )\n",
    "\n",
    "\n",
    "    return df, state_summary.reindex(columns=ordered_cols)\n",
    "    # return state_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1c1ff0",
   "metadata": {},
   "source": [
    "- batt_mintemp, mintemp_cellnum\n",
    "- batt_maxtemp, maxtemp_cellnum\n",
    "- coolant_out\n",
    "- coolant_in\n",
    "- min_cellvolt, minvolt_cellnum\n",
    "- max_cellvolt, maxvolt_cellnum\n",
    "- bat_volt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88422fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Example usage ---\n",
    "# Correct usage\n",
    "df_with_state,state_summary = process_tms_transitions(df)\n",
    "state_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd61e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_session_summary(state_summary: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Visualize session-wise deltas (start ‚Üí end) from the state_summary dataframe.\n",
    "    Shows how temperature, coolant, and voltage shifted in each transition.\n",
    "    \"\"\"\n",
    "    if not {\"batt_maxtemp_start\", \"batt_maxtemp_end\"}.issubset(state_summary.columns):\n",
    "        raise KeyError(\"state_summary missing expected start/end columns. Verify output of process_tms_transitions().\")\n",
    "\n",
    "    summary = state_summary.copy()\n",
    "    summary[\"batt_maxtemp_delta\"] = summary[\"batt_maxtemp_end\"] - summary[\"batt_maxtemp_start\"]\n",
    "    summary[\"batt_mintemp_delta\"] = summary[\"batt_mintemp_end\"] - summary[\"batt_mintemp_start\"]\n",
    "    summary[\"coolant_out_delta\"] = summary[\"coolant_out_end\"] - summary[\"coolant_out_start\"]\n",
    "    summary[\"coolant_in_delta\"] = summary[\"coolant_in_end\"] - summary[\"coolant_in_start\"]\n",
    "    summary[\"bat_voltage_delta\"] = summary[\"bat_voltage_end\"] - summary[\"bat_voltage_start\"]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(summary.index, summary[\"batt_mintemp_delta\"], label=\"Batt Min Temp Œî\", marker=\"o\")\n",
    "    plt.plot(summary.index, summary[\"batt_maxtemp_delta\"], label=\"Batt Max Temp Œî\", marker=\"o\")\n",
    "    plt.plot(summary.index, summary[\"coolant_out_delta\"], label=\"Coolant Out Œî\", marker=\"o\")\n",
    "    plt.plot(summary.index, summary[\"coolant_in_delta\"], label=\"Coolant In Œî\", marker=\"o\")\n",
    "    plt.plot(summary.index, summary[\"bat_voltage_delta\"], label=\"Battery Voltage Œî\", marker=\"o\")\n",
    "\n",
    "    plt.title(\"Session-wise Parameter Change (End ‚àí Start)\")\n",
    "    plt.xlabel(\"Session Index\")\n",
    "    plt.ylabel(\"Œî Value (¬∞C or V)\")\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a994a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tms_session(df: pd.DataFrame, group_id: int):\n",
    "    \"\"\"\n",
    "    Plot TMS temperature and compressor frequency evolution for a given state_group.\n",
    "    Returns the figure object for PDF export.\n",
    "    \"\"\"\n",
    "\n",
    "    if \"state_group\" not in df.columns:\n",
    "        raise KeyError(\"Column 'state_group' not found.\")\n",
    "\n",
    "    session = df[df[\"state_group\"] == group_id].copy()\n",
    "    if session.empty:\n",
    "        print(f\"No data found for state_group {group_id}\")\n",
    "        return None\n",
    "\n",
    "    # -------- Timestamp Fix --------\n",
    "    session = session.sort_values(\"timestamp\")\n",
    "    try:\n",
    "        session[\"timestamp\"] = session[\"timestamp\"].dt.tz_localize(None)\n",
    "    except:\n",
    "        pass\n",
    "    session[\"timestamp\"] = session[\"timestamp\"].ffill().bfill()\n",
    "    required_cols = [\n",
    "        \"batt_mintemp\", \"batt_maxtemp\",\n",
    "        \"coolant_in\", \"coolant_out\",\n",
    "        \"comp_target_freq\", \"comp_running_freq\"\n",
    "    ]\n",
    "\n",
    "    # Skip if all values are null or missing\n",
    "    if session[required_cols].isna().all().all():\n",
    "        return None\n",
    "\n",
    "\n",
    "    # -------- Figure Setup --------\n",
    "    fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    # -------- Temperature Plots --------\n",
    "    ax1.plot(session[\"timestamp\"], session[\"batt_mintemp\"], label=\"Batt Min Temp\", linewidth=2)\n",
    "    ax1.plot(session[\"timestamp\"], session[\"batt_maxtemp\"], label=\"Batt Max Temp\", linewidth=2)\n",
    "    ax1.plot(session[\"timestamp\"], session[\"coolant_in\"], label=\"Coolant In\", linestyle=\"--\")\n",
    "    ax1.plot(session[\"timestamp\"], session[\"coolant_out\"], label=\"Coolant Out\", linestyle=\"--\")\n",
    "\n",
    "    ax1.set_xlabel(\"Timestamp\")\n",
    "    ax1.set_ylabel(\"Temperature (¬∞C)\")\n",
    "    ax1.grid(alpha=0.3)\n",
    "\n",
    "    # -------- Compressor Frequency Plots --------\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(session[\"timestamp\"], session[\"comp_target_freq\"],\n",
    "             linestyle=\"--\", color=\"tab:pink\", label=\"Comp Target Freq\", alpha=0.7)\n",
    "    ax2.plot(session[\"timestamp\"], session[\"comp_running_freq\"],\n",
    "             linestyle=\"-\", color=\"tab:gray\", label=\"Comp Running Freq\", alpha=0.7)\n",
    "\n",
    "    ax2.set_ylabel(\"Compressor Frequency (Hz)\")\n",
    "\n",
    "    # -------- Combined Legend (NO duplicate legends) --------\n",
    "    lines_1, labels_1 = ax1.get_legend_handles_labels()\n",
    "    lines_2, labels_2 = ax2.get_legend_handles_labels()\n",
    "\n",
    "    fig.legend(\n",
    "        lines_1 + lines_2,\n",
    "        labels_1 + labels_2,\n",
    "        loc=\"lower center\",\n",
    "        bbox_to_anchor=(0.5, -0.15),\n",
    "        ncol=3,\n",
    "        frameon=True\n",
    "    )\n",
    "\n",
    "    # -------- Title --------\n",
    "    mode = session[\"tms_working_mode\"].iloc[0]\n",
    "    cmd = session[\"b2t_tms_control_cmd\"].iloc[0]\n",
    "    fig.suptitle(f\"TMS Session {group_id} | Mode: {mode} | Cmd: {cmd}\", fontsize=14)\n",
    "\n",
    "    # -------- Layout --------\n",
    "    fig.tight_layout(rect=[0, 0.05, 1, 0.95])\n",
    "\n",
    "    # ‚úÖ DO NOT call plt.show() ‚Äî breaks PDF capturing\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9a856d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_with_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5b1ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot detailed single session (raw time-series)\n",
    "plot_tms_session(df_with_state,group_id=2)\n",
    "\n",
    "# Plot summary overview (start-end deltas)\n",
    "# plot_session_summary(state_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38002d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_all_tms_sessions(df, pdf_path=\"tms_sessions_report.pdf\"):\n",
    "    # unique_groups = sorted(df[\"state_group\"].dropna().unique())\n",
    "\n",
    "\n",
    "    # with PdfPages(pdf_path) as pdf:\n",
    "    #     for gid in unique_groups:\n",
    "    #         fig = plot_tms_session(df, gid)\n",
    "    #         if fig is not None:\n",
    "    #             pdf.savefig(fig, bbox_inches=\"tight\")\n",
    "    #             plt.close(fig)\n",
    "\n",
    "    # print(f\"‚úÖ All session plots saved to: {pdf_path}\")\n",
    "    if \"state_group\" not in df.columns:\n",
    "        raise KeyError(\"'state_group' not found in dataframe.\")\n",
    "\n",
    "    groups = sorted(df[\"state_group\"].dropna().unique())\n",
    "    skipped = []\n",
    "\n",
    "    with PdfPages(pdf_path) as pdf:\n",
    "        for gid in groups:\n",
    "            fig = plot_tms_session(df, gid)\n",
    "\n",
    "            if fig is None:\n",
    "                skipped.append(gid)\n",
    "                continue\n",
    "\n",
    "            pdf.savefig(fig, bbox_inches=\"tight\")\n",
    "            plt.close(fig)\n",
    "\n",
    "    print(f\"‚úÖ PDF generated: {pdf_path}\")\n",
    "    if skipped:\n",
    "        print(f\"‚ÑπÔ∏è Skipped sessions with no usable data: {skipped}\")\n",
    "\n",
    "\n",
    "save_all_tms_sessions(df_with_state, \"tms_sessions_report.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8353f4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786c41b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_with_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61249ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "wait"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366248b9",
   "metadata": {},
   "source": [
    "1. Compressor Duty Cycle Analysis: based on 300seconds buckets for each state_group\n",
    "2. What is the trigger for self circulation\n",
    "3. When does the "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "naarni_env (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
