{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3cbbccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import struct\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b85e17c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files... (this may take a moment)\n",
      "Found 576 cell voltage columns to map.\n",
      "--------------------------------------------------------------------------------\n",
      "Cell Name                 | Source CAN ID   | Bytes | Endian | Mux ID (Byte 0)\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Mapping complete. Identified 0/576 cells.\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# CONFIGURATION\n",
    "# ---------------------------------------------------------\n",
    "raw_file = 'c2c_can_20Nov_2310_5.csv'      # Your RAW CSV\n",
    "parsed_file = 'cpo_can_20Nov_2310_10m.csv' # Your PARSED CSV\n",
    "\n",
    "# How close must the timestamps be to consider them a match? (in milliseconds)\n",
    "TIME_TOLERANCE_MS = 20 \n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. LOAD AND PREPARE DATA\n",
    "# ---------------------------------------------------------\n",
    "print(\"Loading files... (this may take a moment)\")\n",
    "df_raw = pd.read_csv(raw_file)\n",
    "df_parsed = pd.read_csv(parsed_file)\n",
    "\n",
    "# Ensure timestamps are sorted for merging\n",
    "df_raw = df_raw.sort_values('timestamp')\n",
    "df_parsed = df_parsed.sort_values('timestamp')\n",
    "\n",
    "# Fix the mixed-up byte columns in raw file\n",
    "byte_cols = ['byte1', 'byte2', 'byte3', 'byte4', 'byte5', 'byte6', 'byte7', 'byte8']\n",
    "# Create a list of correctly ordered columns if they exist in the dataframe\n",
    "available_byte_cols = [col for col in byte_cols if col in df_raw.columns]\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. IDENTIFY TARGET COLUMNS\n",
    "# ---------------------------------------------------------\n",
    "# Find all columns starting with \"Pack_cellVoltage_\"\n",
    "cell_columns = [c for c in df_parsed.columns if c.startswith('Pack_cellVoltage_')]\n",
    "# Sort them so we process 1, 2, 3... numerically\n",
    "cell_columns.sort(key=lambda x: int(x.split('_')[-1]) if x.split('_')[-1].isdigit() else 9999)\n",
    "\n",
    "print(f\"Found {len(cell_columns)} cell voltage columns to map.\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. MAPPING ENGINE\n",
    "# ---------------------------------------------------------\n",
    "# We will store results here: CellName -> {ID, ByteOffset, Endianness}\n",
    "cell_map = {}\n",
    "\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'Cell Name':<25} | {'Source CAN ID':<15} | {'Bytes'} | {'Endian'} | {'Mux ID (Byte 0)'}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# We don't need to check every single row. We just need ONE good match to establish the pattern.\n",
    "# We pick a sample of valid rows from the parsed file.\n",
    "sample_indices = df_parsed.dropna(subset=cell_columns).index[::50] # Check every 50th row to speed up\n",
    "\n",
    "for cell_name in cell_columns:\n",
    "    # If we already mapped this cell, skip (optional, but good for verification to keep running)\n",
    "    if cell_name in cell_map: continue\n",
    "\n",
    "    match_found = False\n",
    "    \n",
    "    # Iterate through a few sample points to find a match\n",
    "    for idx in sample_indices[:20]: # Try max 20 different timestamps\n",
    "        if idx not in df_parsed.index: continue\n",
    "        \n",
    "        # Get the target voltage (e.g., 3.31)\n",
    "        val_float = df_parsed.loc[idx, cell_name]\n",
    "        if pd.isna(val_float) or val_float == 0: continue\n",
    "        \n",
    "        # Convert to raw mV (e.g., 3310)\n",
    "        val_mv = int(round(val_float * 1000))\n",
    "        \n",
    "        # Create search patterns\n",
    "        # Little Endian (Standard Intel)\n",
    "        le_bytes = list(struct.pack('<H', val_mv)) \n",
    "        # Big Endian (Motorola)\n",
    "        be_bytes = list(struct.pack('>H', val_mv))\n",
    "        \n",
    "        # Find the timestamp\n",
    "        ts_target = df_parsed.loc[idx, 'timestamp']\n",
    "        \n",
    "        # Get raw rows within tolerance window\n",
    "        # We filter the raw dataframe for a tiny window around the timestamp\n",
    "        window = df_raw[\n",
    "            (df_raw['timestamp'] >= ts_target - TIME_TOLERANCE_MS) & \n",
    "            (df_raw['timestamp'] <= ts_target + TIME_TOLERANCE_MS)\n",
    "        ]\n",
    "        \n",
    "        if window.empty: continue\n",
    "\n",
    "        # Scan the raw frames in this window\n",
    "        for _, raw_row in window.iterrows():\n",
    "            # Reconstruct byte array\n",
    "            data = [raw_row[col] for col in available_byte_cols]\n",
    "            \n",
    "            # Search for the voltage bytes\n",
    "            for i in range(len(data) - 1):\n",
    "                # Check Little Endian\n",
    "                if data[i] == le_bytes[0] and data[i+1] == le_bytes[1]:\n",
    "                    can_id = raw_row['can_id']\n",
    "                    mux = data[0] # Grab first byte in case it's a Multiplex Index\n",
    "                    \n",
    "                    print(f\"{cell_name:<25} | {can_id:<15} | {i}-{i+1}   | LE       | {mux}\")\n",
    "                    cell_map[cell_name] = {'id': can_id, 'bytes': (i, i+1), 'endian': 'LE'}\n",
    "                    match_found = True\n",
    "                    break\n",
    "                \n",
    "                # Check Big Endian\n",
    "                if data[i] == be_bytes[0] and data[i+1] == be_bytes[1]:\n",
    "                    can_id = raw_row['can_id']\n",
    "                    mux = data[0]\n",
    "                    \n",
    "                    print(f\"{cell_name:<25} | {can_id:<15} | {i}-{i+1}   | BE       | {mux}\")\n",
    "                    cell_map[cell_name] = {'id': can_id, 'bytes': (i, i+1), 'endian': 'BE'}\n",
    "                    match_found = True\n",
    "                    break\n",
    "            \n",
    "            if match_found: break\n",
    "        if match_found: break\n",
    "\n",
    "print(\"-\" * 80)\n",
    "print(f\"Mapping complete. Identified {len(cell_map)}/{len(cell_columns)} cells.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "naarni_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
