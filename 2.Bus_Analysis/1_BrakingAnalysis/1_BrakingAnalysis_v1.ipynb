{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc5698b7-348d-4bee-9288-ed2829bd18a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from fpdf import FPDF\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da46293-f93d-44cc-8abf-beed776fb534",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "- Device_ID\n",
    "- \n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68aad3e6-8375-49cd-a165-c9d0248183d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_filtered_braking_events(file_paths):\n",
    "    \"\"\"\n",
    "    Analyzes and plots braking events from multiple files, filtering\n",
    "    based on a user-defined top speed reached during the event.\n",
    "    The logic is fine-tuned to extract the exact start point of braking\n",
    "    (BrakePedalPos > 0.0) within a 20-second window before a hard stop.\n",
    "    \"\"\"\n",
    "    top_speed = 30.0  # Default top speed filter (km/h)\n",
    "    search_window_seconds = 10.0  # Time window to look for brake press before\n",
    "\n",
    "    # # 1. Get user input for filtering and plotting\n",
    "    # while True:\n",
    "    #     try:\n",
    "    #         top_speed = float(input(\"Enter the top speed (km/h) to filter events by: \"))\n",
    "    #         # We still need a search window, but the analysis will be dynamic.\n",
    "    #         search_window_seconds = 20.0\n",
    "    #         break\n",
    "    #     except ValueError:\n",
    "    #         print(\"Error: Invalid input. Please enter a numerical value for top speed.\")\n",
    "\n",
    "    all_event_data = []\n",
    "    # This list will store the dynamically calculated duration for each event.\n",
    "    event_durations = []\n",
    "\n",
    "    # 2. Iterate through each file provided in the list\n",
    "    for file_path in file_paths:\n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "            print(f\"Processing file: {file_path}\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: The file '{file_path}' was not found. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Convert timestamp to human-readable IST and clean the data\n",
    "        df['IST'] = pd.to_datetime(df['timestamp'], unit='ms').dt.tz_localize('UTC').dt.tz_convert('Asia/Kolkata')\n",
    "        df = df[[\"IST\", \"BrakePedalPos\", \"Vehicle_speed_VCU\"]].copy()\n",
    "        df.dropna(subset=[\"Vehicle_speed_VCU\", \"BrakePedalPos\"], inplace=True)\n",
    "        df.sort_values(by='IST', inplace=True)\n",
    "        df.loc[:, 'IST_formatted_string'] = df['IST'].dt.strftime('%H:%M:%S')\n",
    "\n",
    "        # Identify hard stop events (speed becomes 0 from a non-zero value)\n",
    "        hard_stop_mask = (df['Vehicle_speed_VCU'] == 0.0) & (df['Vehicle_speed_VCU'].shift(1) > 0.0)\n",
    "        hard_stop_events = df[hard_stop_mask].copy()\n",
    "\n",
    "        if hard_stop_events.empty:\n",
    "            print(f\"No hard stop events found in '{file_path}'.\")\n",
    "            continue\n",
    "        \n",
    "        # 3. Extract and aggregate the data for each filtered event\n",
    "        for _, event_row in hard_stop_events.iterrows():\n",
    "            end_time = event_row['IST']\n",
    "            # Define a search window of 20 seconds before the stop\n",
    "            search_start_time = end_time - pd.Timedelta(seconds=search_window_seconds)\n",
    "\n",
    "            # Look for the first instance of brake pedal application within this window\n",
    "            search_segment = df[(df['IST'] >= search_start_time) & (df['IST'] <= end_time)].copy()\n",
    "\n",
    "            # Find the first row where BrakePedalPos is greater than 0\n",
    "            first_brake_press = search_segment[search_segment['BrakePedalPos'] > 0.0].head(1)\n",
    "\n",
    "            # Check if a brake press was found in the search window\n",
    "            if not first_brake_press.empty:\n",
    "                # Get the exact start time of the braking event\n",
    "                start_time = first_brake_press.iloc[0]['IST']\n",
    "\n",
    "                # Filter the event segment from the exact start of braking to the stop\n",
    "                event_segment = df[(df['IST'] >= start_time) & (df['IST'] <= end_time)].copy()\n",
    "\n",
    "                # Check if the top speed in this dynamic segment meets the filter criteria\n",
    "                if not event_segment.empty and event_segment['Vehicle_speed_VCU'].max() >= top_speed:\n",
    "                    # Calculate the dynamic time taken to come to a full stop\n",
    "                    time_to_stop_seconds = (end_time - start_time).total_seconds()\n",
    "                    \n",
    "                    # Append the filtered event data and its duration\n",
    "                    all_event_data.append(event_segment)\n",
    "                    event_durations.append(time_to_stop_seconds)\n",
    "\n",
    "    if not all_event_data:\n",
    "        print(f\"No events found across all files that reached a top speed of {top_speed} km/h or greater and had a brake press within {search_window_seconds} seconds of the stop.\")\n",
    "        return\n",
    "\n",
    "    # 4. Generate combined reports\n",
    "    # Determine output filenames based on the first file processed\n",
    "    if file_paths:\n",
    "        try:\n",
    "            l1 = file_paths[0].split('/')[0]\n",
    "            l2 = file_paths[0].split('/')[1].split('_')[0]\n",
    "            base_name = os.path.join(l1, 'brakingAnalysis', l2)\n",
    "        except IndexError:\n",
    "            # Fallback for unexpected file path format\n",
    "            base_name = \"combined_report\"\n",
    "    else:\n",
    "        base_name = \"combined_report\"\n",
    "    \n",
    "    output_csv_filename = f\"{base_name}_combined_report.csv\"\n",
    "    output_pdf_filename = f\"{base_name}_combined_report.pdf\"\n",
    "    \n",
    "    # Create the directory if it doesn't exist\n",
    "    try:\n",
    "        os.makedirs(os.path.dirname(output_csv_filename), exist_ok=True)\n",
    "    except OSError as e:\n",
    "        print(f\"Error creating directory: {e}\")\n",
    "        # If directory creation fails, fall back to a local filename\n",
    "        output_csv_filename = os.path.basename(output_csv_filename)\n",
    "        output_pdf_filename = os.path.basename(output_pdf_filename)\n",
    "\n",
    "    return generate_report_csv(all_event_data, output_csv_filename)\n",
    "    # print(df.info())\n",
    "    # # Pass the list of dynamic event durations to the PDF report function\n",
    "    generate_report_pdf(all_event_data, event_durations, output_pdf_filename)    \n",
    "    # generate_final_report(output_csv_filename)\n",
    "    # plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee333204-793b-4268-af2d-36ef4ac5764d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_report_csv(events, output_filename):\n",
    "    \"\"\"\n",
    "    Generates a CSV report with a summary of braking events.\n",
    "    \"\"\"\n",
    "    # Define constants for the kgf calculation\n",
    "    BUS_MASS_KG = 13500  # 13.5 tonnes * 1000 kg/tonne\n",
    "    G_ACCELERATION = 9.80665 # Standard acceleration due to gravity\n",
    "\n",
    "    table_data = []\n",
    "    \n",
    "    for i, event_group in enumerate(events):\n",
    "        start_time = event_group['IST'].iloc[0]\n",
    "        end_time = event_group['IST'].iloc[-1]\n",
    "        start_velocity = event_group['Vehicle_speed_VCU'].iloc[0]\n",
    "        peak_velocity = event_group['Vehicle_speed_VCU'].max()\n",
    "        max_brake_pedal_pos = event_group['BrakePedalPos'].max()\n",
    "        min_brake_pedal_pos = event_group['BrakePedalPos'].min()\n",
    "        avg_brake_pedal_pos = event_group['BrakePedalPos'].mean()\n",
    "        \n",
    "        event_group.loc[:, 'speed_mps'] = event_group['Vehicle_speed_VCU'] * (1000 / 3600)\n",
    "        time_diffs_sec = event_group['IST'].diff().dt.total_seconds().fillna(0)\n",
    "        distance_covered_m = (event_group['speed_mps'] * time_diffs_sec).sum()\n",
    "        total_time_s = (end_time - start_time).total_seconds()\n",
    "        \n",
    "        if total_time_s > 0:\n",
    "            # Calculate average deceleration in m/s^2\n",
    "            avg_deceleration = (peak_velocity * 1000/3600) / total_time_s\n",
    "        else:\n",
    "            avg_deceleration = 0\n",
    "            \n",
    "        # Calculate braking force in kgf\n",
    "        braking_force_kgf = (BUS_MASS_KG * avg_deceleration) / G_ACCELERATION\n",
    "        \n",
    "        table_data.append({\n",
    "            'idx': i + 1,\n",
    "            'start': start_time.strftime('%d/%m/%y %H:%M:%S'),\n",
    "            'end': end_time.strftime('%d/%m/%y %H:%M:%S'),\n",
    "            'max_bpp': f\"{max_brake_pedal_pos:.2f}\",\n",
    "            # 'min_bpp': f\"{min_brake_pedal_pos:.2f}\",\n",
    "            'avg_bpp': f\"{avg_brake_pedal_pos:.2f}\",\n",
    "            'ttl_dist_m': f\"{distance_covered_m:.2f}\",\n",
    "            'start_vel': f\"{start_velocity:.2f}\",\n",
    "            'peak_vel': f\"{peak_velocity:.2f}\",\n",
    "            'avg_decel_mps2': f\"{avg_deceleration:.2f}\",\n",
    "            'braking_force_kgf': f\"{braking_force_kgf:.2f}\" # New column\n",
    "        })\n",
    "\n",
    "    results_df = pd.DataFrame(table_data)\n",
    "    try:\n",
    "        print(output_filename)\n",
    "        results_df.to_csv(output_filename, index=False)        \n",
    "    except (FileNotFoundError,OSError):\n",
    "        # This block is executed if the directory does not exist.\n",
    "        print(f\"Directory for '{output_filename}' not found. Creating it now...\")\n",
    "    \n",
    "        # Extract the directory path from the full filename\n",
    "        directory = os.path.dirname(output_filename)\n",
    "\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "        # Now that the directory exists, try saving the file again.\n",
    "        results_df.to_csv(output_filename, index=False)\n",
    "        print(f\"Directory created and file saved successfully to '{output_filename}'.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        # A generic exception handler for any other potential errors\n",
    "        print(f\"An unexpected error occurred: {e}\")        \n",
    "        \n",
    "    print(f\"\\nCombined CSV report saved as '{output_filename}'.\")\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76169f6c-6745-4e27-a68a-80bc97658e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_report_pdf(events, durations, output_filename):\n",
    "    \"\"\"\n",
    "    Generates a multi-page PDF report with a summary page and individual plots.\n",
    "    This version uses the dynamic braking duration for each plot's title.\n",
    "    \"\"\"\n",
    "    # Define constants for the kgf calculation\n",
    "    BUS_MASS_KG = 13500  # 13.5 tonnes * 1000 kg/tonne\n",
    "    G_ACCELERATION = 9.80665 # Standard acceleration due to gravity\n",
    "\n",
    "    with PdfPages(output_filename) as pdf:\n",
    "        all_peak_speeds = []\n",
    "        all_distances = []\n",
    "        all_max_bpps = [] # List to store maximum bpp for each event\n",
    "        all_avg_bpps = [] # List to store average bpp for each event\n",
    "        \n",
    "        for i, event_group in enumerate(events):\n",
    "            start_time = event_group['IST'].iloc[0]\n",
    "            end_time = event_group['IST'].iloc[-1]\n",
    "            peak_velocity = event_group['Vehicle_speed_VCU'].max()\n",
    "            \n",
    "            event_group.loc[:, 'speed_mps'] = event_group['Vehicle_speed_VCU'] * (1000 / 3600)\n",
    "            time_diffs_sec = event_group['IST'].diff().dt.total_seconds().fillna(0)\n",
    "            distance_covered_m = (event_group['speed_mps'] * time_diffs_sec).sum()\n",
    "            \n",
    "            # Calculate and store BPP values for the summary\n",
    "            max_bpp = event_group['BrakePedalPos'].max()\n",
    "            avg_bpp = event_group['BrakePedalPos'].mean()\n",
    "            \n",
    "            all_peak_speeds.append(peak_velocity)\n",
    "            all_distances.append(distance_covered_m)\n",
    "            all_max_bpps.append(max_bpp)\n",
    "            all_avg_bpps.append(avg_bpp)\n",
    "\n",
    "        # Create and save the summary page\n",
    "        fig_summary = plt.figure(figsize=(11, 8.5))\n",
    "        ax_summary = fig_summary.add_subplot(111)\n",
    "        ax_summary.axis('off')\n",
    "        \n",
    "        # Create a table for the summary data\n",
    "        summary_data = [\n",
    "            ['Total events found:', f\"{len(events)}\"],\n",
    "            ['Max speed across all events:', f\"{max(all_peak_speeds):.2f} km/h\"],\n",
    "            ['Average speed across all events:', f\"{sum(all_peak_speeds)/len(all_peak_speeds):.2f} km/h\"],\n",
    "            \n",
    "            ['Maximum distance covered:', f\"{max(all_distances):.1f} m\"],\n",
    "            ['Minimum distance covered:', f\"{max(all_distances):.1f} m\"],\n",
    "            ['Average distance covered:', f\"{sum(all_distances)/len(all_distances):.1f} m\"],\n",
    "            \n",
    "            ['Maximum duration:', f\"{max(durations):.1f} s\"],\n",
    "            ['Minimum duration:', f\"{min(durations):.1f} s\"],\n",
    "            ['Average duration:', f\"{sum(durations)/len(durations):.1f} s\"],\n",
    "            \n",
    "            ['Maximum BPP:', f\"{max(all_max_bpps):.1f}\"],\n",
    "            ['Average BPP:', f\"{sum(all_avg_bpps)/len(all_avg_bpps):.1f}\"]\n",
    "        ]\n",
    "        \n",
    "        # Define a title for the table\n",
    "        plt.suptitle(\"Braking Analysis Report\", fontsize=18, y=0.95)\n",
    "        \n",
    "        # Create the table\n",
    "        summary_table = ax_summary.table(\n",
    "            cellText=summary_data,\n",
    "            loc='center',\n",
    "            cellLoc='left',\n",
    "            colWidths=[0.5, 0.5]\n",
    "        )\n",
    "        \n",
    "        summary_table.auto_set_font_size(False)\n",
    "        summary_table.set_fontsize(10)\n",
    "        summary_table.scale(1.2, 1.5)\n",
    "        \n",
    "        pdf.savefig(fig_summary)\n",
    "        plt.close(fig_summary)\n",
    "        \n",
    "        # --- Paginate the detailed event table ---\n",
    "        \n",
    "        table_data = []\n",
    "        for i, event_group in enumerate(events):\n",
    "            start_time = event_group['IST'].iloc[0]\n",
    "            end_time = event_group['IST'].iloc[-1]\n",
    "            max_bpp = event_group['BrakePedalPos'].max()\n",
    "            avg_bpp = event_group['BrakePedalPos'].mean()\n",
    "            dist_m = (event_group['Vehicle_speed_VCU'] * (1000/3600) * event_group['IST'].diff().dt.total_seconds().fillna(0)).sum()\n",
    "            start_vel = event_group['Vehicle_speed_VCU'].iloc[0]\n",
    "            peak_vel = event_group['Vehicle_speed_VCU'].max()\n",
    "            total_time_s = (end_time - start_time).total_seconds()\n",
    "            avg_decel = (peak_vel * 1000/3600) / total_time_s if total_time_s > 0 else 0\n",
    "            \n",
    "            braking_force_kgf = (BUS_MASS_KG * avg_decel) / G_ACCELERATION\n",
    "\n",
    "            table_data.append([\n",
    "                i + 1,\n",
    "                start_time.strftime('%d/%m/%y %H:%M:%S'),\n",
    "                end_time.strftime('%d/%m/%y %H:%M:%S'),\n",
    "                f\"{durations[i]:.2f}\",\n",
    "                f\"{max_bpp:.2f}\",\n",
    "                f\"{avg_bpp:.2f}\",\n",
    "                f\"{dist_m:.2f}\",\n",
    "                f\"{start_vel:.2f}\",\n",
    "                f\"{avg_decel:.2f}\",\n",
    "                f\"{braking_force_kgf:.2f}\"\n",
    "            ])\n",
    "\n",
    "        # Define the number of rows per page\n",
    "        ROWS_PER_PAGE = 23\n",
    "        \n",
    "        # Split the data into chunks for pagination\n",
    "        chunks = [table_data[i:i + ROWS_PER_PAGE] for i in range(0, len(table_data), ROWS_PER_PAGE)]\n",
    "        \n",
    "        # Define columns for the table\n",
    "        columns = [\n",
    "            'idx', 'start', 'end', 'duration_s', 'max_bpp', 'avg_bpp', \n",
    "            'ttl_dist_m', 'start_vel', 'avg_decel_mps2', 'braking_force_kgf'\n",
    "        ]\n",
    "\n",
    "        # Loop through each chunk of data and create a new page\n",
    "        for page_num, chunk in enumerate(chunks):\n",
    "            fig_table = plt.figure(figsize=(11, 8.5))\n",
    "            ax_table = fig_table.add_subplot(111)\n",
    "            ax_table.axis('off')\n",
    "            \n",
    "            # Set relative column widths\n",
    "            col_widths = [0.05, 0.15, 0.15, 0.08, 0.08, 0.08, 0.08, 0.08, 0.1, 0.15]\n",
    "            \n",
    "            table = ax_table.table(cellText=chunk, colLabels=columns, loc='center', cellLoc='center', colWidths=col_widths)\n",
    "            table.auto_set_font_size(False)\n",
    "            table.set_fontsize(8)\n",
    "            table.scale(1, 1.5)\n",
    "            \n",
    "            plt.title(f\"DETAILED BRAKING EVENT TABLE (Page {page_num + 1})\", y=0.95)\n",
    "            plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "            pdf.savefig(fig_table)\n",
    "            plt.close(fig_table)\n",
    "            \n",
    "        # Now, plot and save each individual graph on its own page\n",
    "        for i, event_group in enumerate(events):\n",
    "            fig, ax = plt.subplots(figsize=(15, 6))\n",
    "            \n",
    "            event_group.loc[:, 'IST_formatted_string'] = event_group['IST'].dt.strftime('%H:%M:%S')\n",
    "\n",
    "            distance_covered_m = (event_group['Vehicle_speed_VCU'] * (1000 / 3600) * event_group['IST'].diff().dt.total_seconds().fillna(0)).sum()\n",
    "            total_distance_ft = distance_covered_m * 3.28084\n",
    "            distance_label = (\n",
    "                f'Distance Covered:\\n'\n",
    "                f'{distance_covered_m:.2f} m\\n'\n",
    "                f'{total_distance_ft:.2f} ft'\n",
    "            )\n",
    "\n",
    "            ax.text(\n",
    "                0.95, 0.95,\n",
    "                distance_label,\n",
    "                transform=ax.transAxes,\n",
    "                ha='right',\n",
    "                va='top',\n",
    "                fontsize=12,\n",
    "                bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", ec=\"black\", lw=1)\n",
    "            )\n",
    "\n",
    "            ax.plot(\n",
    "                event_group['IST_formatted_string'],\n",
    "                event_group['Vehicle_speed_VCU'],\n",
    "                label='Vehicle Speed (km/h)',\n",
    "                color='blue'\n",
    "            )\n",
    "            ax.plot(\n",
    "                event_group['IST_formatted_string'],\n",
    "                event_group['BrakePedalPos'],\n",
    "                label='Brake Pedal Position',\n",
    "                color='red'\n",
    "            )\n",
    "            \n",
    "            start_time_str = event_group['IST'].iloc[0].strftime('%d/%m/%y %H:%M:%S')\n",
    "            end_time_str = event_group['IST'].iloc[-1].strftime('%d/%m/%y %H:%M:%S')\n",
    "            ax.set_title(f\"Event: {start_time_str} to {end_time_str}\")\n",
    "            ax.set_xlabel('Time (hh:mm:ss)')\n",
    "            ax.set_ylabel('Value')\n",
    "            ax.grid(True)\n",
    "            ax.legend()\n",
    "            \n",
    "            ax.tick_params(axis='x', rotation=45)\n",
    "            \n",
    "            # Use the duration from the list to create the dynamic title\n",
    "            plt.suptitle(f\"Analysis of Braking Events ({durations[i]:.2f}s to stop)\", fontsize=18)\n",
    "            plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "            \n",
    "            pdf.savefig(fig)\n",
    "            plt.close(fig)\n",
    "            \n",
    "        print(f\"\\nCombined PDF report saved as '{output_filename}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d5733e3-43b8-4c40-a420-8a017af56ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_final_report(file_name):\n",
    "    \"\"\"\n",
    "    Analyzes and compares braking performance data from a CSV file\n",
    "    for two distinct time periods. It generates a summary report and a\n",
    "    visual comparison chart, then combines them into a single PDF document.\n",
    "    \"\"\"\n",
    "    # Check if the file exists in the current directory\n",
    "    if not os.path.exists(file_name):\n",
    "        print(f\"Error: The file '{file_name}' was not found in the current directory.\")\n",
    "        print(\"Please ensure the CSV file is saved in the same folder as this script.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # Read the CSV file directly from the local file path\n",
    "        print(f\"Reading data from '{file_name}'...\")\n",
    "        df = pd.read_csv(file_name)\n",
    "        print(\"File read successfully.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while reading the file: {e}\")\n",
    "        return\n",
    "\n",
    "    # --- Data Cleaning and Preprocessing ---\n",
    "    # Clean column names to handle any leading/trailing spaces or newlines\n",
    "    df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')\n",
    "    \n",
    "    # Now, check the cleaned column names to ensure they exist before proceeding\n",
    "    required_cols = ['avg_decel_mps2', 'avg_bpp', 'ttl_dist_m', 'start_vel', 'peak_vel', 'start', 'max_bpp']\n",
    "    \n",
    "    # Check if all required columns are present after cleaning\n",
    "    if not all(col in df.columns for col in required_cols):\n",
    "        missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "        print(\"Error: The CSV file is missing one or more required columns after cleaning.\")\n",
    "        print(f\"Missing columns: {missing_cols}\")\n",
    "        print(\"\\nAvailable columns are:\")\n",
    "        print(df.columns)\n",
    "        return\n",
    "\n",
    "    # Convert the 'start' column to datetime objects\n",
    "    try:\n",
    "        df['start_datetime'] = pd.to_datetime(df['start'], format='%d/%m/%y %H:%M:%S')\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting dates: {e}. Please check the date format in your CSV file.\")\n",
    "        return\n",
    "\n",
    "    # Convert the key metrics columns to float\n",
    "    numeric_cols = ['avg_decel_mps2', 'avg_bpp', 'ttl_dist_m', 'start_vel', 'peak_vel', 'max_bpp']\n",
    "    for col in numeric_cols:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "    # Drop any rows with NaN values in critical columns\n",
    "    df.dropna(subset=numeric_cols, inplace=True)\n",
    "\n",
    "    # Define the cutoff date to split the data\n",
    "    cutoff_date = pd.to_datetime('17/08/25', format='%d/%m/%y')\n",
    "\n",
    "    # Partition the data into 'before' and 'after' the cutoff date\n",
    "    df_then = df[df['start_datetime'] < cutoff_date]\n",
    "    df_now = df[df['start_datetime'] >= cutoff_date]\n",
    "\n",
    "    # Define the key metrics for analysis\n",
    "    metrics_avg = {\n",
    "        'avg_decel_mps2': 'Avg Deceleration ($m/s^2$)',\n",
    "        'avg_bpp': 'Avg Brake Pedal Position (%)',\n",
    "        'ttl_dist_m': 'Avg Distance (m)',\n",
    "        'start_vel': 'Avg Start Velocity (km/h)', # Renamed to reflect the start of the event\n",
    "        'peak_vel': 'Avg Peak Velocity (km/h)'\n",
    "    }\n",
    "    \n",
    "    # Calculate summary statistics for both periods\n",
    "    summary_then_avg = df_then[metrics_avg.keys()].mean()\n",
    "    summary_now_avg = df_now[metrics_avg.keys()].mean()\n",
    "\n",
    "    # Create a DataFrame for the average metrics comparison\n",
    "    comparison_df_avg = pd.DataFrame({\n",
    "        'Then (Aug 1 - Aug 16)': summary_then_avg,\n",
    "        'Now (Aug 17 - Aug 25)': summary_now_avg\n",
    "    })\n",
    "    \n",
    "    # Rename the index to the more descriptive names\n",
    "    comparison_df_avg = comparison_df_avg.rename(index=metrics_avg)\n",
    "\n",
    "    # Calculate min distance and max brake pedal position\n",
    "    min_dist_then = df_then['ttl_dist_m'].min()\n",
    "    min_dist_now = df_now['ttl_dist_m'].min()\n",
    "    \n",
    "    max_bpp_then = df_then['max_bpp'].max()\n",
    "    max_bpp_now = df_now['max_bpp'].max()\n",
    "    \n",
    "    # Create a new DataFrame for these specific metrics and concatenate\n",
    "    specific_metrics_df = pd.DataFrame({\n",
    "        'Then (Aug 1 - Aug 16)': [min_dist_then, max_bpp_then],\n",
    "        'Now (Aug 17 - Aug 25)': [min_dist_now, max_bpp_now]\n",
    "    }, index=['Min Distance (m)', 'Max Brake Pedal Position (%)'])\n",
    "\n",
    "    # Combine the average and specific metrics DataFrames and round the results\n",
    "    comparison_df = pd.concat([comparison_df_avg, specific_metrics_df])\n",
    "\n",
    "    # Re-order the rows as requested\n",
    "    new_order = [\n",
    "        'Avg Peak Velocity (km/h)',\n",
    "        'Avg Distance (m)',\n",
    "        # 'Min Distance (m)',\n",
    "        'Avg Brake Pedal Position (%)',\n",
    "        'Max Brake Pedal Position (%)',\n",
    "        'Avg Deceleration ($m/s^2$)'\n",
    "    ]\n",
    "    comparison_df = comparison_df.reindex(new_order).round(2)\n",
    "    \n",
    "    # Add a row for total events\n",
    "    comparison_df.loc['Total Events'] = [len(df_then), len(df_now)]\n",
    "    \n",
    "    # --- Generate the comparison chart (PNG) ---\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    # Exclude 'Total Events' from the chart\n",
    "    plot_df = comparison_df.drop('Total Events')\n",
    "\n",
    "    plot_df.T.plot(kind='bar', ax=ax, width=0.8, rot=0)\n",
    "\n",
    "    # Add labels and title\n",
    "    ax.set_title('Braking Performance: Before vs. After August 17, 2025', fontsize=16, fontweight='bold')\n",
    "    ax.set_ylabel('Value', fontsize=12)\n",
    "    ax.set_xlabel('Metric', fontsize=12)\n",
    "    ax.legend(title='Period', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Customize x-axis labels\n",
    "    plt.xticks(ha='center')\n",
    "\n",
    "    # Add value labels on top of the bars\n",
    "    for container in ax.containers:\n",
    "        ax.bar_label(container, fmt='%.2f', label_type='edge', fontsize=10)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
    "\n",
    "    chart_filename = file_name.split('_')[0] + \"_braking_comparison_chart.png\"\n",
    "    plt.savefig(chart_filename)\n",
    "    plt.close(fig)\n",
    "    print(f\"\\nChart successfully saved as '{chart_filename}'.\")\n",
    "\n",
    "    # --- Generate the PDF Report ---\n",
    "    pdf = FPDF('P', 'mm', 'A4')\n",
    "    pdf.add_page()\n",
    "\n",
    "    # Add a title\n",
    "    pdf.set_font(\"Arial\", 'B', 16)\n",
    "    pdf.cell(200, 10, \"Braking Performance Comparison Report\", 0, 1, 'C')\n",
    "\n",
    "    # Add the summary table\n",
    "    pdf.set_font(\"Arial\", '', 12)\n",
    "    pdf.multi_cell(0, 10, \"Summary of Braking Metrics:\", 0, 1)\n",
    "\n",
    "    # Convert the DataFrame to a string with a fixed width for the table\n",
    "    table_str = comparison_df.to_string()\n",
    "    pdf.set_font(\"Courier\", '', 10) # Using a monospace font for table formatting\n",
    "    pdf.multi_cell(0, 5, table_str, 0, 1)\n",
    "    \n",
    "    # Add a title for the chart\n",
    "    pdf.set_font(\"Arial\", 'B', 14)\n",
    "    pdf.cell(200, 10, \"Visual Comparison\", 0, 1, 'C')\n",
    "    \n",
    "    # Add the generated chart image\n",
    "    # Note: Adjust the x, y, width, and height as needed to fit the page.\n",
    "    pdf.image(chart_filename, x=15, y=pdf.get_y() + 5, w=180)\n",
    "\n",
    "    pdf_filename = file_name.split('_')[0] + \"_Braking_Analysis_Report.pdf\"    \n",
    "    pdf.output(pdf_filename)\n",
    "    \n",
    "    print(f\"\\nPDF report successfully generated as '{pdf_filename}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ef587c1-f5f4-4fca-81dd-bb41e8c2fdd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: AP39WF8584/8584_01250825.csv\n",
      "AP39WF8584/brakingAnalysis/8584_combined_report.csv\n",
      "\n",
      "Combined CSV report saved as 'AP39WF8584/brakingAnalysis/8584_combined_report.csv'.\n"
     ]
    }
   ],
   "source": [
    "file_list = [\n",
    "\"AP39WF8584/8584_01250825.csv\",    \n",
    "# \"AP39WF8589/8589_01250825.csv\",\n",
    "# \"AP39WF8593/8593_01250825.csv\",   \n",
    "# \"AP39WG0252/0252_01250825.csv\",\n",
    "# \"AP39WG0271/0271_01250825.csv\",\n",
    "# \"AP39WG4628/4268_01250825.csv\",    \n",
    "# \"AP39WG4630/4630_01250825.csv\"\n",
    "]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage with multiple files\n",
    "    # Replace these with the actual file paths on your system\n",
    "    # file_list\n",
    "    df = analyze_filtered_braking_events(file_list)\n",
    "    df.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af1c286d",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2786258598.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mDB version of the above code is available below\u001b[39m\n       ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "DB version of the above code is available below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7003e72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = [\n",
    "\"AP39WF8584/8584_01250825.csv\",    \n",
    "# \"AP39WF8589/8589_01250825.csv\",\n",
    "# \"AP39WF8593/8593_01250825.csv\",   \n",
    "# \"AP39WG0252/0252_01250825.csv\",\n",
    "# \"AP39WG0271/0271_01250825.csv\",\n",
    "# \"AP39WG4628/4268_01250825.csv\",    \n",
    "# \"AP39WG4630/4630_01250825.csv\"\n",
    "]\n",
    "\n",
    "df_raw = pd.read_csv(file_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5ac7bab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>max_bpp</th>\n",
       "      <th>avg_bpp</th>\n",
       "      <th>ttl_dist_m</th>\n",
       "      <th>start_vel</th>\n",
       "      <th>peak_vel</th>\n",
       "      <th>avg_decel_mps2</th>\n",
       "      <th>braking_force_kgf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>01/08/25 10:02:22</td>\n",
       "      <td>01/08/25 10:02:31</td>\n",
       "      <td>57.20</td>\n",
       "      <td>41.60</td>\n",
       "      <td>44.33</td>\n",
       "      <td>41.93</td>\n",
       "      <td>41.93</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1684.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>01/08/25 10:29:57</td>\n",
       "      <td>01/08/25 10:30:05</td>\n",
       "      <td>57.20</td>\n",
       "      <td>29.96</td>\n",
       "      <td>23.98</td>\n",
       "      <td>30.08</td>\n",
       "      <td>30.08</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1371.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>01/08/25 10:45:04</td>\n",
       "      <td>01/08/25 10:45:13</td>\n",
       "      <td>62.40</td>\n",
       "      <td>31.40</td>\n",
       "      <td>32.29</td>\n",
       "      <td>33.07</td>\n",
       "      <td>33.07</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1314.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>01/08/25 10:53:38</td>\n",
       "      <td>01/08/25 10:53:45</td>\n",
       "      <td>48.80</td>\n",
       "      <td>36.00</td>\n",
       "      <td>22.66</td>\n",
       "      <td>31.34</td>\n",
       "      <td>31.34</td>\n",
       "      <td>1.36</td>\n",
       "      <td>1866.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>01/08/25 10:56:33</td>\n",
       "      <td>01/08/25 10:56:43</td>\n",
       "      <td>63.20</td>\n",
       "      <td>27.92</td>\n",
       "      <td>48.30</td>\n",
       "      <td>32.99</td>\n",
       "      <td>32.99</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1330.66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx              start                end max_bpp avg_bpp ttl_dist_m  \\\n",
       "0    1  01/08/25 10:02:22  01/08/25 10:02:31   57.20   41.60      44.33   \n",
       "1    2  01/08/25 10:29:57  01/08/25 10:30:05   57.20   29.96      23.98   \n",
       "2    3  01/08/25 10:45:04  01/08/25 10:45:13   62.40   31.40      32.29   \n",
       "3    4  01/08/25 10:53:38  01/08/25 10:53:45   48.80   36.00      22.66   \n",
       "4    5  01/08/25 10:56:33  01/08/25 10:56:43   63.20   27.92      48.30   \n",
       "\n",
       "  start_vel peak_vel avg_decel_mps2 braking_force_kgf  \n",
       "0     41.93    41.93           1.22           1684.05  \n",
       "1     30.08    30.08           1.00           1371.55  \n",
       "2     33.07    33.07           0.95           1314.38  \n",
       "3     31.34    31.34           1.36           1866.92  \n",
       "4     32.99    32.99           0.97           1330.66  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def analyze_filtered_braking_events(df:pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Analyzes and plots braking events from multiple files, filtering\n",
    "    based on a user-defined top speed reached during the event.\n",
    "    The logic is fine-tuned to extract the exact start point of braking\n",
    "    (BrakePedalPos > 0.0) within a 20-second window before a hard stop.\n",
    "    \"\"\"\n",
    "    top_speed = 30.0  # Default top speed filter (km/h)\n",
    "    search_window_seconds = 10.0  # Time window to look for brake press before\n",
    "\n",
    "    all_event_data = []\n",
    "    # This list will store the dynamically calculated duration for each event.\n",
    "    event_durations = []\n",
    "\n",
    "    # Convert timestamp to human-readable IST and clean the data\n",
    "    df['IST'] = pd.to_datetime(df['timestamp'], unit='ms').dt.tz_localize('UTC').dt.tz_convert('Asia/Kolkata')\n",
    "    df = df[[\"IST\", \"BrakePedalPos\", \"Vehicle_speed_VCU\"]].copy()\n",
    "    df.dropna(subset=[\"Vehicle_speed_VCU\", \"BrakePedalPos\"], inplace=True)\n",
    "    df.sort_values(by='IST', inplace=True)\n",
    "    df.loc[:, 'IST_formatted_string'] = df['IST'].dt.strftime('%H:%M:%S')\n",
    "\n",
    "    # Identify hard stop events (speed becomes 0 from a non-zero value)\n",
    "    hard_stop_mask = (df['Vehicle_speed_VCU'] == 0.0) & (df['Vehicle_speed_VCU'].shift(1) > 0.0)\n",
    "    hard_stop_events = df[hard_stop_mask].copy()\n",
    "\n",
    "    # if hard_stop_events.empty:\n",
    "    #     print(f\"No hard stop events found in the dataset.\")\n",
    "    #     continue\n",
    "    \n",
    "    # 3. Extract and aggregate the data for each filtered event\n",
    "    for _, event_row in hard_stop_events.iterrows():\n",
    "        end_time = event_row['IST']\n",
    "        # Define a search window of 20 seconds before the stop\n",
    "        search_start_time = end_time - pd.Timedelta(seconds=search_window_seconds)\n",
    "\n",
    "        # Look for the first instance of brake pedal application within this window\n",
    "        search_segment = df[(df['IST'] >= search_start_time) & (df['IST'] <= end_time)].copy()\n",
    "\n",
    "        # Find the first row where BrakePedalPos is greater than 0\n",
    "        first_brake_press = search_segment[search_segment['BrakePedalPos'] > 0.0].head(1)\n",
    "\n",
    "        # Check if a brake press was found in the search window\n",
    "        if not first_brake_press.empty:\n",
    "            # Get the exact start time of the braking event\n",
    "            start_time = first_brake_press.iloc[0]['IST']\n",
    "\n",
    "            # Filter the event segment from the exact start of braking to the stop\n",
    "            event_segment = df[(df['IST'] >= start_time) & (df['IST'] <= end_time)].copy()\n",
    "\n",
    "            # Check if the top speed in this dynamic segment meets the filter criteria\n",
    "            if not event_segment.empty and event_segment['Vehicle_speed_VCU'].max() >= top_speed:\n",
    "                # Calculate the dynamic time taken to come to a full stop\n",
    "                time_to_stop_seconds = (end_time - start_time).total_seconds()\n",
    "                \n",
    "                # Append the filtered event data and its duration\n",
    "                all_event_data.append(event_segment)\n",
    "                event_durations.append(time_to_stop_seconds)\n",
    "\n",
    "    if not all_event_data:\n",
    "        print(f\"No events found across all files that reached a top speed of {top_speed} km/h or greater and had a brake press within {search_window_seconds} seconds of the stop.\")\n",
    "        return\n",
    "\n",
    "\n",
    "    # Define constants for the kgf calculation\n",
    "    BUS_MASS_KG = 13500  # 13.5 tonnes * 1000 kg/tonne\n",
    "    G_ACCELERATION = 9.80665 # Standard acceleration due to gravity\n",
    "\n",
    "    table_data = []\n",
    "    \n",
    "    for i, event_group in enumerate(all_event_data):\n",
    "        start_time = event_group['IST'].iloc[0]\n",
    "        end_time = event_group['IST'].iloc[-1]\n",
    "        start_velocity = event_group['Vehicle_speed_VCU'].iloc[0]\n",
    "        peak_velocity = event_group['Vehicle_speed_VCU'].max()\n",
    "        max_brake_pedal_pos = event_group['BrakePedalPos'].max()\n",
    "        min_brake_pedal_pos = event_group['BrakePedalPos'].min()\n",
    "        avg_brake_pedal_pos = event_group['BrakePedalPos'].mean()\n",
    "        \n",
    "        event_group.loc[:, 'speed_mps'] = event_group['Vehicle_speed_VCU'] * (1000 / 3600)\n",
    "        time_diffs_sec = event_group['IST'].diff().dt.total_seconds().fillna(0)\n",
    "        distance_covered_m = (event_group['speed_mps'] * time_diffs_sec).sum()\n",
    "        total_time_s = (end_time - start_time).total_seconds()\n",
    "        \n",
    "        if total_time_s > 0:\n",
    "            # Calculate average deceleration in m/s^2\n",
    "            avg_deceleration = (peak_velocity * 1000/3600) / total_time_s\n",
    "        else:\n",
    "            avg_deceleration = 0\n",
    "            \n",
    "        # Calculate braking force in kgf\n",
    "        braking_force_kgf = (BUS_MASS_KG * avg_deceleration) / G_ACCELERATION\n",
    "        \n",
    "        table_data.append({\n",
    "            'idx': i + 1,\n",
    "            'start': start_time.strftime('%d/%m/%y %H:%M:%S'),\n",
    "            'end': end_time.strftime('%d/%m/%y %H:%M:%S'),\n",
    "            'max_bpp': f\"{max_brake_pedal_pos:.2f}\",\n",
    "            # 'min_bpp': f\"{min_brake_pedal_pos:.2f}\",\n",
    "            'avg_bpp': f\"{avg_brake_pedal_pos:.2f}\",\n",
    "            'ttl_dist_m': f\"{distance_covered_m:.2f}\",\n",
    "            'start_vel': f\"{start_velocity:.2f}\",\n",
    "            'peak_vel': f\"{peak_velocity:.2f}\",\n",
    "            'avg_decel_mps2': f\"{avg_deceleration:.2f}\",\n",
    "            'braking_force_kgf': f\"{braking_force_kgf:.2f}\" # New column\n",
    "        })\n",
    "\n",
    "    results_df = pd.DataFrame(table_data)\n",
    "    return results_df\n",
    "\n",
    "\n",
    "df_final = analyze_filtered_braking_events(df_raw)\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08b235c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 232 entries, 0 to 231\n",
      "Data columns (total 10 columns):\n",
      " #   Column             Non-Null Count  Dtype         \n",
      "---  ------             --------------  -----         \n",
      " 0   idx                232 non-null    int64         \n",
      " 1   start              232 non-null    datetime64[ns]\n",
      " 2   end                232 non-null    object        \n",
      " 3   max_bpp            232 non-null    object        \n",
      " 4   avg_bpp            232 non-null    object        \n",
      " 5   ttl_dist_m         232 non-null    object        \n",
      " 6   start_vel          232 non-null    object        \n",
      " 7   peak_vel           232 non-null    object        \n",
      " 8   avg_decel_mps2     232 non-null    object        \n",
      " 9   braking_force_kgf  232 non-null    object        \n",
      "dtypes: datetime64[ns](1), int64(1), object(8)\n",
      "memory usage: 18.3+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zf/hbscm11n3x7ckch1nd3tg2nh0000gn/T/ipykernel_20751/2919488298.py:2: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df_chk['start'] = pd.to_datetime(df_chk['start'])\n"
     ]
    }
   ],
   "source": [
    "df_chk = df_final.copy()\n",
    "df_chk['start'] = pd.to_datetime(df_chk['start'])\n",
    "df_chk.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0460622a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating final report...\n"
     ]
    }
   ],
   "source": [
    "if df_chk.empty:\n",
    "    print(\"No data to process for final report.\")\n",
    "else:\n",
    "    print(\"Generating final report...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949ffaff",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2787276106.py, line 6)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mimport osdf_chk.head()\u001b[39m\n                        ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "df_chk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aca2c64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_raw = pd.read_csv('braking_mixed_vehicles.csv')\n",
    "file_list = [\n",
    "\"AP39WF8584/8584_01250825.csv\",    \n",
    "# \"AP39WF8589/8589_01250825.csv\",\n",
    "# \"AP39WF8593/8593_01250825.csv\",   \n",
    "# \"AP39WG0252/0252_01250825.csv\",\n",
    "# \"AP39WG0271/0271_01250825.csv\",\n",
    "# \"AP39WG4628/4268_01250825.csv\",    \n",
    "# \"AP39WG4630/4630_01250825.csv\"\n",
    "]\n",
    "\n",
    "df_raw = pd.read_csv(file_list[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dc22372a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vehicle_id</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>max_bpp</th>\n",
       "      <th>avg_bpp</th>\n",
       "      <th>ttl_dist_m</th>\n",
       "      <th>start_vel</th>\n",
       "      <th>peak_vel</th>\n",
       "      <th>avg_decel_mps2</th>\n",
       "      <th>braking_force_kgf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>2025-08-09 05:52:12</td>\n",
       "      <td>2025-08-09 05:52:21</td>\n",
       "      <td>48.00</td>\n",
       "      <td>38.20</td>\n",
       "      <td>34.05</td>\n",
       "      <td>35.95</td>\n",
       "      <td>35.95</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1450.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>2025-08-09 06:13:46</td>\n",
       "      <td>2025-08-09 06:13:56</td>\n",
       "      <td>58.00</td>\n",
       "      <td>42.04</td>\n",
       "      <td>52.03</td>\n",
       "      <td>47.80</td>\n",
       "      <td>47.80</td>\n",
       "      <td>1.44</td>\n",
       "      <td>1978.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>2025-08-09 06:17:02</td>\n",
       "      <td>2025-08-09 06:17:12</td>\n",
       "      <td>51.60</td>\n",
       "      <td>40.28</td>\n",
       "      <td>40.52</td>\n",
       "      <td>43.49</td>\n",
       "      <td>43.49</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1765.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>2025-08-09 06:34:03</td>\n",
       "      <td>2025-08-09 06:34:12</td>\n",
       "      <td>41.20</td>\n",
       "      <td>31.32</td>\n",
       "      <td>32.97</td>\n",
       "      <td>31.24</td>\n",
       "      <td>31.24</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1244.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>2025-08-09 06:38:02</td>\n",
       "      <td>2025-08-09 06:38:12</td>\n",
       "      <td>47.20</td>\n",
       "      <td>35.00</td>\n",
       "      <td>41.17</td>\n",
       "      <td>41.12</td>\n",
       "      <td>41.12</td>\n",
       "      <td>1.18</td>\n",
       "      <td>1617.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   vehicle_id               start                 end max_bpp avg_bpp  \\\n",
       "0          13 2025-08-09 05:52:12 2025-08-09 05:52:21   48.00   38.20   \n",
       "1          13 2025-08-09 06:13:46 2025-08-09 06:13:56   58.00   42.04   \n",
       "2          13 2025-08-09 06:17:02 2025-08-09 06:17:12   51.60   40.28   \n",
       "3          13 2025-08-09 06:34:03 2025-08-09 06:34:12   41.20   31.32   \n",
       "4          13 2025-08-09 06:38:02 2025-08-09 06:38:12   47.20   35.00   \n",
       "\n",
       "  ttl_dist_m start_vel peak_vel avg_decel_mps2 braking_force_kgf  \n",
       "0      34.05     35.95    35.95           1.05           1450.39  \n",
       "1      52.03     47.80    47.80           1.44           1978.05  \n",
       "2      40.52     43.49    43.49           1.28           1765.51  \n",
       "3      32.97     31.24    31.24           0.90           1244.30  \n",
       "4      41.17     41.12    41.12           1.18           1617.75  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def perform_braking_analysis(df):\n",
    "    \"\"\"\n",
    "    Analyzes braking events for multiple device IDs from a single DataFrame,\n",
    "    filtering based on a fixed top speed of 30 km/h.\n",
    "    \n",
    "    The logic is fine-tuned to extract the exact start point of braking\n",
    "    (BrakePedalPos > 0.0) within a 10-second window before a hard stop.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame containing all bus data.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with a summary of the braking events.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define fixed parameters as requested\n",
    "    top_speed = 30.0  # Fixed top speed filter (km/h)\n",
    "    search_window_seconds = 10.0  # Fixed time window to look for brake press\n",
    "    \n",
    "    # Identify unique device IDs from the DataFrame\n",
    "    device_ids = df['id'].unique().tolist()\n",
    "\n",
    "    all_event_data = []\n",
    "    \n",
    "    # Iterate through each unique device ID\n",
    "    for device_id in device_ids:\n",
    "        # Filter the DataFrame for the current device ID\n",
    "        device_df = df[df['id'] == device_id].copy()\n",
    "        \n",
    "        if device_df.empty:\n",
    "            continue\n",
    "\n",
    "        # Convert timestamp to human-readable IST and clean the data\n",
    "        device_df['IST'] = pd.to_datetime(device_df['timestamp'], unit='ms').dt.tz_localize('UTC').dt.tz_convert('Asia/Kolkata')\n",
    "        device_df = device_df[[\"IST\", \"BrakePedalPos\", \"Vehicle_speed_VCU\"]].copy()\n",
    "        device_df.dropna(subset=[\"Vehicle_speed_VCU\", \"BrakePedalPos\"], inplace=True)\n",
    "        device_df.sort_values(by='IST', inplace=True)\n",
    "\n",
    "        # Identify hard stop events (speed becomes 0 from a non-zero value)\n",
    "        hard_stop_mask = (device_df['Vehicle_speed_VCU'] == 0.0) & (device_df['Vehicle_speed_VCU'].shift(1) > 0.0)\n",
    "        hard_stop_events = device_df[hard_stop_mask].copy()\n",
    "\n",
    "        if hard_stop_events.empty:\n",
    "            continue\n",
    "        \n",
    "        # Extract and aggregate the data for each filtered event\n",
    "        for _, event_row in hard_stop_events.iterrows():\n",
    "            end_time = event_row['IST']\n",
    "            search_start_time = end_time - pd.Timedelta(seconds=search_window_seconds)\n",
    "\n",
    "            search_segment = device_df[(device_df['IST'] >= search_start_time) & (device_df['IST'] <= end_time)].copy()\n",
    "\n",
    "            first_brake_press = search_segment[search_segment['BrakePedalPos'] > 0.0].head(1)\n",
    "\n",
    "            if not first_brake_press.empty:\n",
    "                start_time = first_brake_press.iloc[0]['IST']\n",
    "                event_segment = device_df[(device_df['IST'] >= start_time) & (device_df['IST'] <= end_time)].copy()\n",
    "\n",
    "                if not event_segment.empty and event_segment['Vehicle_speed_VCU'].max() >= top_speed:\n",
    "                    all_event_data.append(event_segment)\n",
    "\n",
    "    if not all_event_data:\n",
    "        return pd.DataFrame() # Return an empty DataFrame if no events are found\n",
    "\n",
    "    # Define constants for the kgf calculation\n",
    "    BUS_MASS_KG = 13500  # 13.5 tonnes * 1000 kg/tonne\n",
    "    G_ACCELERATION = 9.80665 # Standard acceleration due to gravity\n",
    "\n",
    "    table_data = []\n",
    "    \n",
    "    for i, event_group in enumerate(all_event_data):\n",
    "        start_time = event_group['IST'].iloc[0]\n",
    "        end_time = event_group['IST'].iloc[-1]\n",
    "        start_velocity = event_group['Vehicle_speed_VCU'].iloc[0]\n",
    "        peak_velocity = event_group['Vehicle_speed_VCU'].max()\n",
    "        max_brake_pedal_pos = event_group['BrakePedalPos'].max()\n",
    "        avg_brake_pedal_pos = event_group['BrakePedalPos'].mean()\n",
    "        \n",
    "        event_group.loc[:, 'speed_mps'] = event_group['Vehicle_speed_VCU'] * (1000 / 3600)\n",
    "        time_diffs_sec = event_group['IST'].diff().dt.total_seconds().fillna(0)\n",
    "        distance_covered_m = (event_group['speed_mps'] * time_diffs_sec).sum()\n",
    "        total_time_s = (end_time - start_time).total_seconds()\n",
    "        \n",
    "        if total_time_s > 0:\n",
    "            avg_deceleration = (peak_velocity * 1000/3600) / total_time_s\n",
    "        else:\n",
    "            avg_deceleration = 0\n",
    "            \n",
    "        braking_force_kgf = (BUS_MASS_KG * avg_deceleration) / G_ACCELERATION\n",
    "        \n",
    "        table_data.append({\n",
    "            'vehicle_id': device_id,\n",
    "            'start': start_time.strftime('%d/%m/%y %H:%M:%S'),\n",
    "            'end': end_time.strftime('%d/%m/%y %H:%M:%S'),\n",
    "            'max_bpp': f\"{max_brake_pedal_pos:.2f}\",\n",
    "            'avg_bpp': f\"{avg_brake_pedal_pos:.2f}\",\n",
    "            'ttl_dist_m': f\"{distance_covered_m:.2f}\",\n",
    "            'start_vel': f\"{start_velocity:.2f}\",\n",
    "            'peak_vel': f\"{peak_velocity:.2f}\",\n",
    "            'avg_decel_mps2': f\"{avg_deceleration:.2f}\",\n",
    "            'braking_force_kgf': f\"{braking_force_kgf:.2f}\"\n",
    "        })\n",
    "\n",
    "    results_df = pd.DataFrame(table_data)\n",
    "    results_df['start'] = pd.to_datetime(results_df['start'], format='%d/%m/%y %H:%M:%S')\n",
    "    results_df['end'] = pd.to_datetime(results_df['end'], format='%d/%m/%y %H:%M:%S')\n",
    "\n",
    "    return results_df\n",
    "\n",
    "\n",
    "df_final = perform_braking_analysis(df_raw)\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "82067fa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "293"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68c35c72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ee399a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>BrakePedalPos</th>\n",
       "      <th>Vehicle_speed_VCU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>9957.000000</td>\n",
       "      <td>9967.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.923300</td>\n",
       "      <td>2.120076</td>\n",
       "      <td>29.417784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.659557</td>\n",
       "      <td>6.731864</td>\n",
       "      <td>31.366995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.636719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>62.630859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>77.600000</td>\n",
       "      <td>86.234375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  BrakePedalPos  Vehicle_speed_VCU\n",
       "count  10000.000000    9957.000000        9967.000000\n",
       "mean       9.923300       2.120076          29.417784\n",
       "std        3.659557       6.731864          31.366995\n",
       "min        3.000000       0.000000           0.000000\n",
       "25%        7.000000       0.000000           0.000000\n",
       "50%        9.000000       0.000000          14.636719\n",
       "75%       13.000000       0.000000          62.630859\n",
       "max       14.000000      77.600000          86.234375"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
