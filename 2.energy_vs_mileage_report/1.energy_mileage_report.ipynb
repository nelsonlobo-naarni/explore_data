{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01fdf6c6-e35f-49da-94f5-d63e8a83e7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "import sys\n",
    "import platform\n",
    "import logging\n",
    "\n",
    "sys.path.append('..')\n",
    "from common import db_operations\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, date, timedelta\n",
    "from common.db_operations import connect_to_trino, fetch_data_for_day, write_df_to_iceberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb8ccac6-81b6-4fcc-af4a-ea1f7df0badd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Python version: 3.11.13\n"
     ]
    }
   ],
   "source": [
    "# Configure basic logging for the business logic file\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Print the Python version being used\n",
    "print(f\"Using Python version: {platform.python_version()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22b7b972-332d-406c-9f49-6daef6e00a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- report configuration ----\n",
    "TABLE_NAME = \"energy_mileage_report\"\n",
    "SOURCE_TABLE = \"can_parsed_output_100\"\n",
    "COLUMNS_TO_FETCH = [\n",
    "    '\"id\"','\"timestamp\"',\n",
    "    'at_timezone(\"timestamp\", \\'Asia/Kolkata\\') AS IST',\n",
    "    '\"BAT_SOC\"',\n",
    "    '\"Bat_Voltage\"',\n",
    "    '\"Total_Battery_Current\"',\n",
    "    '\"GUN_Connection_Status\"',\n",
    "    '\"OdoMeterReading\"',\n",
    "    '\"Gear_Position\"',\n",
    "    '\"Vehiclereadycondition\"'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3544f4d8-dee3-4768-9dbd-968ce8f9b61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------\n",
    "# Step 3: Function to process vehicle energy stats\n",
    "# --------------------\n",
    "def analyze_vehicle_energy_stats(df:pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Performs a combined analysis on an electric bus dataset that may contain\n",
    "    data from multiple vehicles. The function calculates daily mileage, driving\n",
    "    energy consumption, regenerative braking energy, and idling energy for\n",
    "    each vehicle.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the dataset\n",
    "        # df = pd.read_csv(file_path)\n",
    "\n",
    "        # --- General Data Preparation and Filtering ---\n",
    "        # Ignore data points with extreme current values.\n",
    "        df = df[df['Total_Battery_Current'].abs() <= 3000].copy()\n",
    "\n",
    "        # Drop rows with missing data in key columns, including IST.\n",
    "        # df.loc[:, 'IST'] = pd.to_datetime(df['timestamp'], unit='ms').dt.tz_localize('UTC').dt.tz_convert('Asia/Kolkata')\n",
    "        df.dropna(subset=['OdoMeterReading', 'Gear_Position', 'Vehiclereadycondition', 'Total_Battery_Current', 'Bat_Voltage','IST'], inplace=True)\n",
    "\n",
    "        # Sort data by vehicle ID and timestamp to ensure correct sequential calculations.\n",
    "        df.sort_values(by=['id', 'IST'], inplace=True)\n",
    "\n",
    "        # Extract the date for daily grouping\n",
    "        df['date'] = df['IST'].dt.date\n",
    "\n",
    "        # Get a list of unique vehicle IDs to iterate through\n",
    "        unique_ids = df['id'].unique()\n",
    "        all_daily_stats = []\n",
    "\n",
    "        print(\"\\n--- Daily Vehicle Statistics (Driving, Regenerative Braking, and Idling) ---\")\n",
    "\n",
    "        # Iterate over each unique vehicle ID\n",
    "        for vehicle_id in unique_ids:\n",
    "            vehicle_df = df[df['id'] == vehicle_id].copy()\n",
    "\n",
    "            # Check if the grouped DataFrame is empty\n",
    "            if vehicle_df.empty:\n",
    "                print(f\"No charging events were detected for device {vehicle_id}.\")\n",
    "                continue  \n",
    "\n",
    "            # Calculate the time difference between consecutive data points for the current vehicle.\n",
    "            vehicle_df['time_diff_seconds'] = vehicle_df['IST'].diff().dt.total_seconds().fillna(0)\n",
    "\n",
    "            # Filter out records where time difference is zero or negative.\n",
    "            vehicle_df = vehicle_df[vehicle_df['time_diff_seconds'] > 0]\n",
    "\n",
    "            # Calculate the power in kW\n",
    "            vehicle_df['power_kW'] = (vehicle_df['Bat_Voltage'] * vehicle_df['Total_Battery_Current']) / 1000\n",
    "\n",
    "            # --- Analysis 1: Daily Driving and Regenerative Braking Statistics ---\n",
    "            driving_df = vehicle_df[vehicle_df['Gear_Position'] == 2.0].copy()\n",
    "\n",
    "            # Calculate energy consumption (positive power) and regenerative braking energy (negative power)\n",
    "            driving_df['energy_consumption_kwh'] = driving_df.apply(\n",
    "                lambda row: row['power_kW'] * (row['time_diff_seconds'] / 3600) if row['power_kW'] > 0 else 0, axis=1)\n",
    "            driving_df['regen_energy_kwh'] = driving_df.apply(\n",
    "                lambda row: -row['power_kW'] * (row['time_diff_seconds'] / 3600) if row['power_kW'] < 0 else 0, axis=1)\n",
    "\n",
    "            # Calculate incremental mileage for each row.\n",
    "            driving_df['distance_increment'] = driving_df['OdoMeterReading'].diff().fillna(0)\n",
    "\n",
    "            # Filter out unrealistic mileage jumps (e.g., > 10 km in a single time step)\n",
    "            driving_df = driving_df[driving_df['distance_increment'] <= 10]\n",
    "\n",
    "            if not driving_df.empty:\n",
    "                grouped_by_day_driving = driving_df.groupby(['id', 'date'])\n",
    "                daily_driving_mileage = grouped_by_day_driving['distance_increment'].sum()\n",
    "                daily_driving_energy = grouped_by_day_driving['energy_consumption_kwh'].sum()\n",
    "                daily_regen_energy = grouped_by_day_driving['regen_energy_kwh'].sum()\n",
    "\n",
    "                daily_stats_df = pd.DataFrame({\n",
    "                    'dist_travelled_km': round(daily_driving_mileage, 2), #Mileage in km\n",
    "                    'energy_consumed_kwh': round(daily_driving_energy, 2), #Daily Driving Energy Consumed (kWh)\n",
    "                    'regen_energy_kwh': round(daily_regen_energy, 2) #Daily Regenerative Braking Energy (kWh)\n",
    "                }).reset_index()\n",
    "            else:\n",
    "                # Create an empty DataFrame with the correct columns if there is no driving data\n",
    "                daily_stats_df = pd.DataFrame(columns=[\n",
    "                    'id', 'date', 'dist_travelled_km',\n",
    "                    'energy_consumed_kwh',\n",
    "                    'regen_energy_kwh'\n",
    "                ])\n",
    "\n",
    "            # --- Analysis 2: Daily Idling Energy Consumption ---\n",
    "            # Filter for idling periods using 'Gear_Position' == 0 (Neutral) and 'Vehiclereadycondition' == 1\n",
    "            stationary_df = vehicle_df[(vehicle_df['Gear_Position'] == 0.0) & \n",
    "                                       (vehicle_df['Vehiclereadycondition'] == 1.0)].copy()\n",
    "\n",
    "            if not stationary_df.empty:\n",
    "                stationary_df['energy_kwh'] = stationary_df.apply(\n",
    "                    lambda row: row['power_kW'] * (row['time_diff_seconds'] / 3600) if row['power_kW'] > 0 else 0, axis=1)\n",
    "                grouped_by_day_stationary = stationary_df.groupby(['id', 'date'])\n",
    "                daily_idling_energy = grouped_by_day_stationary['energy_kwh'].sum()\n",
    "\n",
    "                daily_idling_df = daily_idling_energy.reset_index(name='idling_energy_kwh') #Daily Idling Energy Consumed (kWh)\n",
    "                daily_idling_df = daily_idling_df.round({'idling_energy_kwh': 2})  \n",
    "\n",
    "                # Merge with existing stats\n",
    "                daily_stats_df = pd.merge(daily_stats_df, daily_idling_df, on=['id', 'date'], how='outer')\n",
    "                daily_stats_df = daily_stats_df.fillna(0)\n",
    "            else:\n",
    "                # If there's only driving data and no idling data\n",
    "                if not daily_stats_df.empty:\n",
    "                    daily_stats_df['idling_energy_kwh'] = 0\n",
    "\n",
    "            if not daily_stats_df.empty:\n",
    "                #Net Energy Consumed (kWh)\n",
    "                daily_stats_df['net_energy_kwh'] = daily_stats_df['energy_consumed_kwh'] - daily_stats_df['regen_energy_kwh']\n",
    "                #Net Consumption Rate (kWh/km)\n",
    "                daily_stats_df['mileage_kwh_per_km'] = (daily_stats_df['net_energy_kwh'] / daily_stats_df['dist_travelled_km']).round(2)\n",
    "                all_daily_stats.append(daily_stats_df)\n",
    "        \n",
    "        if all_daily_stats:            \n",
    "            final_df = pd.concat(all_daily_stats, ignore_index=True)\n",
    "            final_df = final_df[final_df.mileage_kwh_per_km.isna()==False]\n",
    "            final_df.rename(columns={'id': 'vehicle_id'}, inplace=True)\n",
    "            return final_df\n",
    "        else:\n",
    "            print(\"No data found for driving or idling periods.\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad2ab9c5-aef9-4d31-8a7e-4ab91d840a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(conn,df:pd.DataFrame):\n",
    "    # Process data related energy-mileage relation\n",
    "    df_res = df\n",
    "    if not df_res.empty:\n",
    "        # write_df_to_iceberg(conn, df_res, \"energy_mileage_report\" )\n",
    "        logging.info(\"âœ… Processing and write for specific IDs complete.\")\n",
    "    else:\n",
    "        logging.info(\"Processed DataFrame is empty. No data to write.\")\n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97f86eee-e600-4241-acaf-a1624ef04db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------\n",
    "# Main execution logic\n",
    "# --------------------\n",
    "def main(start_date_str: str = None, end_date_str: str = None):\n",
    "    conn = connect_to_trino()\n",
    "    df_duplicate_processed = pd.DataFrame()\n",
    "    df_duplicate_raw = pd.DataFrame()\n",
    "    vehicle_ids_for_report = []    \n",
    "    if conn:\n",
    "        try:\n",
    "            # Determine the date range to process\n",
    "            if start_date_str and end_date_str:\n",
    "                start_date = date.fromisoformat(start_date_str)\n",
    "                end_date = date.fromisoformat(end_date_str)\n",
    "                date_range = [start_date + timedelta(days=i) for i in range((end_date - start_date).days + 1)]\n",
    "            else:\n",
    "                # Default to processing yesterday's data\n",
    "                date_range = [date.today() - timedelta(days=1)]\n",
    "\n",
    "\n",
    "            for single_date in date_range:\n",
    "                date_str = single_date.isoformat()\n",
    "                logging.info(f\"â–¶ï¸ Starting daily report job for {date_str}\")\n",
    "\n",
    "                # Example 2: Call the function with specific vehicle IDs\n",
    "                logging.info(\"\\n--- Processing specific vehicle IDs ---\")\n",
    "                # vehicle_ids_for_report = ['3', '16', '18', '19']\n",
    "                df_raw_specific = fetch_data_for_day(conn, date_str, COLUMNS_TO_FETCH, SOURCE_TABLE, vehicle_ids_for_report)\n",
    "                df_duplicate_raw = df_raw_specific.copy()\n",
    "\n",
    "                if not df_raw_specific.empty:\n",
    "                    df_processed_specific = process_data(conn,analyze_vehicle_energy_stats(df_raw_specific))\n",
    "                    # df_duplicate_processed = df_processed_specific.copy()\n",
    "                    # if not df_processed_specific.empty:\n",
    "                    #     # Updated function call with the missing 'conn' and 'schema' arguments\n",
    "                    #     # write_df_to_iceberg(conn, df_processed_specific, TABLE_NAME, db_operations.COLUMN_SCHEMA_MILEAGE)\n",
    "                    #     logging.info(\"âœ… Processing and write for specific IDs complete.\")\n",
    "                    # else:\n",
    "                    #     logging.info(\"Processed DataFrame is empty. No data to write.\")\n",
    "                else:\n",
    "                    logging.info(\"Raw DataFrame is empty. No processing needed.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.critical(f\"âŒ A critical error occurred in the main script: {e}\")\n",
    "\n",
    "        finally:\n",
    "            logging.info(\"ðŸ”’ STEP 5: Closing Trino connection...\")\n",
    "            conn.close()\n",
    "            logging.info(\"âœ… STEP 5: Connection closed.\")\n",
    "    else:\n",
    "        logging.critical(\"âŒ Failed to establish a database connection. Exiting.\")\n",
    "    \n",
    "    return df_duplicate_raw, df_processed_specific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df765a06-8e4b-409f-b4d5-33fce1352523",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-12 21:09:16 - INFO - ðŸ”Œ STEP 1: Connecting to Trino...\n",
      "2025-10-12 21:09:16 - INFO - âœ… STEP 1: Connected to Trino\n",
      "2025-10-12 21:09:16 - INFO - â–¶ï¸ Starting daily report job for 2025-09-21\n",
      "2025-10-12 21:09:16 - INFO - \n",
      "--- Processing specific vehicle IDs ---\n",
      "2025-10-12 21:09:16 - INFO - ðŸ“¥ STEP 2a: Validating and fetching data for 2025-09-21...\n",
      "2025-10-12 21:09:16 - INFO - âš™ï¸ Executing query...\n",
      "2025-10-12 21:09:45 - INFO - âœ… Query executed successfully!\n",
      "2025-10-12 21:09:45 - INFO - âœ… STEP 2d: Data fetching for 2025-09-21 completed, Rows fetched: 463625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Daily Vehicle Statistics (Driving, Regenerative Braking, and Idling) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-12 21:09:48 - INFO - âœ… Processing and write for specific IDs complete.\n",
      "2025-10-12 21:09:48 - INFO - â–¶ï¸ Starting daily report job for 2025-09-22\n",
      "2025-10-12 21:09:48 - INFO - \n",
      "--- Processing specific vehicle IDs ---\n",
      "2025-10-12 21:09:48 - INFO - ðŸ“¥ STEP 2a: Validating and fetching data for 2025-09-22...\n",
      "2025-10-12 21:09:48 - INFO - âš™ï¸ Executing query...\n",
      "2025-10-12 21:10:12 - INFO - âœ… Query executed successfully!\n",
      "2025-10-12 21:10:12 - INFO - âœ… STEP 2d: Data fetching for 2025-09-22 completed, Rows fetched: 452763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Daily Vehicle Statistics (Driving, Regenerative Braking, and Idling) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-12 21:10:14 - INFO - âœ… Processing and write for specific IDs complete.\n",
      "2025-10-12 21:10:14 - INFO - â–¶ï¸ Starting daily report job for 2025-09-23\n",
      "2025-10-12 21:10:14 - INFO - \n",
      "--- Processing specific vehicle IDs ---\n",
      "2025-10-12 21:10:14 - INFO - ðŸ“¥ STEP 2a: Validating and fetching data for 2025-09-23...\n",
      "2025-10-12 21:10:14 - INFO - âš™ï¸ Executing query...\n",
      "2025-10-12 21:10:38 - INFO - âœ… Query executed successfully!\n",
      "2025-10-12 21:10:38 - INFO - âœ… STEP 2d: Data fetching for 2025-09-23 completed, Rows fetched: 446275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Daily Vehicle Statistics (Driving, Regenerative Braking, and Idling) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-12 21:10:40 - INFO - âœ… Processing and write for specific IDs complete.\n",
      "2025-10-12 21:10:40 - INFO - ðŸ”’ STEP 5: Closing Trino connection...\n",
      "2025-10-12 21:10:40 - INFO - âœ… STEP 5: Connection closed.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # global_df_raw, global_df_processed = main()\n",
    "    # --- For a one-time manual backfill, uncomment the line below and set your dates ---\n",
    "    global_df_raw, global_df_processed =  main(start_date_str='2025-09-21', end_date_str='2025-09-23')\n",
    "\n",
    "    # --- For daily automated runs, use the existing call ---\n",
    "    # main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c723638f-8f85-420e-a251-1ef01d1fa542",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'global_df_raw' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mglobal_df_raw\u001b[49m.head()\n",
      "\u001b[31mNameError\u001b[39m: name 'global_df_raw' is not defined"
     ]
    }
   ],
   "source": [
    "global_df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443db96a-69df-49eb-acd4-8738210e722c",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_df_raw.loc[:, 'date'] = global_df_raw['IST'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0aac84-3bb4-4c0d-b267-f27e1707df02",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_df_raw.groupby(['id', 'date']).size().reset_index(name='count_of_instances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578cddde-b5fc-4553-a228-264958a416b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_df_raw.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ff8880-6d43-4705-89fb-6483d59c27a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_df_processed[global_df_processed.dist_travelled_km >0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3662bb9-c04d-4c8d-915b-937c2f7cbd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_df_processed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
